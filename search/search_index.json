{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Integrated Seismic Program (ISP) Documentation Integrated Seismic Program is an amenable toolbox that joins functionality and standard algorithms commonly used in seismology. The complete software is separated in several modules and each module is designed to overcome a specific task. Cabieces et al. Integrated Seismic Program (ISP) : A New Python GUI\u2010Based Software for Earthquake Seismology and Seismic Signal Processing. Seismological Research Letters 2022;; 93 (3): 1895\u20131908. doi: https://doi.org/10.1785/0220210205 Links Grid .links-container { display: grid; grid-template-columns: repeat(3, 1fr); gap: 15px; max-width: 800px; margin: auto; background: white; padding: 20px; border-radius: 8px; } .link-item { text-decoration: none; display: flex; align-items: center; background: white; padding: 10px; border-radius: 8px; } .link-item img { margin-right: 10px; } .link-item span { font-size: 16px; color: black; font-weight: bold; } See ISP open-source code Follow us on Twitter Subscribe on YouTube Questions and Issues Mailbox: isp@roa.es surfQuake surfQuake core has been totally joined to ISP, now either the library and the command line interface are installed all together! This new software is designed to streamline the workflow of estimating seismic source parameters: Release Date: 18-April-2024 EGU-24 presentation Software Structure Index: Modules Earthquake Seismology Time-Frequency Analysis Focal Mechanism / Moment Tensor Inversion Array Seismology Receiver Functions Ambient Noise Tomography Index: ToolBoxes Database Retrieve Data (FDSN) Probability Power Spectral Density Function (PPSD) Synthetic Generator Near-Real Time Adquisition Multimedia Tutorials Managing your Project Seismogram Analysis Explore and Search in your Catalog Manual Pick, Locate Event, Fault Plane and Magnitude Automatic Picking and Associate Time-Frequency Analysis Array Seismology Moment Tensor Inversion Data examples repository Case of study , contains a full example of using surfQuake with core Library Python scripts, Core Library bash script and expected results. Of course you can try to run the example using the GUI. We have also created a repository with an example of 3D model","title":"Home"},{"location":"#welcome-to-integrated-seismic-program-isp-documentation","text":"Integrated Seismic Program is an amenable toolbox that joins functionality and standard algorithms commonly used in seismology. The complete software is separated in several modules and each module is designed to overcome a specific task. Cabieces et al. Integrated Seismic Program (ISP) : A New Python GUI\u2010Based Software for Earthquake Seismology and Seismic Signal Processing. Seismological Research Letters 2022;; 93 (3): 1895\u20131908. doi: https://doi.org/10.1785/0220210205 Links Grid .links-container { display: grid; grid-template-columns: repeat(3, 1fr); gap: 15px; max-width: 800px; margin: auto; background: white; padding: 20px; border-radius: 8px; } .link-item { text-decoration: none; display: flex; align-items: center; background: white; padding: 10px; border-radius: 8px; } .link-item img { margin-right: 10px; } .link-item span { font-size: 16px; color: black; font-weight: bold; } See ISP open-source code Follow us on Twitter Subscribe on YouTube Questions and Issues Mailbox: isp@roa.es","title":"Welcome to Integrated Seismic Program (ISP) Documentation"},{"location":"#surfquake","text":"surfQuake core has been totally joined to ISP, now either the library and the command line interface are installed all together! This new software is designed to streamline the workflow of estimating seismic source parameters: Release Date: 18-April-2024 EGU-24 presentation","title":"surfQuake"},{"location":"#software-structure","text":"","title":"Software Structure"},{"location":"#index-modules","text":"Earthquake Seismology Time-Frequency Analysis Focal Mechanism / Moment Tensor Inversion Array Seismology Receiver Functions Ambient Noise Tomography","title":"Index: Modules"},{"location":"#index-toolboxes","text":"Database Retrieve Data (FDSN) Probability Power Spectral Density Function (PPSD) Synthetic Generator Near-Real Time Adquisition","title":"Index: ToolBoxes"},{"location":"#multimedia-tutorials","text":"Managing your Project Seismogram Analysis Explore and Search in your Catalog Manual Pick, Locate Event, Fault Plane and Magnitude Automatic Picking and Associate Time-Frequency Analysis Array Seismology Moment Tensor Inversion","title":"Multimedia Tutorials"},{"location":"#data-examples-repository","text":"Case of study , contains a full example of using surfQuake with core Library Python scripts, Core Library bash script and expected results. Of course you can try to run the example using the GUI. We have also created a repository with an example of 3D model","title":"Data examples repository"},{"location":"Special_Thanks/","text":"The Developer Team of ISP thanks to: Anthony Lomax and Claudio Satriano for helping in NLL configuration and the help in the framework 3D-model Visualisation. ObsPy developers and users community for giving a hand to this project during the last few years. Real Instituto y Observatorio de la Armada (Spain), University of Potsdam (Germany), Institute of Rock Structure and Mechanic (Chzechia), University of Oviedo (Spain), Universidad de Granada (Spain), Instituto de Ciencias del Mar (Spain) and Instituto Geogr\u00e1fico Nacional (Spain).","title":"The Developer Team of ISP thanks to:"},{"location":"Special_Thanks/#the-developer-team-of-isp-thanks-to","text":"Anthony Lomax and Claudio Satriano for helping in NLL configuration and the help in the framework 3D-model Visualisation. ObsPy developers and users community for giving a hand to this project during the last few years. Real Instituto y Observatorio de la Armada (Spain), University of Potsdam (Germany), Institute of Rock Structure and Mechanic (Chzechia), University of Oviedo (Spain), Universidad de Granada (Spain), Instituto de Ciencias del Mar (Spain) and Instituto Geogr\u00e1fico Nacional (Spain).","title":"The Developer Team of ISP thanks to:"},{"location":"aa/","text":"Array Analysis Array Response Function (ARF) The Array Response Function (ARF) (Ruigrok et al., 2017) helps to evaluate the resolution of the array in a specific bandwidth. First you need to create a coordinates files and then load it. To create the coordinate file go to \u201cFiles >>> Stations Coordinates\u201d and fill the table with lat (o), lon (o) and depth (km). See this example: Name Lon Lat Depth IL02 -146.864304 64.784698 261 IL03 -146.851196 64.771400 440 IL04 -146.876099 64.757004 528 IL05 -146.922897 64.773102 389 IL06 -146.904007 64.779198 262 This example of ccordinates files is available at: isp/arrayanalysis/stations/coordsLasa.txt Then you can compute the ARF and plot the map with the array stations. Frequency-Wavenumber Analysis The Frequency-Wavenumber (FK) is basically a method to compute the beamforming in the frequency domain (Capon, 1969). To compute the FK you need follow this steps; Open Earthquake Analysis, then load a metadata (stations coordinates and instrument info). Clicking at Metadata File. Then create a project or load a project, clicking at New Project / Load project. Next, process and plot your waveforms. Finally trim the event (check the box Trim Time) and click on the array analysis button on the top The figure below represents the seismograms: isp/examples/NuclearExplotionILAR_2017 and metadata at: isp/Metadata/dataless_LASA/dataless.dlsv Fill the parameters (Slowness Max, Time Window, overlap\u2026\u2026) Choose methods Press Run F-K Now, you will watch in the upper panels the Rel Power, Absolute Power, Back-Azimuth and Slowness results of your analysis. Two more actions: Double pick at any of the upper panels will run the FK in that specific time window (starting in the point). Then, the slowness map will show up. if you check Shift, the stack and the shifted traces according to the maximum slowness vector will be process and plot. Additionally you can select the stacking method. The stack trace can be saved as miniseed, go to file save seismogram stack. The stack trace can be saved as mseed file, click at file/write seismograms/stack. The pick with the slowness vector corresponding to the phase you selected are automatically saved in the file \u201cisp/arrayanalysis/array_picks.txt\u201d and you can open the file just pressing \u201cctrl+o\u201d. Fk Analysis Traces Stack Vespagram The vespagram is a visualization of the FK results for an specific backazimuth or slowness. So, once you have done the FK analysis, you can compute the vespagram (Rost and Thomas, 2002). But before, you must select the time window. Go with the mouse to the any upper panel. Pick, hold and drag to the right direction to do the selection. The span time will be hilighted and then you can open the vespagram window. In the vespagram window you can select the parameters (Win length, overlap, and frequency bandwidth of the analysis) and the backazimuth and slowness where you want to compute the vespagram. Vespagram Back Projection The Back Projection is a relatively new technique (Kruger and Ohrnberger 2005) designed to quickly and effectively imaging rupture process of large earthquakes. Back-projecting seismic data can be done by big seismic arrays. In ISP the user can process the seismograms and set the BackProjection parameters. It is shown a screenshot of the preparation of the data of Sumatra Earthquake using Earthquake Analysis module, and then using Back Projection tool. First the user set the path to the seismograms, metadata and the output folder. Second, the seismograms can be chopped and a macro with some signal processing can be established. Then, the user must set the Back Projection parameters: Warning . BackProjection is highly computing demanding, so we do not recomend using too high resolutions (dx = dy > 0.5), too long time window (time window < 800s) and too big grids (maxlat-minlat and maxlon - minlon < 15 degrees) Grid: set the minimum longitude and latitude and the maximum latitude and longitude as well as dx and dy (resolution in longitude and latitude in degrees) where the Back projection is going to be calculated. Set the depth. Time window is the whole period in which the BackProjection is going to be calculated. A small sliding window will be shifted forward in time in step by step . Click on generate the Travel Time Grid. This action will create a travel time grid in wich your grid cells have the travel time from every station to every lat and lon cell. Click on Run BackProjection. In every step will be calculated the Backprojcetion aligning the traces using the Multi Channel Cross Correlation technique (VanDecar and Crosson 1990) according to the Travel Time grid and estimating the power by a simple linear stack or using the Zero Lag Cross Correlation Technique (Almendros et al., 1999). Finally, Load the result video and play it. Multimedia Material (Array Analysis) The following video shows a basic analysis of a nueclear explotion (Test from Nort Korea test 2017, Alaska Array ILAR)","title":"Array Analysis"},{"location":"aa/#array-analysis","text":"","title":"Array Analysis"},{"location":"aa/#array-response-function-arf","text":"The Array Response Function (ARF) (Ruigrok et al., 2017) helps to evaluate the resolution of the array in a specific bandwidth. First you need to create a coordinates files and then load it. To create the coordinate file go to \u201cFiles >>> Stations Coordinates\u201d and fill the table with lat (o), lon (o) and depth (km). See this example: Name Lon Lat Depth IL02 -146.864304 64.784698 261 IL03 -146.851196 64.771400 440 IL04 -146.876099 64.757004 528 IL05 -146.922897 64.773102 389 IL06 -146.904007 64.779198 262 This example of ccordinates files is available at: isp/arrayanalysis/stations/coordsLasa.txt Then you can compute the ARF and plot the map with the array stations.","title":"Array Response Function (ARF)"},{"location":"aa/#frequency-wavenumber-analysis","text":"The Frequency-Wavenumber (FK) is basically a method to compute the beamforming in the frequency domain (Capon, 1969). To compute the FK you need follow this steps; Open Earthquake Analysis, then load a metadata (stations coordinates and instrument info). Clicking at Metadata File. Then create a project or load a project, clicking at New Project / Load project. Next, process and plot your waveforms. Finally trim the event (check the box Trim Time) and click on the array analysis button on the top The figure below represents the seismograms: isp/examples/NuclearExplotionILAR_2017 and metadata at: isp/Metadata/dataless_LASA/dataless.dlsv Fill the parameters (Slowness Max, Time Window, overlap\u2026\u2026) Choose methods Press Run F-K Now, you will watch in the upper panels the Rel Power, Absolute Power, Back-Azimuth and Slowness results of your analysis. Two more actions: Double pick at any of the upper panels will run the FK in that specific time window (starting in the point). Then, the slowness map will show up. if you check Shift, the stack and the shifted traces according to the maximum slowness vector will be process and plot. Additionally you can select the stacking method. The stack trace can be saved as miniseed, go to file save seismogram stack. The stack trace can be saved as mseed file, click at file/write seismograms/stack. The pick with the slowness vector corresponding to the phase you selected are automatically saved in the file \u201cisp/arrayanalysis/array_picks.txt\u201d and you can open the file just pressing \u201cctrl+o\u201d. Fk Analysis Traces Stack","title":"Frequency-Wavenumber Analysis"},{"location":"aa/#vespagram","text":"The vespagram is a visualization of the FK results for an specific backazimuth or slowness. So, once you have done the FK analysis, you can compute the vespagram (Rost and Thomas, 2002). But before, you must select the time window. Go with the mouse to the any upper panel. Pick, hold and drag to the right direction to do the selection. The span time will be hilighted and then you can open the vespagram window. In the vespagram window you can select the parameters (Win length, overlap, and frequency bandwidth of the analysis) and the backazimuth and slowness where you want to compute the vespagram. Vespagram","title":"Vespagram"},{"location":"aa/#back-projection","text":"The Back Projection is a relatively new technique (Kruger and Ohrnberger 2005) designed to quickly and effectively imaging rupture process of large earthquakes. Back-projecting seismic data can be done by big seismic arrays. In ISP the user can process the seismograms and set the BackProjection parameters. It is shown a screenshot of the preparation of the data of Sumatra Earthquake using Earthquake Analysis module, and then using Back Projection tool. First the user set the path to the seismograms, metadata and the output folder. Second, the seismograms can be chopped and a macro with some signal processing can be established. Then, the user must set the Back Projection parameters: Warning . BackProjection is highly computing demanding, so we do not recomend using too high resolutions (dx = dy > 0.5), too long time window (time window < 800s) and too big grids (maxlat-minlat and maxlon - minlon < 15 degrees) Grid: set the minimum longitude and latitude and the maximum latitude and longitude as well as dx and dy (resolution in longitude and latitude in degrees) where the Back projection is going to be calculated. Set the depth. Time window is the whole period in which the BackProjection is going to be calculated. A small sliding window will be shifted forward in time in step by step . Click on generate the Travel Time Grid. This action will create a travel time grid in wich your grid cells have the travel time from every station to every lat and lon cell. Click on Run BackProjection. In every step will be calculated the Backprojcetion aligning the traces using the Multi Channel Cross Correlation technique (VanDecar and Crosson 1990) according to the Travel Time grid and estimating the power by a simple linear stack or using the Zero Lag Cross Correlation Technique (Almendros et al., 1999). Finally, Load the result video and play it.","title":"Back Projection"},{"location":"aa/#multimedia-material-array-analysis","text":"The following video shows a basic analysis of a nueclear explotion (Test from Nort Korea test 2017, Alaska Array ILAR)","title":"Multimedia Material (Array Analysis)"},{"location":"ant/","text":"Ambient Noise Tomography The module ANT is divided in three main parts. First the toolbox designed to retrive Empirical Green Function, second the toolbos designed to measure phase and group velocity from the dispersion curves of EGs and third the toolbox to generate dispersion maps from the previous measurements. In this tutorial is explained how to manage the module. We recommend rreading Bensen et al., 2007 to understand the point EGF, Rusell et al., 1988 to understanf the Frequency-Time analysis and the Phase Match Filter, and Barmin 2001 how to compute the Dispersion Maps. EGF 1 Setting Files Path & Metadata To set the path to the metadata of your network and the path where you have hosted your seismogram files. First, let's create a project. Set the path where you have the data files. They can be located in any kind of structure, for example in SDS arquitecture ( NETWORK/STATION/CHANNEL/FILES ) or simply everything in one single folder. WARNING!, create the project can take some time, do not desperate!. Second, set the path where you have the metadata of all nets/stations/channels yo want to process. 2 Setting Parameters for the pre-processing steps of the EGFs 2.1. Processing Box Processing Time Window : This is the time window in seconds that the daily seismograms files will be splitted to save the matrix of noise (see below for more details). Filter Files : Might be you only want to generate a project for a set of stations \"sta1,sta2,sta3...\" or a set of channels \"BHZ,HHZ\". If you want everything just let the space empty. Remove Instrumet : Set the four corner frequencies (very carefull with nyquist frequency of your data), the water level value and the output units. Even though this operation is computationally demanding, it is fully recommended to deconvolve your instrument to prevent from mixture cross-correlation of data from different instruments. Decimate : Set the decimation factor. For example if you have HHZ (100hz), a good decimation factor would be 10 to set the new sampling rate to 10 Hz, which is enough to later measure dispersion. Time Normalization : If is selected a running avarage, a moving median avarage filter of time window selected will be applied. If 1 bit is selected (not recommended) amplitudes will be mapped to (+1, -1). Spectral Whithening : A moving avarage filter in the amplitude spectrum is applied with a bandwidth selected by the user. Then set the folder where you want the output of the pre-processing and the EGFs. 2.2. Stack Box Components : Select the components that you want to cross correlate and stack. This operation allows ISP just select specific noise matrix to boost the speed of the stack. Stacking Method :Select amoung Phase Wave stack, Linear and nth-root stack. Personally we recommend go for linear if you have several months of data and go for PWS if you have just few . Nth-rooth for testing and comparison with linear. The parameter is the power of the method in PWS or Nrooth (Do not change from 2 :-)) Maximum Intedistance : Because sometimes we do not want to mix EGFs with very long interdistance with short distance, ISP allows the user to filter the cross correlation and stack computation by maximum interdistance value. Check Noise Matrix Output : If the user check Compute daily Stacks , ISP will compute the evolution of the EGFs in partial stacks of 20 days. If Include Autocorrelations and Shifted Cross Correlations , ISP will estimate all pssoble cross-correlations including autocorrelations e.g., ZZ and both cross-correlations (e.g., ZE and EZ). This option is mandatory to be checked if you want go for Transversal components to estimate dispersion curves of Love Waves. 3 Run pre-processing Now, click on Run pre-processing. This action will load your settings and will make a database of the available files. Then the process will start to process the data. Finally per every station/channel a file will be saved containing a matrix with the noise data in frequency domain, ready to cross-correlate. 4 Run Stack This action will load files from the pre-processing step and then for every channel-channel combination will do a cross correlation and stack all the stacks will be saved in the .outpur_directory/stack. 5 Explore your EGFs In this point the user can set the path to the output files (hdf5 or sac files), read the files and then process and plot . The user can also establish a Macro to process the EGFs, plot a map and sort the EGFs by inter station distance. Notice that autocorrelations will be 0 distance. Set Path Set the path to your stack output directory. Read Files create a list ready to process and plot of the available stack EGF in the folder. If Sort is checked, the files will be sorted by inter-station distance or backazimth. Process and Plot Process the EGFs of the list according to the macro previously established and then plot. 6 Explaining the output When the user compute the preprocess, all information is saved in Noise Matrix per station/channel. The noise matrid is a 3D matrix in whic the first dimension or the rows are consecutive time windows of an split day, the seconddimension or the colums are the day and the third dimension or depth is the complex numers corresponding to the processed spectrum of the noise window. The matrix is saved as pickle with name \"NWTSTACHANNEL\". The matrix includes a column daily header \"[julday1.year1\",julday2.year1, .... ] and a numpy arrayy with the spectral information. Afterwards, when the user press cross and stack, ISP combines the matrix information ifft(matrix_A*cong(matrix_B)) and then stack. Stack files shoul be named as follows \"NET.STA1_STA2.CHN1CHN2\". The stack files have format hdf5, basically a mseed with extra header info (e.g., inter-distance or inter-azimuth). Stack_daily files are partial stacks with this aspect \"NET.STA1_STA2.CHN1CHN2_daily\", They are part of the output and basically are partial stacks of noise windows of 20 days shifted by default 10 days (50%). This is very useful to both, monitorize the evolution of noise and to synchonize Ocean Bottom Seismometers. output_dir/matrix_files outout_dir/stack/ output_dir/stack_daily/ output_dir/stack_rotated/ Clock Synchronization Clock Synchonization is very easy using ISP. Just select the station pair you want to synchronize Search file and th process (take the parameters from the macro) and plot Plot Daily Correlations . This action will be show the evolution of noise in partial stacks of 20 days. Now you can chop the signal pressing \"q\" for starttime and \"e\" and then check the trim box. Now select how do you want to fit your data, normaly a straight line but you can choose a plynom of degree up to 6. Press sync Finally click and drag with the mouse and draw a free line over the points to be selected. Finally press enter. The output will be saved as a pickle dictionary : isp/ant/clock_dir/STA1_STA2 where STA1_STA2 keys = {clocks_station_name, Dates, Drift, Ref, R2} Dispersion Curves Once you have generated the EGFs, it is time to measure the dispersion curves (phase and group velocity). We are going to explain how to use this module step by step. 1 Creating a Project First of all, create a project by clicking in the upper diplaying pannels \"Dispersion Curves/Manage Project\" then will pop up this widget: Ok, now set the path where you want to create the project and give it a name, next Create New Project . You will find an example of project at ant/disp_maps.pkl, that it is just a dicctionary with the information of the dispersion measurements. Later I will show you that this project is the entry to plot the Dispersion Maps. 2 Time to measure dispersion You can configurate your window as the figure below. Start with general configuration: Settings : Causal/Acausal : part of the quasi-symmetric EGF. This is the part that will be analyze in the process. Rayleigh/Love : wave that will be saved to the project for info. Normally the user should select Raylegh for EGFs retrived from the verical components between pair of stations and Love for the horizontals. Process Phase and Group Velocity : Files Directory : Place the path where you have the stack files (see point 6 of the previous section). Macros : Place the processing steps you with to apply to your EGF. Method : For now tested Continuos Wavelet Transform with the Morlet Wavelet and using number of cycles 6 (perfect match between Fourier frequency and wavelet scales). Min level : Set the minimum water level you want for your Frequency-Time analysis in Group Velocity Phase Match Filter : This filter is applied to measure Group Velocity and basically takes a \"Ref Disp Curve\" and try to match it with your actual Dispersion curve. if you decide apply it you will notice the effect in both the time domain right pannel and in the Frequency-Time Group velocity pannel. Process first Group then Phase velocity : Once It is plot the Time-Frequency plane of Group velocity (central pannel), the you can click (left button) and drag with your mouse to draw a free style line selecting all points that you consider for saving later. Once you close the draw, that point will appear in purple. Now, press process Phase velocity. You will see kind of several parallel curves. Same thing, click and drag to select all point with the same color. 3 Save your stuff in your Project Save to Project : the dispersion measurements of Phase and Group Velocity. Once it is saved into the project, ISP wil check the box correspong to the file and print in the terminal. Remove from Project : a measurement just highlighting a checked file and press this button to remove the wrong measure from your project. Dispersion Maps In a very simple way you will plot Dispersion Maps. Set the path to your project : Remind you that you have available an example at isp/anddisp_maps.pkl. Now you must tell ISP where to find the information you want to plot. You can do it as follows: Select the wave type Vertical/Rayleigh Wave Hrizontal/Love Wave Dispersion type Group/Phase Velocity Then, set some parametriztion related to resolution and smoothing Dispersion Maps Parameters : Set the minimum and maximum Period in which to want to compute the analysis or just check all periods to compute everything possible inside your project. Period Step : It is the period step in which you want to compute every map. Every One second is more than enougth do not be crazy! :-). Grid resolution : It is is the estimated spatial resolution that you expect for your maps. It depends on the geometry of your network, the interdistance and the maximum distance between staion pairs. Dispersion Maps Smoothing Parameters (see Barmin 2001 to understand the effect of the regularization parameters). Our own advice is if you want high detail go foe a = 600, but if you want high smoothing go for a = 1000. Let b = 10 and gamma = 100. We are developing the resolution maps and checkboard test. Just give us a chance","title":"Ambient Noise Tomography"},{"location":"ant/#ambient-noise-tomography","text":"The module ANT is divided in three main parts. First the toolbox designed to retrive Empirical Green Function, second the toolbos designed to measure phase and group velocity from the dispersion curves of EGs and third the toolbox to generate dispersion maps from the previous measurements. In this tutorial is explained how to manage the module. We recommend rreading Bensen et al., 2007 to understand the point EGF, Rusell et al., 1988 to understanf the Frequency-Time analysis and the Phase Match Filter, and Barmin 2001 how to compute the Dispersion Maps.","title":"Ambient Noise Tomography"},{"location":"ant/#egf","text":"1 Setting Files Path & Metadata To set the path to the metadata of your network and the path where you have hosted your seismogram files. First, let's create a project. Set the path where you have the data files. They can be located in any kind of structure, for example in SDS arquitecture ( NETWORK/STATION/CHANNEL/FILES ) or simply everything in one single folder. WARNING!, create the project can take some time, do not desperate!. Second, set the path where you have the metadata of all nets/stations/channels yo want to process. 2 Setting Parameters for the pre-processing steps of the EGFs 2.1. Processing Box Processing Time Window : This is the time window in seconds that the daily seismograms files will be splitted to save the matrix of noise (see below for more details). Filter Files : Might be you only want to generate a project for a set of stations \"sta1,sta2,sta3...\" or a set of channels \"BHZ,HHZ\". If you want everything just let the space empty. Remove Instrumet : Set the four corner frequencies (very carefull with nyquist frequency of your data), the water level value and the output units. Even though this operation is computationally demanding, it is fully recommended to deconvolve your instrument to prevent from mixture cross-correlation of data from different instruments. Decimate : Set the decimation factor. For example if you have HHZ (100hz), a good decimation factor would be 10 to set the new sampling rate to 10 Hz, which is enough to later measure dispersion. Time Normalization : If is selected a running avarage, a moving median avarage filter of time window selected will be applied. If 1 bit is selected (not recommended) amplitudes will be mapped to (+1, -1). Spectral Whithening : A moving avarage filter in the amplitude spectrum is applied with a bandwidth selected by the user. Then set the folder where you want the output of the pre-processing and the EGFs. 2.2. Stack Box Components : Select the components that you want to cross correlate and stack. This operation allows ISP just select specific noise matrix to boost the speed of the stack. Stacking Method :Select amoung Phase Wave stack, Linear and nth-root stack. Personally we recommend go for linear if you have several months of data and go for PWS if you have just few . Nth-rooth for testing and comparison with linear. The parameter is the power of the method in PWS or Nrooth (Do not change from 2 :-)) Maximum Intedistance : Because sometimes we do not want to mix EGFs with very long interdistance with short distance, ISP allows the user to filter the cross correlation and stack computation by maximum interdistance value. Check Noise Matrix Output : If the user check Compute daily Stacks , ISP will compute the evolution of the EGFs in partial stacks of 20 days. If Include Autocorrelations and Shifted Cross Correlations , ISP will estimate all pssoble cross-correlations including autocorrelations e.g., ZZ and both cross-correlations (e.g., ZE and EZ). This option is mandatory to be checked if you want go for Transversal components to estimate dispersion curves of Love Waves. 3 Run pre-processing Now, click on Run pre-processing. This action will load your settings and will make a database of the available files. Then the process will start to process the data. Finally per every station/channel a file will be saved containing a matrix with the noise data in frequency domain, ready to cross-correlate. 4 Run Stack This action will load files from the pre-processing step and then for every channel-channel combination will do a cross correlation and stack all the stacks will be saved in the .outpur_directory/stack. 5 Explore your EGFs In this point the user can set the path to the output files (hdf5 or sac files), read the files and then process and plot . The user can also establish a Macro to process the EGFs, plot a map and sort the EGFs by inter station distance. Notice that autocorrelations will be 0 distance. Set Path Set the path to your stack output directory. Read Files create a list ready to process and plot of the available stack EGF in the folder. If Sort is checked, the files will be sorted by inter-station distance or backazimth. Process and Plot Process the EGFs of the list according to the macro previously established and then plot. 6 Explaining the output When the user compute the preprocess, all information is saved in Noise Matrix per station/channel. The noise matrid is a 3D matrix in whic the first dimension or the rows are consecutive time windows of an split day, the seconddimension or the colums are the day and the third dimension or depth is the complex numers corresponding to the processed spectrum of the noise window. The matrix is saved as pickle with name \"NWTSTACHANNEL\". The matrix includes a column daily header \"[julday1.year1\",julday2.year1, .... ] and a numpy arrayy with the spectral information. Afterwards, when the user press cross and stack, ISP combines the matrix information ifft(matrix_A*cong(matrix_B)) and then stack. Stack files shoul be named as follows \"NET.STA1_STA2.CHN1CHN2\". The stack files have format hdf5, basically a mseed with extra header info (e.g., inter-distance or inter-azimuth). Stack_daily files are partial stacks with this aspect \"NET.STA1_STA2.CHN1CHN2_daily\", They are part of the output and basically are partial stacks of noise windows of 20 days shifted by default 10 days (50%). This is very useful to both, monitorize the evolution of noise and to synchonize Ocean Bottom Seismometers. output_dir/matrix_files outout_dir/stack/ output_dir/stack_daily/ output_dir/stack_rotated/","title":"EGF"},{"location":"ant/#clock-synchronization","text":"Clock Synchonization is very easy using ISP. Just select the station pair you want to synchronize Search file and th process (take the parameters from the macro) and plot Plot Daily Correlations . This action will be show the evolution of noise in partial stacks of 20 days. Now you can chop the signal pressing \"q\" for starttime and \"e\" and then check the trim box. Now select how do you want to fit your data, normaly a straight line but you can choose a plynom of degree up to 6. Press sync Finally click and drag with the mouse and draw a free line over the points to be selected. Finally press enter. The output will be saved as a pickle dictionary : isp/ant/clock_dir/STA1_STA2 where STA1_STA2 keys = {clocks_station_name, Dates, Drift, Ref, R2}","title":"Clock Synchronization"},{"location":"ant/#dispersion-curves","text":"Once you have generated the EGFs, it is time to measure the dispersion curves (phase and group velocity). We are going to explain how to use this module step by step. 1 Creating a Project First of all, create a project by clicking in the upper diplaying pannels \"Dispersion Curves/Manage Project\" then will pop up this widget: Ok, now set the path where you want to create the project and give it a name, next Create New Project . You will find an example of project at ant/disp_maps.pkl, that it is just a dicctionary with the information of the dispersion measurements. Later I will show you that this project is the entry to plot the Dispersion Maps. 2 Time to measure dispersion You can configurate your window as the figure below. Start with general configuration: Settings : Causal/Acausal : part of the quasi-symmetric EGF. This is the part that will be analyze in the process. Rayleigh/Love : wave that will be saved to the project for info. Normally the user should select Raylegh for EGFs retrived from the verical components between pair of stations and Love for the horizontals. Process Phase and Group Velocity : Files Directory : Place the path where you have the stack files (see point 6 of the previous section). Macros : Place the processing steps you with to apply to your EGF. Method : For now tested Continuos Wavelet Transform with the Morlet Wavelet and using number of cycles 6 (perfect match between Fourier frequency and wavelet scales). Min level : Set the minimum water level you want for your Frequency-Time analysis in Group Velocity Phase Match Filter : This filter is applied to measure Group Velocity and basically takes a \"Ref Disp Curve\" and try to match it with your actual Dispersion curve. if you decide apply it you will notice the effect in both the time domain right pannel and in the Frequency-Time Group velocity pannel. Process first Group then Phase velocity : Once It is plot the Time-Frequency plane of Group velocity (central pannel), the you can click (left button) and drag with your mouse to draw a free style line selecting all points that you consider for saving later. Once you close the draw, that point will appear in purple. Now, press process Phase velocity. You will see kind of several parallel curves. Same thing, click and drag to select all point with the same color. 3 Save your stuff in your Project Save to Project : the dispersion measurements of Phase and Group Velocity. Once it is saved into the project, ISP wil check the box correspong to the file and print in the terminal. Remove from Project : a measurement just highlighting a checked file and press this button to remove the wrong measure from your project.","title":"Dispersion Curves"},{"location":"ant/#dispersion-maps","text":"In a very simple way you will plot Dispersion Maps. Set the path to your project : Remind you that you have available an example at isp/anddisp_maps.pkl. Now you must tell ISP where to find the information you want to plot. You can do it as follows: Select the wave type Vertical/Rayleigh Wave Hrizontal/Love Wave Dispersion type Group/Phase Velocity Then, set some parametriztion related to resolution and smoothing Dispersion Maps Parameters : Set the minimum and maximum Period in which to want to compute the analysis or just check all periods to compute everything possible inside your project. Period Step : It is the period step in which you want to compute every map. Every One second is more than enougth do not be crazy! :-). Grid resolution : It is is the estimated spatial resolution that you expect for your maps. It depends on the geometry of your network, the interdistance and the maximum distance between staion pairs. Dispersion Maps Smoothing Parameters (see Barmin 2001 to understand the effect of the regularization parameters). Our own advice is if you want high detail go foe a = 600, but if you want high smoothing go for a = 1000. Let b = 10 and gamma = 100. We are developing the resolution maps and checkboard test. Just give us a chance","title":"Dispersion Maps"},{"location":"basics/","text":"Warming tutorial This section will show you the overall structure of the project and a basic idea of how are the data managed by ISP. Description In ISP we have decided go for miniseed format, with is one of the most broadly used data storage formats for seismograms. The best description is given at mseed which is simply: MiniSEED is the subset of the SEED standard that is used for time series data. Very limited metadata for the time series is included in miniSEED beyond time series identification and simple state-of-health flags. In particular, geographic coordinates, response/scaling information and other information needed to interpret the data values are not included. Time series are stored as generally independent, fixed length data records which each contain a small segment of contiguous series values. A reader of miniSEED is required to reconstruct longer, contiguous time series from the data record segments. Common record lengths are 512-byte (for real time streams) and 4096-byte (for archiving), other record lengths are used for special scenarios. A \u201cfile\u201d or \u201cstream\u201d of miniSEED is simply a concatenation of data records. Depending on the capabilities of the intended reader the data records for multiple channels of data may be multiplexed together. Project: Seismograms and metadata Create a Project from seismogram files We start explaining how to start a project inside Earthquake Analysis module (more details inside sections). First of all you need to create a project. A project is basically a \"dictionary file\" that tells your computer where are your valid data. This strategy makes easier to explore your big data. Now, let's create a new project pressing the button \"New Project\" You will find this dialog that will guide you to crete the project. Two option: Create Project from individual files, you will select individual files that going to be part of your project. Create Full Project, you give the path to the folder tree where you have your daily data files. ISP will scan all folders validating the files and will create the project. Afterwards, you can save your project (recommended) giving a name and press \"Saving Project\". Becareful, when you start to create a project ISP will capture the search filters, so for example if in the Project Box Channels is selected \"BHZ\" as in the picture below, the project will created based on this filters- If you do not want any filter set the filter bocxes empty Filters boxes uses Regex and Python keywords : For example, if ypu want search any component in channels \"BH.\" or if you want any station but verical component station \".+\" channel BHZ. Very important, you can reload your project aplying searching filters simply by pressing \"r\" outside the plot window. This action also takes into account if trim is checked to cut the time window. This is very useful to search for specific time windows where you already knows in advance that there is an event there. Project Video Tutorial The following video shows how to create a project, make searches by wildcards and how to search by specific time windows. Metadata (Dataless and *.xml) ISP uses two kind of metadata files either Dataless or xml. ( https://docs.obspy.org/tutorial/code_snippets/stationxml_file_from_scratch.html ). You can find an example of this files at the folders isp/Metadata/dataless and isp/Metadata/xml. As you will see, in the this files there is information structured as a dictionary nets/stations/channels. Personally, the best way to make your own metadata file is using either the java software PDCC or going to the API Station Management Portal . Important : The idea in ISP is that your Metadata file (one single file) contains all of the information (such as coordinates of your stations, instrument response, sampling frequency and so on ...) of the miniseed files you are going to manage. The reason of this design is that, it is easier to programming something that works independently from the miniseed file to metadata. For example when sorting the minified files from respect to an event. The software internally reads the name of all of your files (in the header) and then match this info with the metadata file. Notes : It is very easy using python to convert your dataless to xml. From: https://docs.obspy.org/_modules/obspy/core/inventory/inventory.html#Inventory.write from obspy import read_inventory inv = read_inventory(\"path_to_your_dataless\") inv.write(path_or_file_object, format=\"stationxml\", validate=True)","title":"Start with the basics"},{"location":"basics/#warming-tutorial","text":"This section will show you the overall structure of the project and a basic idea of how are the data managed by ISP.","title":"Warming tutorial"},{"location":"basics/#description","text":"In ISP we have decided go for miniseed format, with is one of the most broadly used data storage formats for seismograms. The best description is given at mseed which is simply: MiniSEED is the subset of the SEED standard that is used for time series data. Very limited metadata for the time series is included in miniSEED beyond time series identification and simple state-of-health flags. In particular, geographic coordinates, response/scaling information and other information needed to interpret the data values are not included. Time series are stored as generally independent, fixed length data records which each contain a small segment of contiguous series values. A reader of miniSEED is required to reconstruct longer, contiguous time series from the data record segments. Common record lengths are 512-byte (for real time streams) and 4096-byte (for archiving), other record lengths are used for special scenarios. A \u201cfile\u201d or \u201cstream\u201d of miniSEED is simply a concatenation of data records. Depending on the capabilities of the intended reader the data records for multiple channels of data may be multiplexed together.","title":"Description"},{"location":"basics/#project-seismograms-and-metadata","text":"","title":"Project: Seismograms and metadata"},{"location":"basics/#create-a-project-from-seismogram-files","text":"We start explaining how to start a project inside Earthquake Analysis module (more details inside sections). First of all you need to create a project. A project is basically a \"dictionary file\" that tells your computer where are your valid data. This strategy makes easier to explore your big data. Now, let's create a new project pressing the button \"New Project\" You will find this dialog that will guide you to crete the project. Two option: Create Project from individual files, you will select individual files that going to be part of your project. Create Full Project, you give the path to the folder tree where you have your daily data files. ISP will scan all folders validating the files and will create the project. Afterwards, you can save your project (recommended) giving a name and press \"Saving Project\". Becareful, when you start to create a project ISP will capture the search filters, so for example if in the Project Box Channels is selected \"BHZ\" as in the picture below, the project will created based on this filters- If you do not want any filter set the filter bocxes empty Filters boxes uses Regex and Python keywords : For example, if ypu want search any component in channels \"BH.\" or if you want any station but verical component station \".+\" channel BHZ. Very important, you can reload your project aplying searching filters simply by pressing \"r\" outside the plot window. This action also takes into account if trim is checked to cut the time window. This is very useful to search for specific time windows where you already knows in advance that there is an event there.","title":"Create a Project from seismogram files"},{"location":"basics/#project-video-tutorial","text":"The following video shows how to create a project, make searches by wildcards and how to search by specific time windows.","title":"Project Video Tutorial"},{"location":"basics/#metadata-dataless-and-xml","text":"ISP uses two kind of metadata files either Dataless or xml. ( https://docs.obspy.org/tutorial/code_snippets/stationxml_file_from_scratch.html ). You can find an example of this files at the folders isp/Metadata/dataless and isp/Metadata/xml. As you will see, in the this files there is information structured as a dictionary nets/stations/channels. Personally, the best way to make your own metadata file is using either the java software PDCC or going to the API Station Management Portal . Important : The idea in ISP is that your Metadata file (one single file) contains all of the information (such as coordinates of your stations, instrument response, sampling frequency and so on ...) of the miniseed files you are going to manage. The reason of this design is that, it is easier to programming something that works independently from the miniseed file to metadata. For example when sorting the minified files from respect to an event. The software internally reads the name of all of your files (in the header) and then match this info with the metadata file. Notes : It is very easy using python to convert your dataless to xml. From: https://docs.obspy.org/_modules/obspy/core/inventory/inventory.html#Inventory.write from obspy import read_inventory inv = read_inventory(\"path_to_your_dataless\") inv.write(path_or_file_object, format=\"stationxml\", validate=True)","title":"Metadata (Dataless and *.xml)"},{"location":"db/","text":"Database The Database sub-module is designed to incorporate all the results you can obtain from Earthquake location and Moment Tensor Inversion. It is possible to make queries to the data base, for example searching earthquake locations by a geographic frame or in a specific time spam. Moreover you can plot the results of your query in a map. Visual Options Double Clik near an epicenter in the map and it will be hilighted the corresponding row in the table. Double Click in a epicenter in the table and (if here is MTI information) it will be plot the beachball in the map Click with right button in a table row and select highlight event to visualize the exact event in the map. Click with right button to get the phases information corresponding to the selected event Populate your DB Pick in File/Read Hyp Folder to incorporate all information contained inside hyp folders. Hyp folders are the file output from location. Pick in File/Magnitudes to populate your database with the information from the output file obtained in source toolbox. Pick in File/MTI to populate your database with the information from the output file obtained in MTI toolbox. Make a Query Choose the options on the left widget to filter the hypocenter inside your DataBase. The earthquakes shown in the table can be used in the MTI GUI when runs the inversion.","title":"Database"},{"location":"db/#database","text":"The Database sub-module is designed to incorporate all the results you can obtain from Earthquake location and Moment Tensor Inversion. It is possible to make queries to the data base, for example searching earthquake locations by a geographic frame or in a specific time spam. Moreover you can plot the results of your query in a map.","title":"Database"},{"location":"db/#visual-options","text":"Double Clik near an epicenter in the map and it will be hilighted the corresponding row in the table. Double Click in a epicenter in the table and (if here is MTI information) it will be plot the beachball in the map Click with right button in a table row and select highlight event to visualize the exact event in the map. Click with right button to get the phases information corresponding to the selected event","title":"Visual Options"},{"location":"db/#populate-your-db","text":"Pick in File/Read Hyp Folder to incorporate all information contained inside hyp folders. Hyp folders are the file output from location. Pick in File/Magnitudes to populate your database with the information from the output file obtained in source toolbox. Pick in File/MTI to populate your database with the information from the output file obtained in MTI toolbox.","title":"Populate your DB"},{"location":"db/#make-a-query","text":"Choose the options on the left widget to filter the hypocenter inside your DataBase. The earthquakes shown in the table can be used in the MTI GUI when runs the inversion.","title":"Make a Query"},{"location":"el/","text":"Earthquake Location The module Earthquake analysis allows you to analyse waveforms, polarization analysis of seismograms 3-components, calculate earthquake source parameters, locate an event and estimate the focal mechanisms (First Polarity). We will walk through all of the functionality following this scheme: Event Analysis From top to bottom in the left side of the window you will see: Event Info : This small box let enter information about an event, in this way you can plot the theoretical arrivals (ak-135F) with respect your seismograms, clicking the button Plot Arrivals. Plot arrivals requires that you have correctly loaded your metadata. You can also Plot the record section, seismograms sorted according to the distance and ploting the theretical arrivals. Inside File > Open Settings, you can select wich phases you want to plot. In case you want select all arrivals, type \"ALL\" in the Settings box. Metadata File : By clicking in this button you will place the path to you metadata file. The metadata file must contain the information of all of the stations seismograms you want to analyse (metadata must be a xml or dlsv). Start Time and End Time : The time boxes can be selected checking \u201cTrim Time\u201d. If you choose this option all the seismograms will be cut in accordance with the selected time window. Use the shortcuts \"Q\" and \"E\" to set over the plot automatically the trim stat time and endtime. Stations Info : will deploy a table with the fundamental information of the seismograms. Phase box : This combo box allow the selection of specific phases for picking it in the seismograms. Waves box : You can choose Body, surface, coda or noise. With this selected you can highlight a time window of the seismogram for further analysis. The selection are saved inside a dictionary that can be directly used running your own script. See run script to see details. Net, Station and Channel : You can fill this boxes (also using wildcards such as * or BH?) to select specific files from your files folder (check \u201cselect files\u201d). Stations Map : will show you the location of the stations that corresponds to the seismograms of your folder. The seismograms metadata must match with the metadata information. Rotate : This option will rotate all your station - 3 components (channels must be named N,E,Z) to the Great Arc Circle taking the reference the data of Event info tab. Check \"Use this Ang\" to rotate the components a specific angle. Cross : This button will compute the cross-correlation (cc) or the autocorrelation of all processed seismograms with respect the reference \u201cRef\u201d, the number of the seismogram from top to bottom. Process and Plot : This action will read the seismograms from the database of paths to your seismograms, created from your folder tree (database already built using Read Files) and will carry out the processing from the established \u201cMACRO\u201d. Further details in MACRO section \"Macros\". Particle Motion : This action will plor the particle motion from your vertical and N,E or R,T components. This actions works when you have this three waveforms on screen and are trimed. The sam actioon can be also done in the module Polarization Analysis. Run Script : This is on of the most important actions. Basically it runs a python script that you can have storaged at ISP/isp/scripts/your_scriptX.py. The name of the script is up to you however, you might edit the init .py. For example imagine you want to run from ISP your_script1.py. First step edit the ISP/isp/scripts/ init .py: from .your_script1 import run_process Second step the fill the folder with the script you want to run: The structure of this folder ISP/isp/scripts is as follows: __init__.py your_script1.py Here you can set which script you want to edit by changing \".your_script1\" Inside ISP/isp/scripts/script.py you will find an example ready to run by clicking Run Script button. In this example, the action will take the waveform 1 and waveform 2 from the stream ObsPy object and will add their data. Then, the wavform will be plot in a separate window. Of course this two traces must have the same numer of samples!. #!/usr/bin/env python # -*- coding: utf-8 -*- \"\"\" script.py \"\"\" from obspy import Stream, UTCDateTime import matplotlib.pyplot as plt import matplotlib matplotlib.use('Qt5Agg') def run_process(st: Stream, chop: dict, starttime: UTCDateTime, endtime: UTCDateTime, hypo_lat: float, hypo_lon: float, hypo_depth_km: float, hypo_origin_time: UTCDateTime): \"\"\" example of how to design your running script chop = {'Body waves': {}, 'Surf Waves': {}, 'Coda': {}, 'Noise': {}}: dict id = {id: [metadata, t, s, xmin_index, xmax_index, t_start_utc, t_end_utc]} metadata = [dic_metadata['net'], dic_metadata['station'], dic_metadata['location'], dic_metadata['channel'], dic_metadata['starttime'], dic_metadata['endtime'], dic_metadata['sampling_rate'], dic_metadata['npts']] # example of chop_full_dict_input = {'Body waves':{\"WM.SFS..HHZ\": [[WM, SFS,,HHZ,...], time_amplitudes, amplitudes,... \"\"\" try: data = st[0].data + st[1].data fig, ax1 = plt.subplots(1, 1, layout='constrained') ax1.plot(st[0].times(), data) ax1.set_xlabel('Time (s)') ax1.set_ylabel('Trace1 + Trace') ax1.grid(True) plt.show() except Exception as e: # Handle any exception and print the error message print(\"An error occurred:\", str(e)) Important details: The only constrain is that the method must be always named run_process and must have the the same inputs of the example. All inputs are taken from the main Earthquake Location GUI and can be used or not. Additional options from the toolbar are: File File: Project will open the box to assist you in managing a project (load or create a new project). File: New location will clean the picks that are saved automatically for be ready to compute new picking/location. File: Write Files will write in the folder you select the processed seismograms. The seismograms will be saved in mseed format. Moreove, you can write mseed files containing the Charachteristic Functions such as STA/LTA, Cross Correlations or the stack. File: Open Settings will open a window with the specific parameters of the subprocess that you can carry out in this module (sta/lta, wavelet detection, entropy, plor record section phases). Actions Actions: Open Picks will open the file with the information of your picks. You can also open the file from here. Shortcut \"Ctr + u\". Picks are saved in ISP/isp/earthquakeAnalysis/location_output/obs/output.txt Actions: Picks Remove will clean the pick file. Station_name Instrument Component P_phase_onset P_phase_descriptor First_Motion Date Hour_min Seconds GAU Err Coda_duration Amplitude Period PMG ? BHZ ? P ? 20221018 1150 24.693 GAU 0.00E+00 0.0 -3024.00 0.0 Actions: Macro will deploy a window with all of the processing options. All of the processing options will be applied once you press the button Processing and Plot. Action: Clean Events Detected will clean the events associated in the coincidence trigger or events associator. This events are obtained after picking in Auto pick / associate. Action: Data availability will plot the data availability (backlines) for each station/component of your project. Action: Concatenate Waveforms will automatically concatenate waveforms with the same net, station and channel name from different days. This is specially useful to analyze waveforms from teleseismic events splited in two different files. Action: Search in Catalog (see the figure below) is a widget designed to plot your catalog and select an event to search in your project. The catalog can be either a csv file with this header (example below) or a catalog with an specific file formats such as QUAKEML , SC3ML , CMTSOLUTION and so on. To facilitate the selection of events, the user can press \"t\" over the epicenter in the map to hilight it in the table. Finally, Pressing button \"Select Event\" the information is sent to the trim starttime and endtime and to the Event Box. Ready to filter your project to make the search of the event and show your waveforms! You can find an example in isp/examples/catalog. See the video Date;Time;Latitude;Longitude;Depth;Magnitude;mag_type 01/01/2007;02:03:03;34.9608;-4.0459;12.0;2.6;Mw Compute Compute: STA/LTA from all processed seismograms and will plot the result together. STA/LTA takes the parameters from Parameters Settings. Compute: CWT (CF) from all processed seismograms and will plot the result together. CWT takes the parameters from Parameters Settings. Compute: Envelope from all processed seismograms and will plot the result together. Compute: Spectral Entropy from all processed seismograms and will plot the result together. Spectral entropy is estimated in small time windows see Parameters Settings. Compute: All Seismograms : Plot together all seismograms. Compute: Stack run (linear, nth-root or PWS) stack of all processed seismograms. Set your choice in File/Open Settings. Compute: Plot Record Section will plot the waveforms according to distance and will also plot the travel times. This action is available just when you have process and plot your waveforms and sorted by distance. Be careful, you need a correct metadata file loaded and also the event info box corretly filled. This action could take some time. Go Will ship you to the rest of ISP modules (Array analysis, Moment Tensor Inversion, Time-Frequency and RFs mudules). By clicking on one of this module you will send the information of the seismograms and metadata to the other modules. Please see Array analysis and Moment Tensor for further details and examples. For xample, If you press letter \"m\" over a seismogram, then you can click on the TF module picture to analyse the selected waveform in the tf plane. Go to Connect with Earthquake Analysis , for a fully explanation an example. Align Traces Align Traces: From Phase Pick will align the trace with respect the picks of the selected phase in the phase box. For example, this can be very useful to align the first arriaval, let's say P-wave of an event for all traces. Align Traces: From Starttime will set the same starttime to all traces. This is useful if you want to compare seismograms from different days. Align Traces: Using MCCC Multi Channel Cross Correlation technicque to find the best way to align all traces. This technique is very efficient when the user expect high coherence between waveforms. For example teleseismic events, or events detected in a coherent array. Selections Action: Clean Selection will remove an specific seismogram time window selection, such as Body wave, see the combo box selected and will delete from the selections. Action: Remove all selections Import Import: Picks from file It will plot the picks from selected file in the corresponding waveforms. The picks from the file that the user select must be in the ISP/NLL format as it is shown above Actions:Picks. Shortcuts Eartuqake analysis module keywords and mouse shortcuts. Generally there are shortcuts to be used inside plots and ohter shortcuts to be used to run actions. Polarisation Analysis The Polarization Analysis is designed to analyze the three seismograms components from a station. You can freely rotate using the rotation RT or the LQT your NEZ components an angle (Rot Angle) with an Incidence angle (Inc Angle). The Particle motion of the processed seismogram is view clicking in \u201cPlot Polarization\u201d. This option will plot all the time window in a 3D view and in three 2D plot views. If you want to make a sliding window analysis of the polarization press \u201cPolarization Analysis\u201d. This will carry out a polarization analysis on windows length and frequency bandwidth specified by the user over the full analyzed seismogram. For a full particle motion analysis, press \u201cPlot Polarization\u201d. This will open another window with a 3D particle motion on the left and the three characteristic views on the right. Event Location In the Event Location Frame the user can configure the velocity grid 1D/3D model, locate earthquakes and compute Focal Mechanisms. Grid Reference : First it is needed to set a Velocity grid framework (Grid reference and transformation type are mandatory). For now is only available Transformation Simple and Global. Grid Size : Next, the Grid dimensions (Grid Size). Case 1D the dimension in the x coordinate always must be 2 and the grid reference is refered to the corner SW. Case 3D the grid reference is the center of the Grid. Choose the grid type and the wave and then generate the velocity model binary files by clicking \u201cGenerate Velocity Grid\u201d. Please follow the scheme of the next figure to set correctly your 3D grid frame. For example, First the user would place the center of the grid in case you want the center of a 1D grid: Grid reference 34.0 Latitude, -14.0 Longitude and -1 (1 km in topography). Grid Size x = 2 (always) dx = 1, y = 2000 dy =1 and z = 200 dz = 1. Tha means an aproximate square region of radio 2000x2000x150 km with the reference at (34,-14,-1). Second, for the 3D case, the user must set the Grid reference also 37.0 Latitude, -9.0 Longitude and -1 (1 km in topography), but the Grid Size is refered to the distance from the grid reference. So, for example, Grid Size x = 881 dx = 1, y = 661 dy =1 and z = 61 dz = 1. This means a grid centered at 37.0,-9.0,-1.0 with a extension of diameter (881,661,60), see image below. Once the binary files are generated you can check the results in the folder: ISP/earthquakeAnalysis/location_output/model Where and how place the velocity 1D model?: isp/earthquakeAnalysis/location_output/local_models 1D models (see example): For the P-wave the file must named modelP and for the S-wave \"modelS\" LAYER 0.0 6.1 0.0 3.49 0.0 2.7 0.0 LAYER 11.0 6.4 0.0 3.66 0.0 2.7 0.0 LAYER 24.0 6.9 0.0 3.94 0.0 2.7 0.0 LAYER 31.0 8.0 0.0 4.57 0.0 2.7 0.0 LAYER .... ... ... .... ... ... ... Where and how place the velocity 3D model?: isp/earthquakeAnalysis/location_output/model3D We have created a repository with an example of 3D model Every depth layer must be placed in files called, for example For the P wave --> layer.P.mod5.mod For the S wave --> layer.S.mod5.mod Which means that inside this file there is the grid for the layer at depth 5km. The layer must be a matrix with the values in the rows from top to bottom S to N and from left to right E to W. That's mean following the next example that the file corresponding to a depth layer 5km \"layer.P.mod5.mod\" could be like this: 4.5759 4.5735 4.5707 4.5677 4.5760 4.5755 4.5766 4.5670 ...... ...... ...... ...... 4.6800 4.650 4.67300 4.5678 This matrix means that, for example corresponds to geographic points (separated in cells of, dx dy of 0.5 x 0.5 degrees: Warning grid cells must be [dx = dy = dz] for a correct interpretation. (-10.0,34) (-9.5,34) (-9.0,34) (-8.5,34) (-10.0,34.5) (-9.5,34.5) (-9.0,34.5) (-8.5,34.5) ........ ......... ......... ......... (-10.0,40.0) (-9.5,40.0) (-9.0,40.0) (-8.5,40.0) The most important step is to generate the travel-times for all the stations inside the maximum distance the user determine. Please be sure that you have load previously the metadata (this is necessary to associate your picks with your station coordinates). The generated travel-times will save in ISP/earthquakeAnalysis/location_output/time , for example with the following name \"layer.P.EBAD.time.buf\" Once you have complete the above steps you can locate the earthquake and the focal mechanism. The above operation are just necessary to be implemented the first time you use a specific Earth model. For global is not necessary generate the velocity grid and travel times . To visualize the detailed Probability Density Function, press \u201cPlot PDF\u201d, once you have already carried out the location. The Earth Model Viewer is intended to help to visualize 3D Earth velocity models as in the figure below. Just select the binary file *.buf (can be generated from the model as described in previous section). Next, select the depth of the layer, the cross sections in longitude and latitude and the press plot. Moreover, if you have picked the seismic phases and have been designated the polarity in \u201cEvent frame\u201d , you will be able to obtain the Focal Mechanism (it uses the subprogram FocMec) Focal Mechanism - First Polarity The run script that manage FocMec behind ISP is in the file ./isp/EartuqakeAnalysis/location_output/first_polarity/focmec_run . mechanism.out No comments \\* Comment is previous line: Input file for focmec is next test.inp y Use emergent arrivals? [y] correct file [y] y relative weighting..[y] 0.0 allowed P polarity erors..[0] 100 exit after this many acceptable solutions...[100] minimum B trend [0] B increment [5] maximum B trend [355] min B plunge..[0] increment [5] maximum..[90] minimum Angle..[0] increment [5] maximum [175] Indeed what is most important is to play with the value \"allowed P polarity erors\", by default set to 0.0. Spectral Analysis - Source Parameters Moment Magnitude This module is based on SourceSpec v1.7 and it uses the location storaged in the folder Loc Folder (hyp files) to estimate the event source parameters (seismic moment, corner frequency, radiated energy, source size, static stress drop, apparent stress). The configuration file that ISP points to is placed at: ISP/isp/source_spec_parse/config/source_spec.conf The user can modify the configuration as well as the GUI (below) entry points from ISP. Complementary Magnitudes (work in progress): With the Magnitude Estimation you can calculate): Body-wave ( mb ), Surface-wave ( Ms ) and Coda Magnitude ( Mc ). Phase Picking and Associator The Picking algorythm of ISP/surfQuake uses the Deep Neural Network of Phasenet ( Zhu and Beroza, 2019 ) to estimate the arrival times of P- and S-wave. The arrival times are saved as a csv file and in daily folders to be ready to be used by the associator. Example of csv header: date,fname,year,month,day,net,station,flag,tt,date_time,weight,amplitude,phase 20220131,CA.ARBS.P,2022,1,31,CA,ARBS,1,39383.88,2022-01-31T10:56:23.880000,0.53,8557892.7,P 20220131,CA.ARBS.S,2022,1,31,CA,ARBS,1,85480.59,2022-01-31T23:44:40.590000,0.30,8481788.2,S Be sure you have just created a Project or you have loaded one. Then click on Run Auto Pick . This action will start the phase picker and will save the output in Output Directory ready to be used in the associator toolbox and original_picks as csv file for direct reading. After the picking is done, you can optionally run the automatic First Polarity determination. tis will run a deep neural network PolarCap and will edit the picking file with the First Polarity results. Neural Network for picking and First Polarity Multimedia Material Seismogram Analysis Updated The following video shows summarize how to manage the basic waveform processing Explore your Catalog Updated The following video shows a user loading a project, then explores the project using the fast decimation. In the second parte, the user opens a catalog, selects and event and send the information to the main window. Finally filters the project by time and process and plot to see the event wavefroms. Please go to Start with the Basics --> Shorcuts --> Mouse . Manual Pick, Locate Event, Fault Plane and Magnitude Updated The following video shows a user loading a project, then automatically picking phases plus polarity. Please go to Start with the Basics --> Shorcuts --> Mouse . Automatic Picking and Associate Updated The following video shows a user loading a project, then automatically picking phases plus polarity. Please go to Start with the Basics --> Shorcuts --> Mouse .","title":"Earthquake Location"},{"location":"el/#earthquake-location","text":"The module Earthquake analysis allows you to analyse waveforms, polarization analysis of seismograms 3-components, calculate earthquake source parameters, locate an event and estimate the focal mechanisms (First Polarity). We will walk through all of the functionality following this scheme:","title":"Earthquake Location"},{"location":"el/#event-analysis","text":"From top to bottom in the left side of the window you will see: Event Info : This small box let enter information about an event, in this way you can plot the theoretical arrivals (ak-135F) with respect your seismograms, clicking the button Plot Arrivals. Plot arrivals requires that you have correctly loaded your metadata. You can also Plot the record section, seismograms sorted according to the distance and ploting the theretical arrivals. Inside File > Open Settings, you can select wich phases you want to plot. In case you want select all arrivals, type \"ALL\" in the Settings box. Metadata File : By clicking in this button you will place the path to you metadata file. The metadata file must contain the information of all of the stations seismograms you want to analyse (metadata must be a xml or dlsv). Start Time and End Time : The time boxes can be selected checking \u201cTrim Time\u201d. If you choose this option all the seismograms will be cut in accordance with the selected time window. Use the shortcuts \"Q\" and \"E\" to set over the plot automatically the trim stat time and endtime. Stations Info : will deploy a table with the fundamental information of the seismograms. Phase box : This combo box allow the selection of specific phases for picking it in the seismograms. Waves box : You can choose Body, surface, coda or noise. With this selected you can highlight a time window of the seismogram for further analysis. The selection are saved inside a dictionary that can be directly used running your own script. See run script to see details. Net, Station and Channel : You can fill this boxes (also using wildcards such as * or BH?) to select specific files from your files folder (check \u201cselect files\u201d). Stations Map : will show you the location of the stations that corresponds to the seismograms of your folder. The seismograms metadata must match with the metadata information. Rotate : This option will rotate all your station - 3 components (channels must be named N,E,Z) to the Great Arc Circle taking the reference the data of Event info tab. Check \"Use this Ang\" to rotate the components a specific angle. Cross : This button will compute the cross-correlation (cc) or the autocorrelation of all processed seismograms with respect the reference \u201cRef\u201d, the number of the seismogram from top to bottom. Process and Plot : This action will read the seismograms from the database of paths to your seismograms, created from your folder tree (database already built using Read Files) and will carry out the processing from the established \u201cMACRO\u201d. Further details in MACRO section \"Macros\". Particle Motion : This action will plor the particle motion from your vertical and N,E or R,T components. This actions works when you have this three waveforms on screen and are trimed. The sam actioon can be also done in the module Polarization Analysis. Run Script : This is on of the most important actions. Basically it runs a python script that you can have storaged at ISP/isp/scripts/your_scriptX.py. The name of the script is up to you however, you might edit the init .py. For example imagine you want to run from ISP your_script1.py. First step edit the ISP/isp/scripts/ init .py: from .your_script1 import run_process Second step the fill the folder with the script you want to run: The structure of this folder ISP/isp/scripts is as follows: __init__.py your_script1.py Here you can set which script you want to edit by changing \".your_script1\" Inside ISP/isp/scripts/script.py you will find an example ready to run by clicking Run Script button. In this example, the action will take the waveform 1 and waveform 2 from the stream ObsPy object and will add their data. Then, the wavform will be plot in a separate window. Of course this two traces must have the same numer of samples!. #!/usr/bin/env python # -*- coding: utf-8 -*- \"\"\" script.py \"\"\" from obspy import Stream, UTCDateTime import matplotlib.pyplot as plt import matplotlib matplotlib.use('Qt5Agg') def run_process(st: Stream, chop: dict, starttime: UTCDateTime, endtime: UTCDateTime, hypo_lat: float, hypo_lon: float, hypo_depth_km: float, hypo_origin_time: UTCDateTime): \"\"\" example of how to design your running script chop = {'Body waves': {}, 'Surf Waves': {}, 'Coda': {}, 'Noise': {}}: dict id = {id: [metadata, t, s, xmin_index, xmax_index, t_start_utc, t_end_utc]} metadata = [dic_metadata['net'], dic_metadata['station'], dic_metadata['location'], dic_metadata['channel'], dic_metadata['starttime'], dic_metadata['endtime'], dic_metadata['sampling_rate'], dic_metadata['npts']] # example of chop_full_dict_input = {'Body waves':{\"WM.SFS..HHZ\": [[WM, SFS,,HHZ,...], time_amplitudes, amplitudes,... \"\"\" try: data = st[0].data + st[1].data fig, ax1 = plt.subplots(1, 1, layout='constrained') ax1.plot(st[0].times(), data) ax1.set_xlabel('Time (s)') ax1.set_ylabel('Trace1 + Trace') ax1.grid(True) plt.show() except Exception as e: # Handle any exception and print the error message print(\"An error occurred:\", str(e)) Important details: The only constrain is that the method must be always named run_process and must have the the same inputs of the example. All inputs are taken from the main Earthquake Location GUI and can be used or not. Additional options from the toolbar are: File File: Project will open the box to assist you in managing a project (load or create a new project). File: New location will clean the picks that are saved automatically for be ready to compute new picking/location. File: Write Files will write in the folder you select the processed seismograms. The seismograms will be saved in mseed format. Moreove, you can write mseed files containing the Charachteristic Functions such as STA/LTA, Cross Correlations or the stack. File: Open Settings will open a window with the specific parameters of the subprocess that you can carry out in this module (sta/lta, wavelet detection, entropy, plor record section phases). Actions Actions: Open Picks will open the file with the information of your picks. You can also open the file from here. Shortcut \"Ctr + u\". Picks are saved in ISP/isp/earthquakeAnalysis/location_output/obs/output.txt Actions: Picks Remove will clean the pick file. Station_name Instrument Component P_phase_onset P_phase_descriptor First_Motion Date Hour_min Seconds GAU Err Coda_duration Amplitude Period PMG ? BHZ ? P ? 20221018 1150 24.693 GAU 0.00E+00 0.0 -3024.00 0.0 Actions: Macro will deploy a window with all of the processing options. All of the processing options will be applied once you press the button Processing and Plot. Action: Clean Events Detected will clean the events associated in the coincidence trigger or events associator. This events are obtained after picking in Auto pick / associate. Action: Data availability will plot the data availability (backlines) for each station/component of your project. Action: Concatenate Waveforms will automatically concatenate waveforms with the same net, station and channel name from different days. This is specially useful to analyze waveforms from teleseismic events splited in two different files. Action: Search in Catalog (see the figure below) is a widget designed to plot your catalog and select an event to search in your project. The catalog can be either a csv file with this header (example below) or a catalog with an specific file formats such as QUAKEML , SC3ML , CMTSOLUTION and so on. To facilitate the selection of events, the user can press \"t\" over the epicenter in the map to hilight it in the table. Finally, Pressing button \"Select Event\" the information is sent to the trim starttime and endtime and to the Event Box. Ready to filter your project to make the search of the event and show your waveforms! You can find an example in isp/examples/catalog. See the video Date;Time;Latitude;Longitude;Depth;Magnitude;mag_type 01/01/2007;02:03:03;34.9608;-4.0459;12.0;2.6;Mw Compute Compute: STA/LTA from all processed seismograms and will plot the result together. STA/LTA takes the parameters from Parameters Settings. Compute: CWT (CF) from all processed seismograms and will plot the result together. CWT takes the parameters from Parameters Settings. Compute: Envelope from all processed seismograms and will plot the result together. Compute: Spectral Entropy from all processed seismograms and will plot the result together. Spectral entropy is estimated in small time windows see Parameters Settings. Compute: All Seismograms : Plot together all seismograms. Compute: Stack run (linear, nth-root or PWS) stack of all processed seismograms. Set your choice in File/Open Settings. Compute: Plot Record Section will plot the waveforms according to distance and will also plot the travel times. This action is available just when you have process and plot your waveforms and sorted by distance. Be careful, you need a correct metadata file loaded and also the event info box corretly filled. This action could take some time. Go Will ship you to the rest of ISP modules (Array analysis, Moment Tensor Inversion, Time-Frequency and RFs mudules). By clicking on one of this module you will send the information of the seismograms and metadata to the other modules. Please see Array analysis and Moment Tensor for further details and examples. For xample, If you press letter \"m\" over a seismogram, then you can click on the TF module picture to analyse the selected waveform in the tf plane. Go to Connect with Earthquake Analysis , for a fully explanation an example. Align Traces Align Traces: From Phase Pick will align the trace with respect the picks of the selected phase in the phase box. For example, this can be very useful to align the first arriaval, let's say P-wave of an event for all traces. Align Traces: From Starttime will set the same starttime to all traces. This is useful if you want to compare seismograms from different days. Align Traces: Using MCCC Multi Channel Cross Correlation technicque to find the best way to align all traces. This technique is very efficient when the user expect high coherence between waveforms. For example teleseismic events, or events detected in a coherent array. Selections Action: Clean Selection will remove an specific seismogram time window selection, such as Body wave, see the combo box selected and will delete from the selections. Action: Remove all selections Import Import: Picks from file It will plot the picks from selected file in the corresponding waveforms. The picks from the file that the user select must be in the ISP/NLL format as it is shown above Actions:Picks.","title":"Event Analysis"},{"location":"el/#shortcuts","text":"Eartuqake analysis module keywords and mouse shortcuts. Generally there are shortcuts to be used inside plots and ohter shortcuts to be used to run actions.","title":"Shortcuts"},{"location":"el/#polarisation-analysis","text":"The Polarization Analysis is designed to analyze the three seismograms components from a station. You can freely rotate using the rotation RT or the LQT your NEZ components an angle (Rot Angle) with an Incidence angle (Inc Angle). The Particle motion of the processed seismogram is view clicking in \u201cPlot Polarization\u201d. This option will plot all the time window in a 3D view and in three 2D plot views. If you want to make a sliding window analysis of the polarization press \u201cPolarization Analysis\u201d. This will carry out a polarization analysis on windows length and frequency bandwidth specified by the user over the full analyzed seismogram. For a full particle motion analysis, press \u201cPlot Polarization\u201d. This will open another window with a 3D particle motion on the left and the three characteristic views on the right.","title":"Polarisation Analysis"},{"location":"el/#event-location","text":"In the Event Location Frame the user can configure the velocity grid 1D/3D model, locate earthquakes and compute Focal Mechanisms. Grid Reference : First it is needed to set a Velocity grid framework (Grid reference and transformation type are mandatory). For now is only available Transformation Simple and Global. Grid Size : Next, the Grid dimensions (Grid Size). Case 1D the dimension in the x coordinate always must be 2 and the grid reference is refered to the corner SW. Case 3D the grid reference is the center of the Grid. Choose the grid type and the wave and then generate the velocity model binary files by clicking \u201cGenerate Velocity Grid\u201d. Please follow the scheme of the next figure to set correctly your 3D grid frame. For example, First the user would place the center of the grid in case you want the center of a 1D grid: Grid reference 34.0 Latitude, -14.0 Longitude and -1 (1 km in topography). Grid Size x = 2 (always) dx = 1, y = 2000 dy =1 and z = 200 dz = 1. Tha means an aproximate square region of radio 2000x2000x150 km with the reference at (34,-14,-1). Second, for the 3D case, the user must set the Grid reference also 37.0 Latitude, -9.0 Longitude and -1 (1 km in topography), but the Grid Size is refered to the distance from the grid reference. So, for example, Grid Size x = 881 dx = 1, y = 661 dy =1 and z = 61 dz = 1. This means a grid centered at 37.0,-9.0,-1.0 with a extension of diameter (881,661,60), see image below. Once the binary files are generated you can check the results in the folder: ISP/earthquakeAnalysis/location_output/model Where and how place the velocity 1D model?: isp/earthquakeAnalysis/location_output/local_models 1D models (see example): For the P-wave the file must named modelP and for the S-wave \"modelS\" LAYER 0.0 6.1 0.0 3.49 0.0 2.7 0.0 LAYER 11.0 6.4 0.0 3.66 0.0 2.7 0.0 LAYER 24.0 6.9 0.0 3.94 0.0 2.7 0.0 LAYER 31.0 8.0 0.0 4.57 0.0 2.7 0.0 LAYER .... ... ... .... ... ... ... Where and how place the velocity 3D model?: isp/earthquakeAnalysis/location_output/model3D We have created a repository with an example of 3D model Every depth layer must be placed in files called, for example For the P wave --> layer.P.mod5.mod For the S wave --> layer.S.mod5.mod Which means that inside this file there is the grid for the layer at depth 5km. The layer must be a matrix with the values in the rows from top to bottom S to N and from left to right E to W. That's mean following the next example that the file corresponding to a depth layer 5km \"layer.P.mod5.mod\" could be like this: 4.5759 4.5735 4.5707 4.5677 4.5760 4.5755 4.5766 4.5670 ...... ...... ...... ...... 4.6800 4.650 4.67300 4.5678 This matrix means that, for example corresponds to geographic points (separated in cells of, dx dy of 0.5 x 0.5 degrees: Warning grid cells must be [dx = dy = dz] for a correct interpretation. (-10.0,34) (-9.5,34) (-9.0,34) (-8.5,34) (-10.0,34.5) (-9.5,34.5) (-9.0,34.5) (-8.5,34.5) ........ ......... ......... ......... (-10.0,40.0) (-9.5,40.0) (-9.0,40.0) (-8.5,40.0) The most important step is to generate the travel-times for all the stations inside the maximum distance the user determine. Please be sure that you have load previously the metadata (this is necessary to associate your picks with your station coordinates). The generated travel-times will save in ISP/earthquakeAnalysis/location_output/time , for example with the following name \"layer.P.EBAD.time.buf\" Once you have complete the above steps you can locate the earthquake and the focal mechanism. The above operation are just necessary to be implemented the first time you use a specific Earth model. For global is not necessary generate the velocity grid and travel times . To visualize the detailed Probability Density Function, press \u201cPlot PDF\u201d, once you have already carried out the location. The Earth Model Viewer is intended to help to visualize 3D Earth velocity models as in the figure below. Just select the binary file *.buf (can be generated from the model as described in previous section). Next, select the depth of the layer, the cross sections in longitude and latitude and the press plot. Moreover, if you have picked the seismic phases and have been designated the polarity in \u201cEvent frame\u201d , you will be able to obtain the Focal Mechanism (it uses the subprogram FocMec)","title":"Event Location"},{"location":"el/#focal-mechanism-first-polarity","text":"The run script that manage FocMec behind ISP is in the file ./isp/EartuqakeAnalysis/location_output/first_polarity/focmec_run . mechanism.out No comments \\* Comment is previous line: Input file for focmec is next test.inp y Use emergent arrivals? [y] correct file [y] y relative weighting..[y] 0.0 allowed P polarity erors..[0] 100 exit after this many acceptable solutions...[100] minimum B trend [0] B increment [5] maximum B trend [355] min B plunge..[0] increment [5] maximum..[90] minimum Angle..[0] increment [5] maximum [175] Indeed what is most important is to play with the value \"allowed P polarity erors\", by default set to 0.0.","title":"Focal Mechanism - First Polarity"},{"location":"el/#spectral-analysis-source-parameters","text":"","title":"Spectral Analysis - Source Parameters"},{"location":"el/#moment-magnitude","text":"This module is based on SourceSpec v1.7 and it uses the location storaged in the folder Loc Folder (hyp files) to estimate the event source parameters (seismic moment, corner frequency, radiated energy, source size, static stress drop, apparent stress). The configuration file that ISP points to is placed at: ISP/isp/source_spec_parse/config/source_spec.conf The user can modify the configuration as well as the GUI (below) entry points from ISP. Complementary Magnitudes (work in progress): With the Magnitude Estimation you can calculate): Body-wave ( mb ), Surface-wave ( Ms ) and Coda Magnitude ( Mc ).","title":"Moment Magnitude"},{"location":"el/#phase-picking-and-associator","text":"The Picking algorythm of ISP/surfQuake uses the Deep Neural Network of Phasenet ( Zhu and Beroza, 2019 ) to estimate the arrival times of P- and S-wave. The arrival times are saved as a csv file and in daily folders to be ready to be used by the associator. Example of csv header: date,fname,year,month,day,net,station,flag,tt,date_time,weight,amplitude,phase 20220131,CA.ARBS.P,2022,1,31,CA,ARBS,1,39383.88,2022-01-31T10:56:23.880000,0.53,8557892.7,P 20220131,CA.ARBS.S,2022,1,31,CA,ARBS,1,85480.59,2022-01-31T23:44:40.590000,0.30,8481788.2,S Be sure you have just created a Project or you have loaded one. Then click on Run Auto Pick . This action will start the phase picker and will save the output in Output Directory ready to be used in the associator toolbox and original_picks as csv file for direct reading. After the picking is done, you can optionally run the automatic First Polarity determination. tis will run a deep neural network PolarCap and will edit the picking file with the First Polarity results.","title":"Phase Picking and Associator"},{"location":"el/#neural-network-for-picking-and-first-polarity","text":"","title":"Neural Network for picking and First Polarity"},{"location":"el/#multimedia-material","text":"","title":"Multimedia Material"},{"location":"el/#seismogram-analysis","text":"Updated The following video shows summarize how to manage the basic waveform processing","title":"Seismogram Analysis"},{"location":"el/#explore-your-catalog","text":"Updated The following video shows a user loading a project, then explores the project using the fast decimation. In the second parte, the user opens a catalog, selects and event and send the information to the main window. Finally filters the project by time and process and plot to see the event wavefroms. Please go to Start with the Basics --> Shorcuts --> Mouse .","title":"Explore your Catalog"},{"location":"el/#manual-pick-locate-event-fault-plane-and-magnitude","text":"Updated The following video shows a user loading a project, then automatically picking phases plus polarity. Please go to Start with the Basics --> Shorcuts --> Mouse .","title":"Manual Pick, Locate Event, Fault Plane and Magnitude"},{"location":"el/#automatic-picking-and-associate","text":"Updated The following video shows a user loading a project, then automatically picking phases plus polarity. Please go to Start with the Basics --> Shorcuts --> Mouse .","title":"Automatic Picking and Associate"},{"location":"index%20copy/","text":"Welcome to Integrated Seismic Program (ISP) Documentation Integrated Seismic Program is an amenable toolbox that joins functionality and standard algorithms commonly used in seismology. The complete software is separated in several modules and each module is designed to overcome a specific task. Cabieces et al. Integrated Seismic Program (ISP) : A New Python GUI\u2010Based Software for Earthquake Seismology and Seismic Signal Processing. Seismological Research Letters 2022;; 93 (3): 1895\u20131908. doi: https://doi.org/10.1785/0220210205 See ISP open-source code Follow us on Twitter Subscribe on YouTube Questions and Issues Send us an email to subscribe to news and future workshops: isp@roa.es surfQuake surfQuake core has been totally joined to ISP, now either the library and the command line interface are installed all together! This new software is designed to streamline the workflow of estimating seismic source parameters: Release Date: 18-April-2024 EGU-24 presentation Software Structure Index: Modules Earthquake Seismology Time-Frequency Analysis Focal Mechanism / Moment Tensor Inversion Array Seismology Receiver Functions Ambient Noise Tomography Index: ToolBoxes Database Retrieve Data (FDSN) Probability Power Spectral Density Function (PPSD) Synthetic Generator Near-Real Time Adquisition Multimedia Tutorials Managing your Project Seismogram Analysis Explore and Search in your Catalog Manual Pick, Locate Event, Fault Plane and Magnitude Automatic Picking and Associate Time-Frequency Analysis Array Seismology Moment Tensor Inversion Data examples repository Case of study , contains a full example of using surfQuake with core Library Python scripts, Core Library bash script and expected results. Of course you can try to run the example using the GUI. We have also created a repository with an example of 3D model","title":"Welcome to Integrated Seismic Program (ISP) Documentation"},{"location":"index%20copy/#welcome-to-integrated-seismic-program-isp-documentation","text":"Integrated Seismic Program is an amenable toolbox that joins functionality and standard algorithms commonly used in seismology. The complete software is separated in several modules and each module is designed to overcome a specific task. Cabieces et al. Integrated Seismic Program (ISP) : A New Python GUI\u2010Based Software for Earthquake Seismology and Seismic Signal Processing. Seismological Research Letters 2022;; 93 (3): 1895\u20131908. doi: https://doi.org/10.1785/0220210205 See ISP open-source code Follow us on Twitter Subscribe on YouTube Questions and Issues Send us an email to subscribe to news and future workshops: isp@roa.es","title":"Welcome to Integrated Seismic Program (ISP) Documentation"},{"location":"index%20copy/#surfquake","text":"surfQuake core has been totally joined to ISP, now either the library and the command line interface are installed all together! This new software is designed to streamline the workflow of estimating seismic source parameters: Release Date: 18-April-2024 EGU-24 presentation","title":"surfQuake"},{"location":"index%20copy/#software-structure","text":"","title":"Software Structure"},{"location":"index%20copy/#index-modules","text":"Earthquake Seismology Time-Frequency Analysis Focal Mechanism / Moment Tensor Inversion Array Seismology Receiver Functions Ambient Noise Tomography","title":"Index: Modules"},{"location":"index%20copy/#index-toolboxes","text":"Database Retrieve Data (FDSN) Probability Power Spectral Density Function (PPSD) Synthetic Generator Near-Real Time Adquisition","title":"Index: ToolBoxes"},{"location":"index%20copy/#multimedia-tutorials","text":"Managing your Project Seismogram Analysis Explore and Search in your Catalog Manual Pick, Locate Event, Fault Plane and Magnitude Automatic Picking and Associate Time-Frequency Analysis Array Seismology Moment Tensor Inversion","title":"Multimedia Tutorials"},{"location":"index%20copy/#data-examples-repository","text":"Case of study , contains a full example of using surfQuake with core Library Python scripts, Core Library bash script and expected results. Of course you can try to run the example using the GUI. We have also created a repository with an example of 3D model","title":"Data examples repository"},{"location":"install/","text":"Installation First of all, clone the repository from ISP master branch . Just open your terminal and navigate whenever you want to place ISP and type in the terminal git clone --depth 1 --branch master --single-branch https://github.com/ProjectISP/ISP.git To be updated, from ./ISP type in your terminal, git pull --depth 1 The installation file will install the requirements and will compile the source packages (advanced). At the end of the installation the user will be asked for an alias \"isp\". Following the directions Installation for end users , it is needed to have previously installed anaconda . Additionally, Rosetta allows Mac machines with Apple chips to run applications meant for Mac systems with Intel processors. If this is your case, please install Rosseta AFTER the ISP installation, if you need either Locate Events, First Polarity Focal Mechanism or to use MTI module. Installation for end users (Mac and Linux) To run the installation go to ./ISP/install and type: chmod u+x ISP_installer.sh ./ISP_installer.sh You will be ask for the type of installation, in this case your answer must be, conventional Which type of installation would you prefer, conventional or advanced ? conventional Now the installation process is finished. Open a terminal and type: >> isp Just in case the alias isp do not open the software (because the alias has not been written in your shell), go to ./ISP and type: conda activate isp or source activate isp python start_isp.py WARNING! For Linux users it is recommendable to install futher dependencies: sudo apt update sudo apt-get install xdg-utils sudo apt install --reinstall libxcb-xinerama0 sudo apt install --reinstall libxcb1 libx11-xcb1 libxext6 libxkbcommon-x11-0 Installation for developers (Mac and Linux) Before run this type of installation be sure you have installed and in your PATH system variables cmake & Intel Fortran Stand Alone version with useful directions for Ubuntu users To run the installation go to ./ISP/install and type: chmod u+x ISP_installer.sh ./ISP_installer.sh You will be ask for the type of installation, in this case your answer must be, advanced Which type of installation would you prefer, conventional or advanced ? advanced Just in case the alias isp do not open the software, go to ./ISP and type: conda activate isp or source activate isp python start_isp.py Installation for Windows 10/11 users In the following text, we briefly explain how to install ISP in windows 10/11 via WSL . Please, download the directions here Uninstall ISP First remove the folder ISP, then type in your terminal: conda remove --name isp --all Good luck with the process, and report any issue to the ISP github repository","title":"Installation"},{"location":"install/#installation","text":"First of all, clone the repository from ISP master branch . Just open your terminal and navigate whenever you want to place ISP and type in the terminal git clone --depth 1 --branch master --single-branch https://github.com/ProjectISP/ISP.git To be updated, from ./ISP type in your terminal, git pull --depth 1 The installation file will install the requirements and will compile the source packages (advanced). At the end of the installation the user will be asked for an alias \"isp\". Following the directions Installation for end users , it is needed to have previously installed anaconda . Additionally, Rosetta allows Mac machines with Apple chips to run applications meant for Mac systems with Intel processors. If this is your case, please install Rosseta AFTER the ISP installation, if you need either Locate Events, First Polarity Focal Mechanism or to use MTI module.","title":"Installation"},{"location":"install/#installation-for-end-users-mac-and-linux","text":"To run the installation go to ./ISP/install and type: chmod u+x ISP_installer.sh ./ISP_installer.sh You will be ask for the type of installation, in this case your answer must be, conventional Which type of installation would you prefer, conventional or advanced ? conventional Now the installation process is finished. Open a terminal and type: >> isp Just in case the alias isp do not open the software (because the alias has not been written in your shell), go to ./ISP and type: conda activate isp or source activate isp python start_isp.py WARNING! For Linux users it is recommendable to install futher dependencies: sudo apt update sudo apt-get install xdg-utils sudo apt install --reinstall libxcb-xinerama0 sudo apt install --reinstall libxcb1 libx11-xcb1 libxext6 libxkbcommon-x11-0","title":"Installation for end users (Mac and Linux)"},{"location":"install/#installation-for-developers-mac-and-linux","text":"Before run this type of installation be sure you have installed and in your PATH system variables cmake & Intel Fortran Stand Alone version with useful directions for Ubuntu users To run the installation go to ./ISP/install and type: chmod u+x ISP_installer.sh ./ISP_installer.sh You will be ask for the type of installation, in this case your answer must be, advanced Which type of installation would you prefer, conventional or advanced ? advanced Just in case the alias isp do not open the software, go to ./ISP and type: conda activate isp or source activate isp python start_isp.py","title":"Installation for developers (Mac and Linux)"},{"location":"install/#installation-for-windows-1011-users","text":"In the following text, we briefly explain how to install ISP in windows 10/11 via WSL . Please, download the directions here","title":"Installation for Windows 10/11 users"},{"location":"install/#uninstall-isp","text":"First remove the folder ISP, then type in your terminal: conda remove --name isp --all Good luck with the process, and report any issue to the ISP github repository","title":"Uninstall ISP"},{"location":"mti/","text":"Moment Tensor Inversion (MTI). Methodology The functionality of this module is based on the Bayes-ISOLA code Vack\u00e1\u0159 et al., 2017 , a tool for automated CMT inversion in a Bayesian framework. A nice improvement that boost the robusness of the MTI is to use an optional data covariance matrix from pre-event noise that yields an automatic weighting function for the receiver components according to their noise levels. This also serves as an automated frequency filter that suppresses noisy frequency ranges. During the inversion, a grid search is performed over time and space, combined with an analytical (least squares) moment tensor inversion at each grid point, which accelerates the inversion process. The more time-consuming tasks like the Green\u2019s function computation and the grid search are parallelized for efficiency. The results provided by the module contain the best-fit solution, as well as the full posterior probability density function (PPDF), which allows the user to plot the marginal probability density functions (PDFs) for any of the CMT parameters. Connect Earthquake Analysis to MTI module. The first step to estimate the Focal Mechanism using the MTI module is to send your waveforms in velocity usints to the MTI module. To be familiarize with this process, you have an example inside Waveforms, macro and event info --> /isp/example/Moment_Tensor_example Metadata --> /isp/Metadata/xml/metadata.xml Create a new project pointing to the files of the example Load the metadata Load Macro Process and plot your waveforms Cut the waveforms (remember with Q starttime and E endtime over the plot and check the box Trim Time), then Process and plot your waveforms another time. See the figures related with this example Click on Macro and Load the file macro_mti.pkl from the example: Click on Process and Plot: Now everything is ready!!!, We need to send all of this information (Waveforms plus metadata to MTI module). Now, click on the picture (up left button) This action will connect your waveforms with the MTI module. It will open a dialog asking how to set your earthquake hypocenter source parameters (lat, lon, depth and mag). You can either choose: Manually . After open MTI module, you will have to fill Moment Tensor Parameters box by yourself. Load Last Location , This action will load the information from your last (last.hyp file) eartuquake location from the default output location folder and will automatically fill the Moment Tensor. load other , This action will let you choose a \"file.hyp\" file and will automatically fill the Moment Tensor. Ok, now we are almost ready, next is configurate your eath velocity model Create Earth velocity model To start you need to load a Earth model. Go to Build a 1D Earth Model and open the Earth Model Form, the fill it and save it. Alternatively, Yo can find examples of regional models in ./isp/mti/input/iberia.dat and ./isp/mti/input/AK135.txt . Bayesian Inversion In this point the conexion between Earthquake Analysis and MTI module is done. You have in memory the Seismograms processed and the Metadata (information of stations coordinates and the response of the instrument). The connexion is not required, if you want to run the MTI from the database (see database for further details and below to see how to run it). Output Files >> path to the seismogram files Earth Model >> Path to the Earth model file (see previous section for see how to make this file with ISP, the user can also do it manually). Open Stations/Channels info . This action will allow you select which station/component will be used in the inversion (this is a mandatory action. Now fill the Moment Tensor Information Box ; Hipocenter Location and Uncertainty (m) Include the estimated hypocenter location along with its associated uncertainty in meters. Origin Time and Uncertainty Specify the calculated origin time of the event and its corresponding uncertainty. Magnitude Provide the event's magnitude as determined from the analysis. Frequency Range for Inversion Indicate the frequency range used during the inversion process. Refer to the example shown in the figure below for clarity. Distance Filter Exclude stations that fall outside the defined distance filter. This filter is based on the distance from the epicenter to each station. Options for Running the Inversion Depending on your analysis, you can choose from the following options: - Deviatoric Configure the inversion to focus on deviatoric components. - Source Circular Shape Enforce a circular source shape for the inversion process. - Covariance Use covariance for the inversion. *Note:* Covariance utilizes a previously calculated noise window. Ensure that this window is sufficiently long (e.g., at least 15 minutes). - Precalculated Green Functions Utilize precalculated Green functions to streamline the inversion process. *Tip:* Run an initial inversion with this option disabled to generate the necessary Green functions. Once generated, you can refine the inversion by selecting different components, distance filters, or frequency bandwidths. Plotting Your results In order to plot your results, Click at Plot at last solution -- It will print a log file with the result of the inversion, and the beachball of the focal methanism plus the fit of the synthetci seismograms in time and frecuwency domain. Double click on the images to zoom in. Click at Open full report . It will be open the report with the full output images on your webbrowser navigator. Multimedia Material (MTI)","title":"Seismic Moment Tensor Inversion"},{"location":"mti/#moment-tensor-inversion-mti","text":"","title":"Moment Tensor Inversion (MTI)."},{"location":"mti/#methodology","text":"The functionality of this module is based on the Bayes-ISOLA code Vack\u00e1\u0159 et al., 2017 , a tool for automated CMT inversion in a Bayesian framework. A nice improvement that boost the robusness of the MTI is to use an optional data covariance matrix from pre-event noise that yields an automatic weighting function for the receiver components according to their noise levels. This also serves as an automated frequency filter that suppresses noisy frequency ranges. During the inversion, a grid search is performed over time and space, combined with an analytical (least squares) moment tensor inversion at each grid point, which accelerates the inversion process. The more time-consuming tasks like the Green\u2019s function computation and the grid search are parallelized for efficiency. The results provided by the module contain the best-fit solution, as well as the full posterior probability density function (PPDF), which allows the user to plot the marginal probability density functions (PDFs) for any of the CMT parameters.","title":"Methodology"},{"location":"mti/#connect-earthquake-analysis-to-mti-module","text":"The first step to estimate the Focal Mechanism using the MTI module is to send your waveforms in velocity usints to the MTI module. To be familiarize with this process, you have an example inside Waveforms, macro and event info --> /isp/example/Moment_Tensor_example Metadata --> /isp/Metadata/xml/metadata.xml Create a new project pointing to the files of the example Load the metadata Load Macro Process and plot your waveforms Cut the waveforms (remember with Q starttime and E endtime over the plot and check the box Trim Time), then Process and plot your waveforms another time. See the figures related with this example Click on Macro and Load the file macro_mti.pkl from the example: Click on Process and Plot: Now everything is ready!!!, We need to send all of this information (Waveforms plus metadata to MTI module). Now, click on the picture (up left button) This action will connect your waveforms with the MTI module. It will open a dialog asking how to set your earthquake hypocenter source parameters (lat, lon, depth and mag). You can either choose: Manually . After open MTI module, you will have to fill Moment Tensor Parameters box by yourself. Load Last Location , This action will load the information from your last (last.hyp file) eartuquake location from the default output location folder and will automatically fill the Moment Tensor. load other , This action will let you choose a \"file.hyp\" file and will automatically fill the Moment Tensor. Ok, now we are almost ready, next is configurate your eath velocity model","title":"Connect Earthquake Analysis to MTI module."},{"location":"mti/#create-earth-velocity-model","text":"To start you need to load a Earth model. Go to Build a 1D Earth Model and open the Earth Model Form, the fill it and save it. Alternatively, Yo can find examples of regional models in ./isp/mti/input/iberia.dat and ./isp/mti/input/AK135.txt .","title":"Create Earth velocity model"},{"location":"mti/#bayesian-inversion","text":"In this point the conexion between Earthquake Analysis and MTI module is done. You have in memory the Seismograms processed and the Metadata (information of stations coordinates and the response of the instrument). The connexion is not required, if you want to run the MTI from the database (see database for further details and below to see how to run it). Output Files >> path to the seismogram files Earth Model >> Path to the Earth model file (see previous section for see how to make this file with ISP, the user can also do it manually). Open Stations/Channels info . This action will allow you select which station/component will be used in the inversion (this is a mandatory action. Now fill the Moment Tensor Information Box ; Hipocenter Location and Uncertainty (m) Include the estimated hypocenter location along with its associated uncertainty in meters. Origin Time and Uncertainty Specify the calculated origin time of the event and its corresponding uncertainty. Magnitude Provide the event's magnitude as determined from the analysis. Frequency Range for Inversion Indicate the frequency range used during the inversion process. Refer to the example shown in the figure below for clarity. Distance Filter Exclude stations that fall outside the defined distance filter. This filter is based on the distance from the epicenter to each station. Options for Running the Inversion Depending on your analysis, you can choose from the following options: - Deviatoric Configure the inversion to focus on deviatoric components. - Source Circular Shape Enforce a circular source shape for the inversion process. - Covariance Use covariance for the inversion. *Note:* Covariance utilizes a previously calculated noise window. Ensure that this window is sufficiently long (e.g., at least 15 minutes). - Precalculated Green Functions Utilize precalculated Green functions to streamline the inversion process. *Tip:* Run an initial inversion with this option disabled to generate the necessary Green functions. Once generated, you can refine the inversion by selecting different components, distance filters, or frequency bandwidths.","title":"Bayesian Inversion"},{"location":"mti/#plotting-your-results","text":"In order to plot your results, Click at Plot at last solution -- It will print a log file with the result of the inversion, and the beachball of the focal methanism plus the fit of the synthetci seismograms in time and frecuwency domain. Double click on the images to zoom in. Click at Open full report . It will be open the report with the full output images on your webbrowser navigator.","title":"Plotting Your results"},{"location":"mti/#multimedia-material-mti","text":"","title":"Multimedia Material (MTI)"},{"location":"nrt/","text":"Near Real Time Adquisition The tool Near Real Time Adquisition is intended to retrieve data from a server. Structure Metadata Set the metadata file **Net/Station/Channel Place separated by \",\" the name of nets stations and channels you want to retrieve. It is convinient to use wildcards such as \"BH?\" or \"*\" Server Address Set the name of the server address you want to point to. Max Num Traces Number of traces you want to plot Time Window Duration of the time window in minutes you want to plot the traces Save Data This action will allow saving the mseed files that are collected in the destionation folder. The mseed will have a maximum of 24 h being the cut at \"00:00:00.0000\". Plot Map This action will plot the map of the metadata stations in red plus the statios you are collecting data in green.","title":"Near Real Time Adquisition"},{"location":"nrt/#near-real-time-adquisition","text":"The tool Near Real Time Adquisition is intended to retrieve data from a server.","title":"Near Real Time Adquisition"},{"location":"nrt/#structure","text":"Metadata Set the metadata file **Net/Station/Channel Place separated by \",\" the name of nets stations and channels you want to retrieve. It is convinient to use wildcards such as \"BH?\" or \"*\" Server Address Set the name of the server address you want to point to. Max Num Traces Number of traces you want to plot Time Window Duration of the time window in minutes you want to plot the traces Save Data This action will allow saving the mseed files that are collected in the destionation folder. The mseed will have a maximum of 24 h being the cut at \"00:00:00.0000\". Plot Map This action will plot the map of the metadata stations in red plus the statios you are collecting data in green.","title":"Structure"},{"location":"ppsds/","text":"Probability Power Spectral Dentitiy (PPSD) Background One the most common tools to evaluate the station performance of seismic data acquisition (Mcnamara and Buland, 2004) is to estimate the Probability Density Functions (PDFs). Once the PDFs are calculated, the seismic noise levels can be compared with the standard low and high noise levels, NLNM and NHNM (Peterson, 1993), or can be calculated cumulative spectrograms to observe seasonal variations. The ISP submodule \u201cPPSD\u201d allows to build a database to storage the PDFs of the stations/components desired from PPSDs, with an specific frame work for this task. Moreover the original databased can be upgraded with more data. Once the PDFs are computed, they can be visualized into another framework that offers multiple visualization options. The Fig. 1 shows the visualization framework with the PDFs of three components from three different station and the Fig 2 & 3 the diurnal and seasonal variation, respectively. The PDFs are also compared with earthquake power desnsity spectrums (Clinton and Heaton, 2002). How to use this PPSD toolbox The first step is to generate a database where all PDFs will be saved for later use. For this porpuse the user have available the following dialog. Set how you want to name your new database : and set the path where you have your folder tree, populated by seismograms and sel the metadata directory path. Set the spectral parameters : Length \u2013 Length of data segments passed to psd in seconds. A lenght of 3600 s (1 hour) is recommended to balance the frequency resolution with the nu,ber of segments. Overlap of segments passed to psd. Overlap may take values between 0 and 100 and is given as % of the length of one segment, e.g. ppsd_length=3600 and overlap=50 % result in an overlap of 1800s of the segments. Smoothing width in octaves. Determines over what period/frequency range the psd is smoothed around every central period/frequency. Given in fractions of octaves (default of 1 means the psd is averaged over a full octave at each central frequency). Period step octaves. Step length on frequency axis in fraction of octaves (default of 0.125 means one smoothed psd value on the frequency axis is measured every 1/8 of an octave). Select filter : per network, stations and channels. For example Nets --> WM,ES Stations --> SFS,EPON Channels --> HHZ,HHE,HHN If you keep empty spaces at the filter boxes the process will run over all sismograms at the folder tree specified above. Click on Process : At this step ISP will procss all seismograms and will create a database od PDFs. This process can take for a while specially if your folder tree has many seismogram files. Be patient, a progress bar will let you know. Save the Database : Save the PDFs database for later use. VERY RECOMENDABLE Ready to Go : This action will send all information (PDFs and station information) to the PPSSD main frame. A table with all available network/station/channel will be fill. Select some raws from the table : set the nu,ber of stations per page that you want to visualize and select the PDF or Variation (be careful with the time window you select, if you hesitate choose something crazy from year 1975- year 2060). Finally click on plote : You can select the page at the bottom right part of the plot. Warning , if the colorpallette appears overlapped, just click another time at plot.","title":"PPSDs"},{"location":"ppsds/#probability-power-spectral-dentitiy-ppsd","text":"","title":"Probability Power Spectral Dentitiy (PPSD)"},{"location":"ppsds/#background","text":"One the most common tools to evaluate the station performance of seismic data acquisition (Mcnamara and Buland, 2004) is to estimate the Probability Density Functions (PDFs). Once the PDFs are calculated, the seismic noise levels can be compared with the standard low and high noise levels, NLNM and NHNM (Peterson, 1993), or can be calculated cumulative spectrograms to observe seasonal variations. The ISP submodule \u201cPPSD\u201d allows to build a database to storage the PDFs of the stations/components desired from PPSDs, with an specific frame work for this task. Moreover the original databased can be upgraded with more data. Once the PDFs are computed, they can be visualized into another framework that offers multiple visualization options. The Fig. 1 shows the visualization framework with the PDFs of three components from three different station and the Fig 2 & 3 the diurnal and seasonal variation, respectively. The PDFs are also compared with earthquake power desnsity spectrums (Clinton and Heaton, 2002).","title":"Background"},{"location":"ppsds/#how-to-use-this-ppsd-toolbox","text":"The first step is to generate a database where all PDFs will be saved for later use. For this porpuse the user have available the following dialog. Set how you want to name your new database : and set the path where you have your folder tree, populated by seismograms and sel the metadata directory path. Set the spectral parameters : Length \u2013 Length of data segments passed to psd in seconds. A lenght of 3600 s (1 hour) is recommended to balance the frequency resolution with the nu,ber of segments. Overlap of segments passed to psd. Overlap may take values between 0 and 100 and is given as % of the length of one segment, e.g. ppsd_length=3600 and overlap=50 % result in an overlap of 1800s of the segments. Smoothing width in octaves. Determines over what period/frequency range the psd is smoothed around every central period/frequency. Given in fractions of octaves (default of 1 means the psd is averaged over a full octave at each central frequency). Period step octaves. Step length on frequency axis in fraction of octaves (default of 0.125 means one smoothed psd value on the frequency axis is measured every 1/8 of an octave). Select filter : per network, stations and channels. For example Nets --> WM,ES Stations --> SFS,EPON Channels --> HHZ,HHE,HHN If you keep empty spaces at the filter boxes the process will run over all sismograms at the folder tree specified above. Click on Process : At this step ISP will procss all seismograms and will create a database od PDFs. This process can take for a while specially if your folder tree has many seismogram files. Be patient, a progress bar will let you know. Save the Database : Save the PDFs database for later use. VERY RECOMENDABLE Ready to Go : This action will send all information (PDFs and station information) to the PPSSD main frame. A table with all available network/station/channel will be fill. Select some raws from the table : set the nu,ber of stations per page that you want to visualize and select the PDF or Variation (be careful with the time window you select, if you hesitate choose something crazy from year 1975- year 2060). Finally click on plote : You can select the page at the bottom right part of the plot. Warning , if the colorpallette appears overlapped, just click another time at plot.","title":"How to use this PPSD toolbox"},{"location":"progress/","text":"News 22-Nov-2024 We have upgraded modules Moment Tensor Inversion and Array Analysis. Now they are perfectly connected with Earthquake analysis and are much more flexible and intuitive. News 1-Nov-2024 We have renew the Synthetic Toolbox . We have included an option to run your own Python script from a seismogram processed with ISP. You can see how to use this option at Earthquake Seismology - Run Script . Now you can read ObsPy catalogs using ISP Earthquake Seismology - Search in Catalog . The ISP team has recently developed: Earthquake Analysis module Upgraded In this upgrade you can create your project from your individual files or from your sds structure. We have also included a fast way to search your waveforms from a catalog (./isp/examples/catalog/). Now it is created a connection Earthquake Analysis to TF Analysis to allow the user a rapid deep signal processing investigation. Moreover, it is included a very nice way of sort tyour waveforms by distance and showing the theoretical Travel-Times. Seismic Ambient Noise Tomography For now, It is available the Empirical Green Functions retrieval of vertical and Horizontal components, synchronize clocks using EGFs ,a tool to measure Group and Phase velocity from dispersion curves and create dispersion maps. An example with the results of Cabieces et al., 2022 \"Upper lithospheric structure of northeastern Venezuela from joint inversion of surface wave dispersion and receiver functions\" can be found in ./isp/ant We have implemented the conexion between Erthquake Location and Time-Frequency Anlysis","title":"Gallery & Progress"},{"location":"progress/#news-22-nov-2024","text":"We have upgraded modules Moment Tensor Inversion and Array Analysis. Now they are perfectly connected with Earthquake analysis and are much more flexible and intuitive.","title":"News 22-Nov-2024"},{"location":"progress/#news-1-nov-2024","text":"We have renew the Synthetic Toolbox . We have included an option to run your own Python script from a seismogram processed with ISP. You can see how to use this option at Earthquake Seismology - Run Script . Now you can read ObsPy catalogs using ISP Earthquake Seismology - Search in Catalog . The ISP team has recently developed: Earthquake Analysis module Upgraded In this upgrade you can create your project from your individual files or from your sds structure. We have also included a fast way to search your waveforms from a catalog (./isp/examples/catalog/). Now it is created a connection Earthquake Analysis to TF Analysis to allow the user a rapid deep signal processing investigation. Moreover, it is included a very nice way of sort tyour waveforms by distance and showing the theoretical Travel-Times. Seismic Ambient Noise Tomography For now, It is available the Empirical Green Functions retrieval of vertical and Horizontal components, synchronize clocks using EGFs ,a tool to measure Group and Phase velocity from dispersion curves and create dispersion maps. An example with the results of Cabieces et al., 2022 \"Upper lithospheric structure of northeastern Venezuela from joint inversion of surface wave dispersion and receiver functions\" can be found in ./isp/ant We have implemented the conexion between Erthquake Location and Time-Frequency Anlysis","title":"News 1-Nov-2024"},{"location":"rd/","text":"Retrieve Data Retrieve Data framework is an interface to facilitate download specific events to time-series or select a period and download data from different stations. Step 1, FDSN connection : Select a FDSN web service and click Load . This action will load the inventory. Warning , some FDSNs service have access to more than one network, so if you want to speed up the process please select anetwork (see figure is preselected network IU. Step 2, Download Catalog : Once the FDSN connection is done, fill the fileds in Catalog box and then click Download catalog . Warning, please if you are too ambicious (e.g., a catalog of many years) the procees can be endless :-). The events will be plot according to the magnitude and scale bar depth (km). Select an event pressing \"t\" near an epicenter (this is to graphycally help the user select events). You will see the event selected iluminated in grey in the events table. Now click on the iluminated row to be definetly selected (now the sleected row will be shown in blue). You can select more than one vent to be downloaded at once!!! Step 3, Selection Process : Plot Stations : This action will plot the stations inside the inventory from your FDSN connection (step 1). Station Selction : Doucle-click near the red triangles to automatically include names inside Network/Stations box. Press \"c\" near the psotion of the station you want to remove from the selection (might be you want to deselect some stations). Manually just station names separated by commas e.g. ARNO,SFS (see figure). Select Components : Examples: BH? or simply BHZ (accept wildcards) or BHN,BHE,BHZ. Step 4, Download Data : From this point you can follow different actions, Download Time Series : Just set Starttime and Endtime and click on the button. This will download the mseeds of the stations/channels requested for that period. Download Metadata : This action will download the stations.xml of the stations/channels requested. This file is the metadata that is used by ISP in the rest of the modules. Download event data : This action will download the events selected data of the list of Newtork/Stations/Channels with a time window lenght Time before - otime- Time after. Warning: Be sure you have clicked in the events table just in the events you want to donwload data. Finally ISP will request a folder where you want to download the data. A feedback with downloading process will be shown. The available FDSN web services are: BGR http://eida.bgr.de EMSC http://www.seismicportal.eu ETH http://eida.ethz.ch GEONET http://service.geonet.org.nz GFZ http://geofon.gfz-potsdam.de ICGC http://ws.icgc.cat INGV http://webservices.ingv.it IPGP http://ws.ipgp.fr IRIS http://service.iris.edu ISC http://isc-mirror.iris.washington.edu KNMI http://rdsa.knmi.nl KOERI http://eida.koeri.boun.edu.tr LMU http://erde.geophysik.uni-muenchen.de NCEDC http://service.ncedc.org NIEP http://eida-sc3.infp.ro NOA http://eida.gein.noa.gr ODC http://www.orfeus-eu.org ORFEUS http://www.orfeus-eu.org RASPISHAKE http://fdsnws.raspberryshakedata.com RESIF http://ws.resif.fr SCEDC http://service.scedc.caltech.edu TEXNET http://rtserve.beg.utexas.edu USGS http://earthquake.usgs.gov USP http://sismo.iag.usp.br There is also the possibility to connect to your own Earthworm server to download the inventory and the data. Just fill the check box and the IP/Port. We are working in the connection between SeisComp3 Database and ISP. We will soon deliver this part of the project (currently is being tested).","title":"Retrieve Data"},{"location":"rd/#retrieve-data","text":"Retrieve Data framework is an interface to facilitate download specific events to time-series or select a period and download data from different stations. Step 1, FDSN connection : Select a FDSN web service and click Load . This action will load the inventory. Warning , some FDSNs service have access to more than one network, so if you want to speed up the process please select anetwork (see figure is preselected network IU. Step 2, Download Catalog : Once the FDSN connection is done, fill the fileds in Catalog box and then click Download catalog . Warning, please if you are too ambicious (e.g., a catalog of many years) the procees can be endless :-). The events will be plot according to the magnitude and scale bar depth (km). Select an event pressing \"t\" near an epicenter (this is to graphycally help the user select events). You will see the event selected iluminated in grey in the events table. Now click on the iluminated row to be definetly selected (now the sleected row will be shown in blue). You can select more than one vent to be downloaded at once!!! Step 3, Selection Process : Plot Stations : This action will plot the stations inside the inventory from your FDSN connection (step 1). Station Selction : Doucle-click near the red triangles to automatically include names inside Network/Stations box. Press \"c\" near the psotion of the station you want to remove from the selection (might be you want to deselect some stations). Manually just station names separated by commas e.g. ARNO,SFS (see figure). Select Components : Examples: BH? or simply BHZ (accept wildcards) or BHN,BHE,BHZ. Step 4, Download Data : From this point you can follow different actions, Download Time Series : Just set Starttime and Endtime and click on the button. This will download the mseeds of the stations/channels requested for that period. Download Metadata : This action will download the stations.xml of the stations/channels requested. This file is the metadata that is used by ISP in the rest of the modules. Download event data : This action will download the events selected data of the list of Newtork/Stations/Channels with a time window lenght Time before - otime- Time after. Warning: Be sure you have clicked in the events table just in the events you want to donwload data. Finally ISP will request a folder where you want to download the data. A feedback with downloading process will be shown. The available FDSN web services are: BGR http://eida.bgr.de EMSC http://www.seismicportal.eu ETH http://eida.ethz.ch GEONET http://service.geonet.org.nz GFZ http://geofon.gfz-potsdam.de ICGC http://ws.icgc.cat INGV http://webservices.ingv.it IPGP http://ws.ipgp.fr IRIS http://service.iris.edu ISC http://isc-mirror.iris.washington.edu KNMI http://rdsa.knmi.nl KOERI http://eida.koeri.boun.edu.tr LMU http://erde.geophysik.uni-muenchen.de NCEDC http://service.ncedc.org NIEP http://eida-sc3.infp.ro NOA http://eida.gein.noa.gr ODC http://www.orfeus-eu.org ORFEUS http://www.orfeus-eu.org RASPISHAKE http://fdsnws.raspberryshakedata.com RESIF http://ws.resif.fr SCEDC http://service.scedc.caltech.edu TEXNET http://rtserve.beg.utexas.edu USGS http://earthquake.usgs.gov USP http://sismo.iag.usp.br There is also the possibility to connect to your own Earthworm server to download the inventory and the data. Just fill the check box and the IP/Port. We are working in the connection between SeisComp3 Database and ISP. We will soon deliver this part of the project (currently is being tested).","title":"Retrieve Data"},{"location":"refs/","text":"References Boashash, B., and P. Black (1987). An efficient real-time implementation of the Wigner-Ville distribution, IEEE Trans. Acoust. Speech Signal Process. 35, no. 11, 1611\u20131618. Bormann, P., and J. W. Dewey (2012). The new IASPEI standards for determining magnitudes from digital data and their relation to classical magnitudes, in New Manual of Seismological Observatory Practice 2 (NMSOP-2), Deutsches GeoForschungsZentrum GFZ, Potsdam, Germany, 1\u201344. Cabieces, R., E. Buforn, S. Cesca, and A. Pazos (2020). Focal parameters of earthquakes offshore Cape St. Vincent using an amphibious network, Pure Appl. Geophys. doi: 10.1007/s00024-020-02475-3. Cabieces R., Kr\u00fcger, F., Garcia-Yeguas, A., Villase\u00f1or, A., Buforn, E., Pazos, A., Olivar-Casta\u00f1o, A.,Barco, J (2020) Slowness vector estimation over large-aperture sparse arrays with the Continuous Wavelet Transform (CWT): Application to Ocean Bottom Seismometers, Geophysical Journal International, ggaa427, https://doi.org/10.1093/gji/ggaa427 Cabieces, R., Villase\u00f1or, A., Berg, E., Olivar-Casta\u00f1o, A., Arnaiz, M., Ventosa, S & Ferreira, A (2022). Upper Lithosphere structure of northeastern Venezuela from joint inversion of surface waves dispersion and receiver functions. Solid Earth. Capon, J. (1969). High-resolution frequency-wavenumber spectrum analysis, Proc. IEEE 57, no. 8, 1408\u20131418. Clinton, J. F., and T. H. Heaton (2002). Potential advantages of a strong-motion velocity meter over a strong-motion accelerometer, Seismol. Res. Lett. 73, no. 3, 332\u2013342. Daubechies, I. (1992). Ten Lectures on Wavelets, Society for industrial and applied mathematics, doi: 10.1137/1.9781611970104. Flinn, E. A. (1965). Signal analysis using rectilinearity and direction of particle motion, Proc. IEEE 53, no. 12, 1874\u20131876. Font, Y., H. Kao, S. Lallemand, C.-S. Liu, and L.-Y. Chiao (2004). Hypocentre determination offshore of eastern Taiwan using the MaximumIntersectionmethod, Geophys. J. Int. 158, no. 2, 655\u2013675. Gal, M., A. M. Reading, S. P. Ellingsen, K. D. Koper, S. J. Gibbons, and S. P. Nasholm (2014). Improved implementation of the fk and Capon methods for array analysis of seismic noise, Geophys. J. Int. 198, no. 2, 1045\u20131054, doi: 10.1093/gji/ggu183. Goldstein, P., D. Dodge, M. Firpo, and L. Minner (2003). SAC2000: Signal processing and analysis tools for seismologists and engineers, in The IASPEI International Handbook of Earthquake Engineering and Seismology, W. H. K. Lee, H. Kanamori, P. C. Jennings, and C. Kisslinger (Editors), Vol. 81, Academic Press, London, United Kingdom, 1613\u20131620, doi: 10.1016/S0074-6142 (03)80284-X. Goutorbe, B., D. L. de Oliveira Coelho, and S. Drouet (2015). Rayleigh wave group velocities at periods of 6-23 s across Brazil from ambient noise tomography, Geophys. J. Int. 203, no. 2, 869\u2013882. Havskov, J., P. H. Voss, and L. Ottemoller (2020). Seismological observatory software: 30 Yr of SEISAN, Seismol. Res. Lett. 91, no. 3, 1846\u20131852, doi: 10.1785/0220190313. Herrmann, R. B. (2013). Computer programs in seismology: An evolving tool for instruction and research, Seismol. Res. Lett. 84, no. 6, 1081\u20131088, doi: 10.1785/0220110096. Hunter, J. D. (2007). Matplotlib: A 2D graphics environment, Comput. Sci. Eng. 9, no. 3, 90\u201395, doi: 10.1109/MCSE.2007.55. Jiang, C., and M. A. Denolle (2020). NoisePy: A new high-performance Python tool for ambient-noise seismology, Seismol. Res. Lett. 91, no. 3, 1853\u20131866, doi: 10.1785/0220190364. Krischer, L., T. Megies, R. Barsch, M. Beyreuther, T. Lecocq, C. Caudron, and J. Wassermann (2015). ObsPy: A bridge for seismology into the scientific Python ecosystem, Comput. Sci. Discov. doi: 10.1088/1749-4699/8/1/014003. Langston, C. A. (1979). Structure under Mount Rainier, Washington, inferred from teleseismic body waves, J. Geophys. Res. 84, no. B9, 4749\u20134762. Lecocq, T., C. Caudron, and F. Brenguier (2014). MSNoise, a Python package for monitoring seismic velocity changes using ambient seismic noise, Seismol. Res. Lett. 85, no. 3, 715\u2013726. Loeliger, J., and M. McCullough (2012). Version Control with Git: Powerful Tools and Techniques for Collaborative Software Development, O\u2019Reilly Media, Inc, ASIN: 1449316387. Lomax, A., and A. Curtis (2001). Fast, probabilistic earthquake location in 3D models using oct-tree importance sampling, Geophys. Res. Abstr. 3, 955. Mallat, S. (2009). A Wavelet Tour of Signal Processing, Third Ed., Academic Press, Inc., USA, ISBN: 9780123743701. McNamara, D. E., and R. P. Buland (2004). Ambiente noise levels in the continental United States, Bull. Seismol. Soc. Am. doi: 10.1785/ 012003001. Nawab, S., F. Dowla, and R. Lacoss (1985). Direction determination of wideband signals, IEEE Trans. Acoust. Speech Signal Process. 33, no. 5, 1114\u20131122. Nissen-Meyer, T., M. van Driel, S. C. St\u00e4hler, K. Hosseini, S. Hempel, L. Auer, A. Colombi, and A. Fournier (2014). AxiSEM: Broadband 3-D seismic wavefields in axisymmetric media, Solid Earth 5, 425\u2013445, doi: 10.5194/se-5-425-2014. Peterson, J. R. (1993). Observations and modeling of seismic background noise, U.S. Geol. Su\\rv. Open-File Rept. 93-322, doi:10.3133/ofr93322. Podvin, P., and I. Lecomte (1991). Finite difference computation of traveltimes in very contrasted velocity models: A massively parallel approach and its associated tools, Geophys. J. Int. 105, no. 1, 271\u2013284. Prieto, G. A., R. L. Parker, and F. L. Vernon (2009). A Fortran 90 library for multitaper spectrum analysis, Comput. Geosci. doi:10.1016/j.cageo.2008.06.007. Ross, Z. E., M.-A. Meier, E. Hauksson, and T. H. Heaton (2018). Generalized seismic phase detection with deep learning, Bull.Seismol. Soc. Am. 108, no. 5A, 2894\u20132901, doi: 10.1785/0120180080. Rost, S., and C. Thomas (2002). Array seismology: Methods and applications, Rev. Geophys. 40, no. 3, 2\u201327. Ruigrok, E., S. Gibbons, and K. Wapenaar (2017). Cross-correlation beamforming, J. Seismol. 21, no. 3, 495\u2013508. Sambridge, M. (2013). A parallel tempering algorithm for probabilistic sampling and multimodal optimization, Geophys. J. Int. 196, no. 1, 357\u2013374, doi: 10.1093/gji/ggt342. Sambridge, M., and K. Mosegaard (2002). Monte Carlo methods in geophysical inverse problems, Rev. Geophys. 40, no. 3, 3\u201329. Schimmel, M., and H. Paulssen (1997). Noise reduction and detection of weak, coherent signals through phase-weighted stacks, Geophys.J. Int. doi: 10.1111/j.1365-246X.1997.tb05664.x. Smith, W. S., Z. Zeng, and J. Carette (2018). Seismology software: State of the practice, J. Seismol. 22, no. 3, 755\u2013788. Silva, S., P. Terrinha, L. Matias, J. C. Duarte, C. Roque, C. R. Ranero, W. H. Geisslerh, and N. Zitellini (2017). Micro-seismicity in the Gulf of Cadiz: Is there a link between micro-seismicity, high magnitude earthquakes and active faults? Tectonophysics doi: 10.1016/j.tecto.2017.07.026. Stammler, K. (1993). S SeismicHandler\u2014Programmable multichannel data handler for interactive and automatic processing of seismological analyses, Comput. Geosci. 19, no. 2, 135\u2013140. Thomson, D. J. (1982). Spectrum estimation and harmonic analysis, Proc. IEEE 70, no. 9, 1055\u20131096. Torrence, C., and G. P. Compo (1998). A practical guide to wavelet analysis, Bull. Am. Meteorol. Soc. doi: 10.1175/1520-0477(1998) 079<0061:APGTWA>2.0.CO;2. Vack\u00e1\u0159, J., J. Burj\u00e1nek, F. Gallovic, J. Zahradn\u00edk, and J. Clinton (2017). Bayesian ISOLA: New tool for automated centroid moment tensor inversion, Geophys. J. Int. 210, no. 2, 693\u2013705, doi: 10.1093/gji/ggx158. van Driel, M., L. Krischer, S. C. St\u00e4hler, K. Hosseini, and T. Nissen-Meyer (2015). Instaseis: Instant global seismograms based on a broadband waveform database, Solid Earth 6, no. 2, 701\u2013717, doi: 10.5194/se-6-701-2015. Ventosa, S., M. Schimmel, and E. Stutzmann (2017). Extracting surface waves, hum and normal modes: Time-scale phaseweighted stack and beyond, Geophys. J. Int. doi: 10.1093/gji/ggx284. Wathelet, M., J. L. Chatelain, C. Cornou, G. D. Giulio, B. Guillier, M.Ohrnberger, and A. Savvaidis (2020). Geopsy: A user-friendly open-source tool set for ambient vibration processing, Seismol. Res. Lett. 91, no. 3, 1878\u20131889. Zhou, H. (1994). Rapid three-dimensional hypocentral determination using a master station method, J. Geophys. Res. 99, no. B8, 15,439\u201315,455. Zhu, L., and H. Kanamori (2000). Moho depth variation in southern California from teleseismic receiver functions, J. Geophys. Res. 105, no. B2, 2969\u20132980.","title":"References"},{"location":"refs/#references","text":"Boashash, B., and P. Black (1987). An efficient real-time implementation of the Wigner-Ville distribution, IEEE Trans. Acoust. Speech Signal Process. 35, no. 11, 1611\u20131618. Bormann, P., and J. W. Dewey (2012). The new IASPEI standards for determining magnitudes from digital data and their relation to classical magnitudes, in New Manual of Seismological Observatory Practice 2 (NMSOP-2), Deutsches GeoForschungsZentrum GFZ, Potsdam, Germany, 1\u201344. Cabieces, R., E. Buforn, S. Cesca, and A. Pazos (2020). Focal parameters of earthquakes offshore Cape St. Vincent using an amphibious network, Pure Appl. Geophys. doi: 10.1007/s00024-020-02475-3. Cabieces R., Kr\u00fcger, F., Garcia-Yeguas, A., Villase\u00f1or, A., Buforn, E., Pazos, A., Olivar-Casta\u00f1o, A.,Barco, J (2020) Slowness vector estimation over large-aperture sparse arrays with the Continuous Wavelet Transform (CWT): Application to Ocean Bottom Seismometers, Geophysical Journal International, ggaa427, https://doi.org/10.1093/gji/ggaa427 Cabieces, R., Villase\u00f1or, A., Berg, E., Olivar-Casta\u00f1o, A., Arnaiz, M., Ventosa, S & Ferreira, A (2022). Upper Lithosphere structure of northeastern Venezuela from joint inversion of surface waves dispersion and receiver functions. Solid Earth. Capon, J. (1969). High-resolution frequency-wavenumber spectrum analysis, Proc. IEEE 57, no. 8, 1408\u20131418. Clinton, J. F., and T. H. Heaton (2002). Potential advantages of a strong-motion velocity meter over a strong-motion accelerometer, Seismol. Res. Lett. 73, no. 3, 332\u2013342. Daubechies, I. (1992). Ten Lectures on Wavelets, Society for industrial and applied mathematics, doi: 10.1137/1.9781611970104. Flinn, E. A. (1965). Signal analysis using rectilinearity and direction of particle motion, Proc. IEEE 53, no. 12, 1874\u20131876. Font, Y., H. Kao, S. Lallemand, C.-S. Liu, and L.-Y. Chiao (2004). Hypocentre determination offshore of eastern Taiwan using the MaximumIntersectionmethod, Geophys. J. Int. 158, no. 2, 655\u2013675. Gal, M., A. M. Reading, S. P. Ellingsen, K. D. Koper, S. J. Gibbons, and S. P. Nasholm (2014). Improved implementation of the fk and Capon methods for array analysis of seismic noise, Geophys. J. Int. 198, no. 2, 1045\u20131054, doi: 10.1093/gji/ggu183. Goldstein, P., D. Dodge, M. Firpo, and L. Minner (2003). SAC2000: Signal processing and analysis tools for seismologists and engineers, in The IASPEI International Handbook of Earthquake Engineering and Seismology, W. H. K. Lee, H. Kanamori, P. C. Jennings, and C. Kisslinger (Editors), Vol. 81, Academic Press, London, United Kingdom, 1613\u20131620, doi: 10.1016/S0074-6142 (03)80284-X. Goutorbe, B., D. L. de Oliveira Coelho, and S. Drouet (2015). Rayleigh wave group velocities at periods of 6-23 s across Brazil from ambient noise tomography, Geophys. J. Int. 203, no. 2, 869\u2013882. Havskov, J., P. H. Voss, and L. Ottemoller (2020). Seismological observatory software: 30 Yr of SEISAN, Seismol. Res. Lett. 91, no. 3, 1846\u20131852, doi: 10.1785/0220190313. Herrmann, R. B. (2013). Computer programs in seismology: An evolving tool for instruction and research, Seismol. Res. Lett. 84, no. 6, 1081\u20131088, doi: 10.1785/0220110096. Hunter, J. D. (2007). Matplotlib: A 2D graphics environment, Comput. Sci. Eng. 9, no. 3, 90\u201395, doi: 10.1109/MCSE.2007.55. Jiang, C., and M. A. Denolle (2020). NoisePy: A new high-performance Python tool for ambient-noise seismology, Seismol. Res. Lett. 91, no. 3, 1853\u20131866, doi: 10.1785/0220190364. Krischer, L., T. Megies, R. Barsch, M. Beyreuther, T. Lecocq, C. Caudron, and J. Wassermann (2015). ObsPy: A bridge for seismology into the scientific Python ecosystem, Comput. Sci. Discov. doi: 10.1088/1749-4699/8/1/014003. Langston, C. A. (1979). Structure under Mount Rainier, Washington, inferred from teleseismic body waves, J. Geophys. Res. 84, no. B9, 4749\u20134762. Lecocq, T., C. Caudron, and F. Brenguier (2014). MSNoise, a Python package for monitoring seismic velocity changes using ambient seismic noise, Seismol. Res. Lett. 85, no. 3, 715\u2013726. Loeliger, J., and M. McCullough (2012). Version Control with Git: Powerful Tools and Techniques for Collaborative Software Development, O\u2019Reilly Media, Inc, ASIN: 1449316387. Lomax, A., and A. Curtis (2001). Fast, probabilistic earthquake location in 3D models using oct-tree importance sampling, Geophys. Res. Abstr. 3, 955. Mallat, S. (2009). A Wavelet Tour of Signal Processing, Third Ed., Academic Press, Inc., USA, ISBN: 9780123743701. McNamara, D. E., and R. P. Buland (2004). Ambiente noise levels in the continental United States, Bull. Seismol. Soc. Am. doi: 10.1785/ 012003001. Nawab, S., F. Dowla, and R. Lacoss (1985). Direction determination of wideband signals, IEEE Trans. Acoust. Speech Signal Process. 33, no. 5, 1114\u20131122. Nissen-Meyer, T., M. van Driel, S. C. St\u00e4hler, K. Hosseini, S. Hempel, L. Auer, A. Colombi, and A. Fournier (2014). AxiSEM: Broadband 3-D seismic wavefields in axisymmetric media, Solid Earth 5, 425\u2013445, doi: 10.5194/se-5-425-2014. Peterson, J. R. (1993). Observations and modeling of seismic background noise, U.S. Geol. Su\\rv. Open-File Rept. 93-322, doi:10.3133/ofr93322. Podvin, P., and I. Lecomte (1991). Finite difference computation of traveltimes in very contrasted velocity models: A massively parallel approach and its associated tools, Geophys. J. Int. 105, no. 1, 271\u2013284. Prieto, G. A., R. L. Parker, and F. L. Vernon (2009). A Fortran 90 library for multitaper spectrum analysis, Comput. Geosci. doi:10.1016/j.cageo.2008.06.007. Ross, Z. E., M.-A. Meier, E. Hauksson, and T. H. Heaton (2018). Generalized seismic phase detection with deep learning, Bull.Seismol. Soc. Am. 108, no. 5A, 2894\u20132901, doi: 10.1785/0120180080. Rost, S., and C. Thomas (2002). Array seismology: Methods and applications, Rev. Geophys. 40, no. 3, 2\u201327. Ruigrok, E., S. Gibbons, and K. Wapenaar (2017). Cross-correlation beamforming, J. Seismol. 21, no. 3, 495\u2013508. Sambridge, M. (2013). A parallel tempering algorithm for probabilistic sampling and multimodal optimization, Geophys. J. Int. 196, no. 1, 357\u2013374, doi: 10.1093/gji/ggt342. Sambridge, M., and K. Mosegaard (2002). Monte Carlo methods in geophysical inverse problems, Rev. Geophys. 40, no. 3, 3\u201329. Schimmel, M., and H. Paulssen (1997). Noise reduction and detection of weak, coherent signals through phase-weighted stacks, Geophys.J. Int. doi: 10.1111/j.1365-246X.1997.tb05664.x. Smith, W. S., Z. Zeng, and J. Carette (2018). Seismology software: State of the practice, J. Seismol. 22, no. 3, 755\u2013788. Silva, S., P. Terrinha, L. Matias, J. C. Duarte, C. Roque, C. R. Ranero, W. H. Geisslerh, and N. Zitellini (2017). Micro-seismicity in the Gulf of Cadiz: Is there a link between micro-seismicity, high magnitude earthquakes and active faults? Tectonophysics doi: 10.1016/j.tecto.2017.07.026. Stammler, K. (1993). S SeismicHandler\u2014Programmable multichannel data handler for interactive and automatic processing of seismological analyses, Comput. Geosci. 19, no. 2, 135\u2013140. Thomson, D. J. (1982). Spectrum estimation and harmonic analysis, Proc. IEEE 70, no. 9, 1055\u20131096. Torrence, C., and G. P. Compo (1998). A practical guide to wavelet analysis, Bull. Am. Meteorol. Soc. doi: 10.1175/1520-0477(1998) 079<0061:APGTWA>2.0.CO;2. Vack\u00e1\u0159, J., J. Burj\u00e1nek, F. Gallovic, J. Zahradn\u00edk, and J. Clinton (2017). Bayesian ISOLA: New tool for automated centroid moment tensor inversion, Geophys. J. Int. 210, no. 2, 693\u2013705, doi: 10.1093/gji/ggx158. van Driel, M., L. Krischer, S. C. St\u00e4hler, K. Hosseini, and T. Nissen-Meyer (2015). Instaseis: Instant global seismograms based on a broadband waveform database, Solid Earth 6, no. 2, 701\u2013717, doi: 10.5194/se-6-701-2015. Ventosa, S., M. Schimmel, and E. Stutzmann (2017). Extracting surface waves, hum and normal modes: Time-scale phaseweighted stack and beyond, Geophys. J. Int. doi: 10.1093/gji/ggx284. Wathelet, M., J. L. Chatelain, C. Cornou, G. D. Giulio, B. Guillier, M.Ohrnberger, and A. Savvaidis (2020). Geopsy: A user-friendly open-source tool set for ambient vibration processing, Seismol. Res. Lett. 91, no. 3, 1878\u20131889. Zhou, H. (1994). Rapid three-dimensional hypocentral determination using a master station method, J. Geophys. Res. 99, no. B8, 15,439\u201315,455. Zhu, L., and H. Kanamori (2000). Moho depth variation in southern California from teleseismic receiver functions, J. Geophys. Res. 105, no. B2, 2969\u20132980.","title":"References"},{"location":"release_notes/","text":"ISP is licensed under the GNU Lesser General Public License (LGPL) v3.0","title":"Release Notes"},{"location":"rf/","text":"Receiver Functions Get & Cut Eartquakes The receiver functions module uses a water-level deconvolution method to compute P to S receiver functions from earthquake recordings in mseed format. The program can be used to perform the H-k stacking (Zhu & Kanamori, 2000) of the receiver functions for the determination of the crustal thickness and VP/VS ratio, as well as the back-tracing and CCP (\u2018common-conversion point\u2019) stacking. The first step in the receiver function analysis consists in cutting a time window containing the P-wave arrivals for each earthquake and station. The \u2018Cut earthquakes\u2019 tool requires that the data we want to work with is available locally and can be accessed from the Menu Bar under \u2018Tools > Cut earthquakes \u2026\u2019 (Fig. 1). Fig. 1. Screenshot of the 'Cut earthquakes' tool. The numbers in the image are referred to in the text below. The \u2018Raw data\u2019 and \u2018XML/dataless\u2019 fields [1] must point to the directory containing our mseed data and the StationXML/dataless file for the instruments used to record the data (which must contain the location of the stations at least, and the instrumental responses if we wish to remove them). The \u2018Quick file search\u2019 checkbox can be used to quickly index the input files if they follow the naming convention \u201cYEAR.JULDAY.LOC.STATION.CHANNEL.mseed\u201d. If they do not, simply uncheck this option and the code will read the .mseed file headers instead. The buttons labeled with \u2018\u2026\u2019 [2] can be used to select the correct paths through the file explorer. The output of the \u2018Cut earthquakes\u2019 tool consists in a directory containing the windowed earthquakes for each station [3], and a metadata file [4] containing information about each event such as the origin time, location, azimuth, ray parameter, etc. The output paths for these files must also be set by the user. Under the \u2018Settings\u2019 section we can tune a few parameters regarding event selection, quality control and time windowing of the records. The determination of the P-wave arrival time to each station is performed automatically using the TauPy package and the information contained in a event catalog downloaded from a Web Service [5]. The \u2018Earth model\u2019 used in the TauPy computations can be selected using a drop-down menu [6]. The starting and ending dates for the event catalog can be set using [7]. The minimum magnitude of the selected events, the minimum and maximum epicentral distances (in degrees), the minimum acceptable signal-to-noise ratio for each event, and the start and end of the time window to cut from the local record relative to the P-wave arrival time can be set using [8], [9], [10], [11], [12], [13]. The coordinate system in which we want to work, \u2018LQT\u2019 for Q-receiver functions or \u2018ZRT\u2019 for R-receiver functions, can be set using a drop-down menu [14]. Fig. 2. Selection of the metadata file provided in the ISP example files. Estimate RFs Once the P-wave records are cut, the metadata file and a directory with the structure output/station/mseed files should have been created (the output path was set in the \u2018Cut earthquakes\u2019 tool, fields [3] and [4]). To compute and start working with the receiver functions, load the metadata file using the Main menu bar option \u2018Input > Read event data file \u2026\u2019 (Fig. 2). Triggering this option will open the file explorer. Once the metadata file has been successfully loaded, read the P-wave records under \u2018Input > RF Analysis > Read waveforms \u2026\u2019. A new instance of the file explorer will be opened (Fig. 3). It is important that the root directory containing the different station folders (field [3] chosen in the \u2018Cut earthquakes\u2019 tool) is selected, as the directory structure will allow the code to sort the data correctly. In this example, we will use the P-wave recordings and metadata file provided with ISP. These were created from 4 years of continuous recordings of the IU.PAB station (2002 to 2006) downloaded from the IRIS DMC. After correctly selecting the example files, the station \u2018PAB\u2019 will appear in the Water-level deconvolution panel [15] (Fig. 4). The Water-level deconvolution settings include a bandpass filter that is applied to the waveforms prior to deconvolution, with corner frequencies f1 and f2 [16], the width of the low-pass Gaussian filter used in the deconvolution [17], and the water-level itself [18]. These parameters should be tuned to obtain the best results for each individual station, but the default values are usually a good starting point. Once the settings are set, press the \u2018Compute RFs\u2019 button [19] and the receiver functions will appear on the panel [20]. A maximum of 7 receiver functions are displayed at once. Scroll through the different pages using the \u2018<\u2019 and \u2018>\u2019 buttons on the bottom right side of the panel [21]. Poor-quality receiver functions can be discarded by left-clicking on them, and reaccepted by left-clicking again (Fig. 5). Right clicking on the frame of a receiver function will display the waveform from which it was calculated. The \u2018Analysis tools\u2019 panel [22] can be used to change the time range displayed [23], sort the display order of the receiver functions [24] by back-azimuth or distance, discard all events lower than a certain magnitude [25] or remove all rejections, manual or automatic, and accept all receiver functions [26]. The \u2018Receiver function stack\u2019 panel [27] is intended to give the user an overview of all the available receiver functions in use, in order to facilitate their inspection and the detection of poor quality receiver functions that may be harming the results. The stack of all receiver functions is shown in the top part of this panel [28] and stacks at regular intervals of backazimuth or epicentral distance are shown on the bottom panel [29]. The size of these intervals and any desired overlap between them can be adjusted using the fields [30] and [31]. A \u2018Ps\u2019 phase moveout correction can be applied by selecting it in the [32] drop-down menu. To display the stack, simply press the \u2018Update plot\u2019 button [33]. The \u2018H-k stack\u2019 panel [34] displays the results of the H-k stacking, based on Zhu & Kanamori (2000). The code uses the semblance-weighted stacking method proposed by Eaton et al. (2006). The density of crustal thickness \u2013 Vp/Vs ratio (k) points for the H-k matrix can be adjusted using the fields [35], although the default value should be more than enough. The crustal thickness \u2013 Vp/Vs value ranges can be set using the fields [36], and the weights for the Ps, PpPs and PpSs+PsPs phases can be set using the fields [37]. Two widely used sets of weights are 0.70, 0.20, 0.10 and 0.34, 0.33, 0.44 for Ps, PpPs and PpSs+PsPs, respectively. Once satisfied with the parameters, press the \u2018Compute H-k stack\u2019 button. The H-k matrix will be shown, and the location of the maximum will be marked with two white lines. The uncertainty is displayed as a green ellipse and is computed following Eaton et al. (2006). The values and uncertainties for both parameters are shown in two labels below the H-k plot [38], [39]. The results for the PAB station example are H = 31.42, k = 1.73. The EARS result for this station are H = 32 km, k = 1.76 (http://ears.iris.washington.edu/Data/Summary/gauss_2.5/WM/UCM/station.html, last seen 26/01/2021). The event panel is located in the bottom right side of the main window [40] and displays the location of all the events used in the H-k computations. To generate this figure, simply press the \u2018Plot events\u2019 button [41]. For reference, two circles indicating 30 and 90 degrees of epicentral distance from the station are also displayed. After the H-k maximum is determined, the theoretical arrival times of the Ps, PpPs and PpSs+PsPs phases can be displayed on the \u2018Receiver function stack\u2019 panel for reference. For this, check the box labeled as \u2018Show theoretical arrival times\u2019 [42] and press the button \u2018Update plot\u2019 [33]. Two types of results can be saved: the receiver functions (which will be used in the second chapter of this tutorial) and the H-k maximum coordinates, pressing buttons \u2018Save RFs\u2019 [43] and \u2018Save results\u2019 [44], respectively. Both options open a file dialog. The \u2018Save RFs\u2019 [43] function requires the user to select an output folder where the receiver functions for the current station will be dumped as a Python pickle file. The \u2018Save results\u2019 [44] will output the H-k results in .csv format, creating a new file if it doesn\u2019t exist, or appending to an existing file if selected. Figures of the Receiver function stack, the H-k stack, and the event location plot can be saved using the corresponding \u2018Save figure\u2019 button, which will display the Save figure dialog. The \u2018Save figure\u2019 dialog creates a .png or .pdf image of the data being displayed in the main user interface. Height, width, and quality of the figure (DPI) can be chosen, as well as the size of the margins and the figure labels. Fig. 4. Screenshot of the main window. The numbers in the image are referred to in the text above* Back-tracing and CCP stacking of RFs After the receiver functions have been computed and undergone a visual quality control, they can be saved using the \u2018Save RFs\u2019 feature ([43], Fig. 4). The resulting files can be loaded back into the program for the back-tracing and CCP stacking of the receiver functions. The first step is to load the event metadata file produced in the previous chapter. If it is already loaded for the H-k analysis, it will not be necessary to load it again. The second step is to read the saved receiver functions. This can be done under \u2018Input > CCP Stacking > Read RFs \u2026\u2019. Triggering this option will display an open file dialog, in which the directory containing the receiver function files must be selected. Once loaded, switch to the \u201cCCP Stacking\u201d tab in the main window. A map of the stations with available receiver functions will be in display. The stacking is performed over a user-defined grid. This can be done either manually (pressing the \u2018Manual selection\u2019 button in the \u2018Grid Fig. 5. Cross section map and CCP stacking","title":"Receiver Functions"},{"location":"rf/#receiver-functions","text":"","title":"Receiver Functions"},{"location":"rf/#get-cut-eartquakes","text":"The receiver functions module uses a water-level deconvolution method to compute P to S receiver functions from earthquake recordings in mseed format. The program can be used to perform the H-k stacking (Zhu & Kanamori, 2000) of the receiver functions for the determination of the crustal thickness and VP/VS ratio, as well as the back-tracing and CCP (\u2018common-conversion point\u2019) stacking. The first step in the receiver function analysis consists in cutting a time window containing the P-wave arrivals for each earthquake and station. The \u2018Cut earthquakes\u2019 tool requires that the data we want to work with is available locally and can be accessed from the Menu Bar under \u2018Tools > Cut earthquakes \u2026\u2019 (Fig. 1). Fig. 1. Screenshot of the 'Cut earthquakes' tool. The numbers in the image are referred to in the text below. The \u2018Raw data\u2019 and \u2018XML/dataless\u2019 fields [1] must point to the directory containing our mseed data and the StationXML/dataless file for the instruments used to record the data (which must contain the location of the stations at least, and the instrumental responses if we wish to remove them). The \u2018Quick file search\u2019 checkbox can be used to quickly index the input files if they follow the naming convention \u201cYEAR.JULDAY.LOC.STATION.CHANNEL.mseed\u201d. If they do not, simply uncheck this option and the code will read the .mseed file headers instead. The buttons labeled with \u2018\u2026\u2019 [2] can be used to select the correct paths through the file explorer. The output of the \u2018Cut earthquakes\u2019 tool consists in a directory containing the windowed earthquakes for each station [3], and a metadata file [4] containing information about each event such as the origin time, location, azimuth, ray parameter, etc. The output paths for these files must also be set by the user. Under the \u2018Settings\u2019 section we can tune a few parameters regarding event selection, quality control and time windowing of the records. The determination of the P-wave arrival time to each station is performed automatically using the TauPy package and the information contained in a event catalog downloaded from a Web Service [5]. The \u2018Earth model\u2019 used in the TauPy computations can be selected using a drop-down menu [6]. The starting and ending dates for the event catalog can be set using [7]. The minimum magnitude of the selected events, the minimum and maximum epicentral distances (in degrees), the minimum acceptable signal-to-noise ratio for each event, and the start and end of the time window to cut from the local record relative to the P-wave arrival time can be set using [8], [9], [10], [11], [12], [13]. The coordinate system in which we want to work, \u2018LQT\u2019 for Q-receiver functions or \u2018ZRT\u2019 for R-receiver functions, can be set using a drop-down menu [14]. Fig. 2. Selection of the metadata file provided in the ISP example files.","title":"Get &amp; Cut Eartquakes"},{"location":"rf/#estimate-rfs","text":"Once the P-wave records are cut, the metadata file and a directory with the structure output/station/mseed files should have been created (the output path was set in the \u2018Cut earthquakes\u2019 tool, fields [3] and [4]). To compute and start working with the receiver functions, load the metadata file using the Main menu bar option \u2018Input > Read event data file \u2026\u2019 (Fig. 2). Triggering this option will open the file explorer. Once the metadata file has been successfully loaded, read the P-wave records under \u2018Input > RF Analysis > Read waveforms \u2026\u2019. A new instance of the file explorer will be opened (Fig. 3). It is important that the root directory containing the different station folders (field [3] chosen in the \u2018Cut earthquakes\u2019 tool) is selected, as the directory structure will allow the code to sort the data correctly. In this example, we will use the P-wave recordings and metadata file provided with ISP. These were created from 4 years of continuous recordings of the IU.PAB station (2002 to 2006) downloaded from the IRIS DMC. After correctly selecting the example files, the station \u2018PAB\u2019 will appear in the Water-level deconvolution panel [15] (Fig. 4). The Water-level deconvolution settings include a bandpass filter that is applied to the waveforms prior to deconvolution, with corner frequencies f1 and f2 [16], the width of the low-pass Gaussian filter used in the deconvolution [17], and the water-level itself [18]. These parameters should be tuned to obtain the best results for each individual station, but the default values are usually a good starting point. Once the settings are set, press the \u2018Compute RFs\u2019 button [19] and the receiver functions will appear on the panel [20]. A maximum of 7 receiver functions are displayed at once. Scroll through the different pages using the \u2018<\u2019 and \u2018>\u2019 buttons on the bottom right side of the panel [21]. Poor-quality receiver functions can be discarded by left-clicking on them, and reaccepted by left-clicking again (Fig. 5). Right clicking on the frame of a receiver function will display the waveform from which it was calculated. The \u2018Analysis tools\u2019 panel [22] can be used to change the time range displayed [23], sort the display order of the receiver functions [24] by back-azimuth or distance, discard all events lower than a certain magnitude [25] or remove all rejections, manual or automatic, and accept all receiver functions [26]. The \u2018Receiver function stack\u2019 panel [27] is intended to give the user an overview of all the available receiver functions in use, in order to facilitate their inspection and the detection of poor quality receiver functions that may be harming the results. The stack of all receiver functions is shown in the top part of this panel [28] and stacks at regular intervals of backazimuth or epicentral distance are shown on the bottom panel [29]. The size of these intervals and any desired overlap between them can be adjusted using the fields [30] and [31]. A \u2018Ps\u2019 phase moveout correction can be applied by selecting it in the [32] drop-down menu. To display the stack, simply press the \u2018Update plot\u2019 button [33]. The \u2018H-k stack\u2019 panel [34] displays the results of the H-k stacking, based on Zhu & Kanamori (2000). The code uses the semblance-weighted stacking method proposed by Eaton et al. (2006). The density of crustal thickness \u2013 Vp/Vs ratio (k) points for the H-k matrix can be adjusted using the fields [35], although the default value should be more than enough. The crustal thickness \u2013 Vp/Vs value ranges can be set using the fields [36], and the weights for the Ps, PpPs and PpSs+PsPs phases can be set using the fields [37]. Two widely used sets of weights are 0.70, 0.20, 0.10 and 0.34, 0.33, 0.44 for Ps, PpPs and PpSs+PsPs, respectively. Once satisfied with the parameters, press the \u2018Compute H-k stack\u2019 button. The H-k matrix will be shown, and the location of the maximum will be marked with two white lines. The uncertainty is displayed as a green ellipse and is computed following Eaton et al. (2006). The values and uncertainties for both parameters are shown in two labels below the H-k plot [38], [39]. The results for the PAB station example are H = 31.42, k = 1.73. The EARS result for this station are H = 32 km, k = 1.76 (http://ears.iris.washington.edu/Data/Summary/gauss_2.5/WM/UCM/station.html, last seen 26/01/2021). The event panel is located in the bottom right side of the main window [40] and displays the location of all the events used in the H-k computations. To generate this figure, simply press the \u2018Plot events\u2019 button [41]. For reference, two circles indicating 30 and 90 degrees of epicentral distance from the station are also displayed. After the H-k maximum is determined, the theoretical arrival times of the Ps, PpPs and PpSs+PsPs phases can be displayed on the \u2018Receiver function stack\u2019 panel for reference. For this, check the box labeled as \u2018Show theoretical arrival times\u2019 [42] and press the button \u2018Update plot\u2019 [33]. Two types of results can be saved: the receiver functions (which will be used in the second chapter of this tutorial) and the H-k maximum coordinates, pressing buttons \u2018Save RFs\u2019 [43] and \u2018Save results\u2019 [44], respectively. Both options open a file dialog. The \u2018Save RFs\u2019 [43] function requires the user to select an output folder where the receiver functions for the current station will be dumped as a Python pickle file. The \u2018Save results\u2019 [44] will output the H-k results in .csv format, creating a new file if it doesn\u2019t exist, or appending to an existing file if selected. Figures of the Receiver function stack, the H-k stack, and the event location plot can be saved using the corresponding \u2018Save figure\u2019 button, which will display the Save figure dialog. The \u2018Save figure\u2019 dialog creates a .png or .pdf image of the data being displayed in the main user interface. Height, width, and quality of the figure (DPI) can be chosen, as well as the size of the margins and the figure labels. Fig. 4. Screenshot of the main window. The numbers in the image are referred to in the text above*","title":"Estimate RFs"},{"location":"rf/#back-tracing-and-ccp-stacking-of-rfs","text":"After the receiver functions have been computed and undergone a visual quality control, they can be saved using the \u2018Save RFs\u2019 feature ([43], Fig. 4). The resulting files can be loaded back into the program for the back-tracing and CCP stacking of the receiver functions. The first step is to load the event metadata file produced in the previous chapter. If it is already loaded for the H-k analysis, it will not be necessary to load it again. The second step is to read the saved receiver functions. This can be done under \u2018Input > CCP Stacking > Read RFs \u2026\u2019. Triggering this option will display an open file dialog, in which the directory containing the receiver function files must be selected. Once loaded, switch to the \u201cCCP Stacking\u201d tab in the main window. A map of the stations with available receiver functions will be in display. The stacking is performed over a user-defined grid. This can be done either manually (pressing the \u2018Manual selection\u2019 button in the \u2018Grid Fig. 5. Cross section map and CCP stacking","title":"Back-tracing and CCP stacking of RFs"},{"location":"synth/","text":"Synthetic Generator The synthetic toolbox is a toolbox designed to request synthetic seismograms from IRIS Synthetics Engine (Syngine). To make a query just add the location of the stations for the synthetics be generated. In this step the user has two options. Add coordinates plus station name and network manually Load a coordinates files with the following structure Latitude;Longitude;Network;Station 35.8;-3.0;WM;ARNO 36.9;-4.0;XX;OBS01 37.2;-5.0;WM;SFS Design a line with a number of stations from a specific geografic reference point. Just fill the following dialog: Then choose a model, units (velocity, displacement or acceleration) the source coordinates and time spam and, very important, the type of source and focal parameters. Click at apply button and then the query will be send. Finally ISP will ask for a folder where will be save the seismograms in mseed format, the information related with the query in a file.json and the coordinates of the stations. Finally, you can rapidly visualize the seismograms just following the example below. you will find the data at ISP/isp/example/Synthetic_mti to replicate the example. From left to right. Filter your seismogram selection : by Nets, Station or channel. For example Nets WM, Stations OBS01 Channels OBS01 then pres Read Files to filter the seismogram selection to be shown. PA button : take the phases from the Attival Times and plot the theoretical values on the screen. Stations Info : will show basic information of the seismograms such as number of point, sampling rate, start time and end time. Spectrum will process and plot the amplitude spectrum of the seismograms. Size : is simply the amplification factor to visualize the seimograms. Plot button : will plot the seismograms (after applied selection filter using read files and the boxes Netwrok, station and channels). Try it! Map : will show the beach ball repreentimg the focal mechanism and the map with the epicenter and the stations distribution","title":"Synthetic Generator"},{"location":"synth/#synthetic-generator","text":"The synthetic toolbox is a toolbox designed to request synthetic seismograms from IRIS Synthetics Engine (Syngine). To make a query just add the location of the stations for the synthetics be generated. In this step the user has two options. Add coordinates plus station name and network manually Load a coordinates files with the following structure Latitude;Longitude;Network;Station 35.8;-3.0;WM;ARNO 36.9;-4.0;XX;OBS01 37.2;-5.0;WM;SFS Design a line with a number of stations from a specific geografic reference point. Just fill the following dialog: Then choose a model, units (velocity, displacement or acceleration) the source coordinates and time spam and, very important, the type of source and focal parameters. Click at apply button and then the query will be send. Finally ISP will ask for a folder where will be save the seismograms in mseed format, the information related with the query in a file.json and the coordinates of the stations. Finally, you can rapidly visualize the seismograms just following the example below. you will find the data at ISP/isp/example/Synthetic_mti to replicate the example. From left to right. Filter your seismogram selection : by Nets, Station or channel. For example Nets WM, Stations OBS01 Channels OBS01 then pres Read Files to filter the seismogram selection to be shown. PA button : take the phases from the Attival Times and plot the theoretical values on the screen. Stations Info : will show basic information of the seismograms such as number of point, sampling rate, start time and end time. Spectrum will process and plot the amplitude spectrum of the seismograms. Size : is simply the amplification factor to visualize the seimograms. Plot button : will plot the seismograms (after applied selection filter using read files and the boxes Netwrok, station and channels). Try it! Map : will show the beach ball repreentimg the focal mechanism and the map with the epicenter and the stations distribution","title":"Synthetic Generator"},{"location":"tf/","text":"Time-Frequency Analysis Multitaper, CWT and Wigner Distribution The Time-Frequency Analysis window is designed to facilitate the computation of advanced seismic signal processes on individual seismograms. The seismograms are selected in the files explorer. You can also set a macro with basic process before running any time-Frequency analysis The most important is the selection of the Seismogram (the analysis will be show in the upper panel . \u201cseismogram 1\u201d and lower panel seismogram 2). Then you can select which one of Time-Frequency analysis you want to compute. Before Compute the Time-Frequency analysis be sure that you have filled the parameters of that kind of analysis (MT for multitaper spectrogram and CWT for Continuous Wavelet Transform). With respect to the Wavelet: The wavelet needs, select the wavelet (Morlet, Paul or Mexican Hat are available) and fill the parameters in accordance to the selected wavelet (Mallat, 2009). With respect to the Multitaper (Thomson, 1982): His analysis needs to specify the Window Length, Time-Bandwidth, the Number of Tapers and the range of the frequencies Advanced TF analysis (two seismograms at once) In the Figures are shown an example of computation of CWT and the uncertainty cone using the Morlet wavelet (upper panel) and multitaper spectrogram (lower panel). In the multimedia material can be found an example of how to mange the TF framework. Once two seismograms are selected we can follow with more advanced signal processing (Open advanced analysis): Spectrum Comparison >>> plot the amplitude and phase spectrum individual and together (Fig. 2). Coherence >>> Plot the magnitude square coherence and its phase (Fig. 3). Cross Correlation >>> Plot the Autocorrelations and the cross correlation of both signals (Fig. 4). Cross Wavelet >>> Plot the Cross-CWT of both signals (Fig. 5). Connect with Earthquake Analysis Super easy, when you have a waveform plot in Earquake analysis, hold your mouse over the waveform and press \" m \". This action will save your waveform data to be ready to send it to TF Analysis. A wavelet symbol will appear in the bottom left corner of the waveform plot. Now just, click over the the symbol of TF Anlysis icon in the Upper part of the widget This action will open TF Analysis and will launch Seismogram 3. Split into Long period and High frequency running the CWT. If you have loeaded the metadata and fill the event box, the travel times will also be shown. Multimedia Material (Time-Frequency Analysis) The following video shows a basic analysis of an earthquake Shortcuts Shortcut Action 'q' Set start time 'w' Process and Plot 'e' Set end time","title":"Time-Frequency Analysis"},{"location":"tf/#time-frequency-analysis","text":"","title":"Time-Frequency Analysis"},{"location":"tf/#multitaper-cwt-and-wigner-distribution","text":"The Time-Frequency Analysis window is designed to facilitate the computation of advanced seismic signal processes on individual seismograms. The seismograms are selected in the files explorer. You can also set a macro with basic process before running any time-Frequency analysis The most important is the selection of the Seismogram (the analysis will be show in the upper panel . \u201cseismogram 1\u201d and lower panel seismogram 2). Then you can select which one of Time-Frequency analysis you want to compute. Before Compute the Time-Frequency analysis be sure that you have filled the parameters of that kind of analysis (MT for multitaper spectrogram and CWT for Continuous Wavelet Transform). With respect to the Wavelet: The wavelet needs, select the wavelet (Morlet, Paul or Mexican Hat are available) and fill the parameters in accordance to the selected wavelet (Mallat, 2009). With respect to the Multitaper (Thomson, 1982): His analysis needs to specify the Window Length, Time-Bandwidth, the Number of Tapers and the range of the frequencies","title":"Multitaper, CWT and Wigner Distribution"},{"location":"tf/#advanced-tf-analysis-two-seismograms-at-once","text":"In the Figures are shown an example of computation of CWT and the uncertainty cone using the Morlet wavelet (upper panel) and multitaper spectrogram (lower panel). In the multimedia material can be found an example of how to mange the TF framework. Once two seismograms are selected we can follow with more advanced signal processing (Open advanced analysis): Spectrum Comparison >>> plot the amplitude and phase spectrum individual and together (Fig. 2). Coherence >>> Plot the magnitude square coherence and its phase (Fig. 3). Cross Correlation >>> Plot the Autocorrelations and the cross correlation of both signals (Fig. 4). Cross Wavelet >>> Plot the Cross-CWT of both signals (Fig. 5).","title":"Advanced TF analysis (two seismograms at once)"},{"location":"tf/#connect-with-earthquake-analysis","text":"Super easy, when you have a waveform plot in Earquake analysis, hold your mouse over the waveform and press \" m \". This action will save your waveform data to be ready to send it to TF Analysis. A wavelet symbol will appear in the bottom left corner of the waveform plot. Now just, click over the the symbol of TF Anlysis icon in the Upper part of the widget This action will open TF Analysis and will launch Seismogram 3. Split into Long period and High frequency running the CWT. If you have loeaded the metadata and fill the event box, the travel times will also be shown.","title":"Connect with Earthquake Analysis"},{"location":"tf/#multimedia-material-time-frequency-analysis","text":"The following video shows a basic analysis of an earthquake","title":"Multimedia Material (Time-Frequency Analysis)"},{"location":"tf/#shortcuts","text":"Shortcut Action 'q' Set start time 'w' Process and Plot 'e' Set end time","title":"Shortcuts"}]}