{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Integrated Seismic Program (ISP) Documentation Integrated Seismic Program is an amenable toolbox that joins functionality and standard algorithms commonly used in seismology. The complete software is separated in several modules and each module is designed to overcome a specific task. In this tutorial will show how you can master ISP GitHub ISP github . Follow us in: twitter . Website ISP website Contact : info@integratedseismicprogram.com . Reference Paper: Integrated Seismic Program (ISP): A new Python GUI-based software for earthquake seismology and seismic signal processing. R. Cabieces, A. Olivar-Casta\u00f1o, T. C. Junqueira, J. Relinque, J. Vack\u00e1r, L. Fernandez-Prieto, J. Barco, A. Pazos and L. Garc\u00eda-Mart\u00ednez, Seismological Research Letters (Under Review). News 2021-11-16 We are working on the second version. The ISP team has recently developed the new module: Seismic Ambient Noise Tomography For now, It is available the Empirical Green Functions retrieval of vertical and Horizontal components. Real Time Acquisition You can play with this new tool, soon we incorporate the corresponding tutorial. Moreover, we are improving Array Analysis module adding BackProjection Tab widget. This new tab will facilitate the estimation of big earthquakes BackProjection using large aperture arrays with many stations.","title":"Home"},{"location":"#welcome-to-integrated-seismic-program-isp-documentation","text":"Integrated Seismic Program is an amenable toolbox that joins functionality and standard algorithms commonly used in seismology. The complete software is separated in several modules and each module is designed to overcome a specific task. In this tutorial will show how you can master ISP GitHub ISP github . Follow us in: twitter . Website ISP website Contact : info@integratedseismicprogram.com . Reference Paper: Integrated Seismic Program (ISP): A new Python GUI-based software for earthquake seismology and seismic signal processing. R. Cabieces, A. Olivar-Casta\u00f1o, T. C. Junqueira, J. Relinque, J. Vack\u00e1r, L. Fernandez-Prieto, J. Barco, A. Pazos and L. Garc\u00eda-Mart\u00ednez, Seismological Research Letters (Under Review).","title":"Welcome to Integrated Seismic Program (ISP) Documentation"},{"location":"#news-2021-11-16","text":"We are working on the second version. The ISP team has recently developed the new module: Seismic Ambient Noise Tomography For now, It is available the Empirical Green Functions retrieval of vertical and Horizontal components. Real Time Acquisition You can play with this new tool, soon we incorporate the corresponding tutorial. Moreover, we are improving Array Analysis module adding BackProjection Tab widget. This new tab will facilitate the estimation of big earthquakes BackProjection using large aperture arrays with many stations.","title":"News 2021-11-16"},{"location":"Special_Thanks/","text":"The Developer Team of ISP thanks to: Anthony Lomax and Claudio Satriano for helping in NLL configuration and the help in the framework 3D-model Visualisation. ObsPy developers and users community for giving a hand to this project during the last few years. Real Instituto y Observatorio de la Armada (Spain), University of Potsdam (Germany), Institute of Rock Structure and Mechanic (Chzechia), University of Oviedo (Spain), Universidad de Granada (Spain), Instituto de Ciencias del Mar (Spain) and Instituto Geogr\u00e1fico Nacional (Spain).","title":"The Developer Team of ISP thanks to:"},{"location":"Special_Thanks/#the-developer-team-of-isp-thanks-to","text":"Anthony Lomax and Claudio Satriano for helping in NLL configuration and the help in the framework 3D-model Visualisation. ObsPy developers and users community for giving a hand to this project during the last few years. Real Instituto y Observatorio de la Armada (Spain), University of Potsdam (Germany), Institute of Rock Structure and Mechanic (Chzechia), University of Oviedo (Spain), Universidad de Granada (Spain), Instituto de Ciencias del Mar (Spain) and Instituto Geogr\u00e1fico Nacional (Spain).","title":"The Developer Team of ISP thanks to:"},{"location":"aa/","text":"Array Analysis Array Response Function (ARF) The Array Response Function (ARF) (Ruigrok et al., 2017) helps to evaluate the resolution of the array in a specific bandwidth. First you need to create a coordinates files and then load it. To create the coordinate file go to \u201cFiles >>> Stations Coordinates\u201d and fill the table with lat (o), lon (o) and depth (km). Then you can compute the ARF and plot the map with the array stations. Frequency-Wavenumber Analysis The Frequency-Wavenumber (FK) is basically a method to compute the beamforming in the frequency domain (Capon, 1969). To compute the FK you need follow this steps; Files: Path where you have the seismograms Dataless: path where you have the metadata ( .dlsv or .xml) Set temporal window of the analysis and check the box Trim Plot the seismograms Fill the parameters (Slowness Max, Time Window, overlap\u2026\u2026) Choose methods Press Run F-K Now, you will watch in the upper panels the Rel Power, Absolute Power, Back-Azimuth and Slowness results of your analysis. Two more actions: Double pick in the upper panels will run the FK in that specific time window (starting in the point). Then, the slowness map and the stack corresponding to the delays of the maximum power in the slowness vector will show up. The pick with the slowness vector corresponding to the phase you selected are automatically saved in the file \u201cisp/arrayanalysis/dataframe.csv\u201d and you can open the file just pressing \u201cctrl+o\u201d Vespagram The vespagram is a visualization of the FK results for an specific backazimuth or slowness. So, once you have done the FK analysis, you can compute the vespagram (Rost and Thomas, 2002). But before, you must select the time window. Go with the mouse to the any upper panel. Pick, hold and drag to the right direction to do the selection. Now you can open the vespagram window. In the vespagram window you can select the parameters (Win length, overlap, and frequency bandwidth of the analysis) and the backazimuth and slowness where you want to compute the vespagram. Multimedia Material (Array Analysis) The following video shows a basic analysis of a nueclear explotion (Test from Nort Korea test 2017, Alaska Array ILAR)","title":"Array Analysis"},{"location":"aa/#array-analysis","text":"","title":"Array Analysis"},{"location":"aa/#array-response-function-arf","text":"The Array Response Function (ARF) (Ruigrok et al., 2017) helps to evaluate the resolution of the array in a specific bandwidth. First you need to create a coordinates files and then load it. To create the coordinate file go to \u201cFiles >>> Stations Coordinates\u201d and fill the table with lat (o), lon (o) and depth (km). Then you can compute the ARF and plot the map with the array stations.","title":"Array Response Function (ARF)"},{"location":"aa/#frequency-wavenumber-analysis","text":"The Frequency-Wavenumber (FK) is basically a method to compute the beamforming in the frequency domain (Capon, 1969). To compute the FK you need follow this steps; Files: Path where you have the seismograms Dataless: path where you have the metadata ( .dlsv or .xml) Set temporal window of the analysis and check the box Trim Plot the seismograms Fill the parameters (Slowness Max, Time Window, overlap\u2026\u2026) Choose methods Press Run F-K Now, you will watch in the upper panels the Rel Power, Absolute Power, Back-Azimuth and Slowness results of your analysis. Two more actions: Double pick in the upper panels will run the FK in that specific time window (starting in the point). Then, the slowness map and the stack corresponding to the delays of the maximum power in the slowness vector will show up. The pick with the slowness vector corresponding to the phase you selected are automatically saved in the file \u201cisp/arrayanalysis/dataframe.csv\u201d and you can open the file just pressing \u201cctrl+o\u201d","title":"Frequency-Wavenumber Analysis"},{"location":"aa/#vespagram","text":"The vespagram is a visualization of the FK results for an specific backazimuth or slowness. So, once you have done the FK analysis, you can compute the vespagram (Rost and Thomas, 2002). But before, you must select the time window. Go with the mouse to the any upper panel. Pick, hold and drag to the right direction to do the selection. Now you can open the vespagram window. In the vespagram window you can select the parameters (Win length, overlap, and frequency bandwidth of the analysis) and the backazimuth and slowness where you want to compute the vespagram.","title":"Vespagram"},{"location":"aa/#multimedia-material-array-analysis","text":"The following video shows a basic analysis of a nueclear explotion (Test from Nort Korea test 2017, Alaska Array ILAR)","title":"Multimedia Material (Array Analysis)"},{"location":"ant/","text":"Ambient Noise Tomography (in progress) The module ANT, currently is just designed to retrieve the Empirical Green Functions (EGFs). EGFs Setting Parameters for the pre-processing steps of the EGFs. Setting Metadata and Files Path To set the path to the metadata of your network and the path where you have hosted your seismogram files. The files can be located in any kind of structure, for example in SDS arquitecture ( NETWORK/STATION/CHANNEL/FILES ) or simply everything in one single folder. Then set the folder where you want the output of the pre-processing and the EGFs. Run pre-processing Now, click on Run pre-processing. This action will load your settings and will make a database of the available files. Then the process will start to process the data. Finally per every station/channel a file will be saved containing a matrix with the noise data in frequency domain, ready to cross-correlate. Run Stack This action will load files from the pre-processing step and then for every channel-channel combination will do a cross correlation and stack all the stacks will be saved in the .outpur_directory/stack. Process and Plot In this point the user can set the path to the output files (hdf5 or sac files), read the files and then process and plot . The user can also establish a Macro to process the EGFs, plot a map and sort the EGFs by inter station distance. Notice that autocorrelations will be 0 distance.","title":"Ambient Noise Tomography"},{"location":"ant/#ambient-noise-tomography-in-progress","text":"The module ANT, currently is just designed to retrieve the Empirical Green Functions (EGFs).","title":"Ambient Noise Tomography (in progress)"},{"location":"ant/#egfs","text":"Setting Parameters for the pre-processing steps of the EGFs. Setting Metadata and Files Path To set the path to the metadata of your network and the path where you have hosted your seismogram files. The files can be located in any kind of structure, for example in SDS arquitecture ( NETWORK/STATION/CHANNEL/FILES ) or simply everything in one single folder. Then set the folder where you want the output of the pre-processing and the EGFs.","title":"EGFs"},{"location":"ant/#run-pre-processing","text":"Now, click on Run pre-processing. This action will load your settings and will make a database of the available files. Then the process will start to process the data. Finally per every station/channel a file will be saved containing a matrix with the noise data in frequency domain, ready to cross-correlate.","title":"Run pre-processing"},{"location":"ant/#run-stack","text":"This action will load files from the pre-processing step and then for every channel-channel combination will do a cross correlation and stack all the stacks will be saved in the .outpur_directory/stack.","title":"Run Stack"},{"location":"ant/#process-and-plot","text":"In this point the user can set the path to the output files (hdf5 or sac files), read the files and then process and plot . The user can also establish a Macro to process the EGFs, plot a map and sort the EGFs by inter station distance. Notice that autocorrelations will be 0 distance.","title":"Process and Plot"},{"location":"basics/","text":"Warming tutorial This section will show you the overall structure of the project and a basic idea of how are the data managed by ISP. Project Structure The current (ISP 1.0) structure of the project is showed in the plot below. We also show a scheme-description of the project. We include some of the most relevant files, such as OBSs/out.txt (output observations) ISP/ \u251c\u2500\u2500 install \u251c\u2500\u2500 isp \u2502 \u251c\u2500\u2500 DataProcessing \u2502 \u2502 \u251c\u2500\u2500 NeuralNetwork \u2502 \u2502 \u2502 \u251c\u2500\u2500 model \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 red_modelo.json \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 red_pesos.hdf5 \u2502 \u2502 \u2502 \u251c\u2500\u2500 picking_cnn_s_p_waves.py \u2502 \u2502 \u251c\u2500\u2500 dataless_manager.py \u2502 \u2502 \u251c\u2500\u2500 metadata_manager.py \u2502 \u2502 \u251c\u2500\u2500 plot_tools_manager.py \u2502 \u2502 \u251c\u2500\u2500 seismogram_analysis.py \u2502 \u2502 \u2514\u2500\u2500 wavelet.py \u2502 \u251c\u2500\u2500 FOCMEC \u2502 \u2502 \u2514\u2500\u2500 bin \u2502 \u2502 \u2514\u2500\u2500 focmec \u2502 \u251c\u2500\u2500 Gui \u2502 \u2502 \u251c\u2500\u2500 Frames \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_parameters.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 array_analysis_frames.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 crustal_model_parameters_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 data_download_tool.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 earth_model_viewer.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 earthquake_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 earthquake_frame_tabs.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 event_location_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 help_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 isola_ISP_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 main.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 matplotlib_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 open_magnitudes_calc.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 parameters.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 plot_polarization.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 ppsds_db_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 ppsds_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 qt_components.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 receiver_functions_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 settings_dialog.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 stations_coordinates.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 stations_info.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 synthetics_analysis_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 synthetics_generator_dialog.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 time_frequency_advance_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 time_frequency_frames.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 time_frequency_frames_old.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 uis_frames.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 vespagram.py \u2502 \u2502 \u251c\u2500\u2500 Models \u2502 \u2502 \u2502 \u2514\u2500\u2500 sql_alchemy_model.py \u2502 \u2502 \u251c\u2500\u2500 StyleLib \u2502 \u2502 \u2502 \u2514\u2500\u2500 isp.mplstyle \u2502 \u2502 \u251c\u2500\u2500 Utils \u2502 \u2502 \u2502 \u251c\u2500\u2500 matplotlib_util.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 pyqt_decorators.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 pyqt_utils.py \u2502 \u2502 \u251c\u2500\u2500 controllers \u2502 \u2502 \u2502 \u2514\u2500\u2500 window_controller.py \u2502 \u2502 \u251c\u2500\u2500 databases \u2502 \u2502 \u2502 \u2514\u2500\u2500 isp_test.db \u2502 \u251c\u2500\u2500 Metadata \u2502 \u2502 \u251c\u2500\u2500 dataless \u2502 \u2502 \u2502 \u2514\u2500\u2500 dataless.dlsv \u2502 \u2502 \u2514\u2500\u2500 xml \u2502 \u2502 \u2514\u2500\u2500 metadata.xml \u2502 \u251c\u2500\u2500 NLL7 \u2502 \u2502 \u251c\u2500\u2500 bin \u2502 \u2502 \u2514\u2500\u2500 src \u2502 \u251c\u2500\u2500 PPSDS_Utils \u2502 \u2502 \u2514\u2500\u2500 ppsds_utils.py \u2502 \u251c\u2500\u2500 Structures \u2502 \u2502 \u251c\u2500\u2500 obspy_stats_keys.py \u2502 \u2502 \u2514\u2500\u2500 structures.py \u2502 \u251c\u2500\u2500 Test \u2502 \u251c\u2500\u2500 Utils \u2502 \u2502 \u251c\u2500\u2500 class_decorators.py \u2502 \u2502 \u251c\u2500\u2500 nllOrgErrors.py \u2502 \u2502 \u251c\u2500\u2500 obspy_utils.py \u2502 \u2502 \u251c\u2500\u2500 subprocess_utils.py \u2502 \u2502 \u2514\u2500\u2500 time_utils.py \u2502 \u251c\u2500\u2500 arrayanalysis \u2502 \u2502 \u251c\u2500\u2500 array_analysis.py \u2502 \u2502 \u2514\u2500\u2500 stations \u2502 \u2502 \u251c\u2500\u2500 coords.txt \u2502 \u251c\u2500\u2500 db \u2502 \u2502 \u251c\u2500\u2500 data_base.py \u2502 \u2502 \u251c\u2500\u2500 map_class \u2502 \u2502 \u2502 \u251c\u2500\u2500 clases_mpl_pyqt.py \u2502 \u2502 \u2514\u2500\u2500 models \u2502 \u2502 \u251c\u2500\u2500 base_model.py \u2502 \u2502 \u2514\u2500\u2500 models.py \u2502 \u251c\u2500\u2500 earthquakeAnalisysis \u2502 \u2502 \u251c\u2500\u2500 NLLGrid.py \u2502 \u2502 \u251c\u2500\u2500 auto_detect \u2502 \u2502 \u2502 \u251c\u2500\u2500 events \u2502 \u2502 \u2502 \u2514\u2500\u2500 phases \u2502 \u2502 \u251c\u2500\u2500 ellipsoid.py \u2502 \u2502 \u251c\u2500\u2500 first_polarity.py \u2502 \u2502 \u251c\u2500\u2500 focmecobspy.py \u2502 \u2502 \u251c\u2500\u2500 location_output \u2502 \u2502 \u2502 \u251c\u2500\u2500 ak135 \u2502 \u2502 \u2502 \u251c\u2500\u2500 all_locations \u2502 \u2502 \u2502 \u251c\u2500\u2500 first_polarity \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 focmec.lst \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 focmec_run \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 log.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 mechanism.out \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 rfocmec_RW \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 rfocmec_UW \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 test.inp \u2502 \u2502 \u2502 \u251c\u2500\u2500 loc \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 last.hyp \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 last.hyp.scat.xyz \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 location_run_temp.txt \u2502 \u2502 \u2502 \u251c\u2500\u2500 local_models \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 modelP \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 modelS \u2502 \u2502 \u2502 \u251c\u2500\u2500 model \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 layer.P.mod.buf \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 layer.P.mod.hdr \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 layer.S.mod.buf \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 layer.S.mod.hdr \u2502 \u2502 \u2502 \u251c\u2500\u2500 model3D \u2502 \u2502 \u2502 \u251c\u2500\u2500 obs \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 output.txt \u2502 \u2502 \u2502 \u251c\u2500\u2500 run \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 g2t_template \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 global_template \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 run_template \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 v2g_template \u2502 \u2502 \u2502 \u251c\u2500\u2500 stations \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 stations.txt \u2502 \u2502 \u2502 \u251c\u2500\u2500 temp \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 G2T_temp.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 info.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 input.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 run_temp.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 stations.txt \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 test_grd2time.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_fp \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 focmec.lst \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 mechanism.out \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 test.inp \u2502 \u2502 \u2502 \u2514\u2500\u2500 time \u2502 \u2502 \u251c\u2500\u2500 magnitude_atenuation \u2502 \u2502 \u2502 \u2514\u2500\u2500 atenuation.txt \u2502 \u2502 \u251c\u2500\u2500 pdf_plot.py \u2502 \u2502 \u251c\u2500\u2500 picker_manager.py \u2502 \u2502 \u251c\u2500\u2500 rotate.py \u2502 \u2502 \u251c\u2500\u2500 run_nll.py \u2502 \u2502 \u2514\u2500\u2500 stations_map.py \u2502 \u251c\u2500\u2500 examples \u2502 \u2502 \u251c\u2500\u2500 3Components \u2502 \u2502 \u251c\u2500\u2500 CFs \u2502 \u2502 \u251c\u2500\u2500 Coherence \u2502 \u2502 \u251c\u2500\u2500 Downloads \u2502 \u2502 \u251c\u2500\u2500 EGFs \u2502 \u2502 \u251c\u2500\u2500 Earthquake_location_test \u2502 \u2502 \u251c\u2500\u2500 Moment_Tensor_example \u2502 \u2502 \u251c\u2500\u2500 NuclearExplotionILAR_2017 \u2502 \u2502 \u251c\u2500\u2500 PPSDS_example \u2502 \u2502 \u251c\u2500\u2500 Synthetics \u2502 \u2502 \u251c\u2500\u2500 receiver_functions_example \u2502 \u2502 \u2514\u2500\u2500 teleseism \u2502 \u251c\u2500\u2500 mac_bin \u2502 \u251c\u2500\u2500 maps \u2502 \u251c\u2500\u2500 mti \u2502 \u2502 \u251c\u2500\u2500 class_isola_new.py \u2502 \u2502 \u251c\u2500\u2500 green \u2502 \u2502 \u251c\u2500\u2500 green_source \u2502 \u2502 \u251c\u2500\u2500 html \u2502 \u2502 \u251c\u2500\u2500 input \u2502 \u2502 \u251c\u2500\u2500 mti_utilities.py \u2502 \u2502 \u251c\u2500\u2500 output \u2502 \u2502 \u2514\u2500\u2500 read_log.py \u2502 \u251c\u2500\u2500 receiverfunctions \u2502 \u2502 \u251c\u2500\u2500 earth_models \u2502 \u2502 \u2502 \u2514\u2500\u2500 iasp91.csv \u2502 \u2502 \u251c\u2500\u2500 rf_dialogs.py \u2502 \u2502 \u251c\u2500\u2500 rf_dialogs_utils.py \u2502 \u2502 \u251c\u2500\u2500 rf_main_window_utils.py \u2502 \u2502 \u2514\u2500\u2500 rf_matplotlibwidget.py \u2502 \u251c\u2500\u2500 resources \u2502 \u2502 \u251c\u2500\u2500 designer_uis \u2502 \u2502 \u2502 \u251c\u2500\u2500 ArrayAnalysisFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 CrustalModelParametersFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 DataDownload.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 EarthModelWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 Earthquake3CFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 EarthquakeAnalysisFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 EarthquakeAnalysisFrame_old.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 EarthquakeLocationFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 EventInfoDockWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 EventLocationFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 FilterDockWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 MagnitudeFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 MainFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 MomentTensor.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 MomentTensor_old.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 PPSD.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 PPSDDialogsSettings.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 PPSD_DBGeneratorDialog.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 PaginationWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 PlotPolarizationWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 ReceiverFunctionsFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 RfAboutDialog.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 RfDialogsCrossSection.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 RfDialogsCutEqs.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 RfDialogsSaveFigure.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 RfDialogsShowEarthquake.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 SettingsDialog.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 SpectrumDockWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 StationInfoDockWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 StationsCoordinates.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 StationsInfo.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 SyntheticsAnalisysFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 SyntheticsGeneratorDialog.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 TimeAnalysisWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 TimeFrequencyAddWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 TimeFrequencyFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 TimeFrequencyFrame_old.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 TimeSelectorDockWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 VespagramWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 additionalParameters.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 help.ui \u2502 \u2502 \u2502 \u2514\u2500\u2500 parameters.ui \u2502 \u2502 \u251c\u2500\u2500 images \u2502 \u2502 \u2502 \u251c\u2500\u2500 icons \u2502 \u2502 \u251c\u2500\u2500 resources.py \u2502 \u2502 \u251c\u2500\u2500 resources.qrc \u2502 \u2502 \u2514\u2500\u2500 resources_rc.py \u2502 \u251c\u2500\u2500 retrieve_events \u2502 \u2502 \u2514\u2500\u2500 retrive_data_tools.py \u2502 \u2514\u2500\u2500 seismogramInspector \u2502 \u251c\u2500\u2500 COMPLIANCE.py \u2502 \u251c\u2500\u2500 CWT_fast.py \u2502 \u251c\u2500\u2500 MTspectrogram.py \u2502 \u251c\u2500\u2500 ba_fast.py \u2502 \u251c\u2500\u2500 entropy.py \u2502 \u251c\u2500\u2500 plotpm.py \u2502 \u251c\u2500\u2500 polarity2.py \u2502 \u251c\u2500\u2500 signal_processing_advanced.py \u2502 \u251c\u2500\u2500 status.py \u2502 \u2514\u2500\u2500 utilsEntropy.py \u251c\u2500\u2500 isp.sh \u251c\u2500\u2500 mti.tar.gz \u251c\u2500\u2500 requirements.txt \u251c\u2500\u2500 setup.py \u251c\u2500\u2500 start_isp.py Seismograms and metadata Description In ISP we have decided go for minified format, with is one of the most broadly used data storage formats for seismograms. The best description is given at http://ds.iris.edu/ds/nodes/dmc/data/formats/miniseed/ which is simply: MiniSEED is the subset of the SEED standard that is used for time series data. Very limited metadata for the time series is included in miniSEED beyond time series identification and simple state-of-health flags. In particular, geographic coordinates, response/scaling information and other information needed to interpret the data values are not included. Time series are stored as generally independent, fixed length data records which each contain a small segment of contiguous series values. A reader of miniSEED is required to reconstruct longer, contiguous time series from the data record segments. Common record lengths are 512-byte (for real time streams) and 4096-byte (for archiving), other record lengths are used for special scenarios. A \u201cfile\u201d or \u201cstream\u201d of miniSEED is simply a concatenation of data records. Depending on the capabilities of the intended reader the data records for multiple channels of data may be multiplexed together. How to read miniseed files The user can find example of local miniseed files containing a broad variety of waveforms at .isp/examples (see Project Structure). Additionally, you can download data and metadata from the tool \"Retrieve Data\", either from a specific time window or an earthquake from a catalog. For example, if you are using Earthquake Analysis Module. Follow. The directions of the following screenshot: Robust will check that the files to be storage in the database are valid mseedfiles. Scan will allow create the database from a full folder tree. This option is very useful when the user has the mseed files distributed as SDS architecture (NET/STATIONS/CHANNELS/FILES). Metadata (Dataless and *.xml) ISP uses two kind of metadata files either Dataless or xml. ( https://docs.obspy.org/tutorial/code_snippets/stationxml_file_from_scratch.html ). You can find an example of this files at the folders isp/Metadata/dataless and isp/Metadata/xml. As you will see, in the this files there is information structured as a dictionary nets/stations/channels. Personally, the best way to make your own metadata file is using either the java software PDCC or going to the API Station Management Portal . Important : The idea in ISP is that your Metadata file (one single file) contains all of the information (such as coordinates of your stations, instrument response, sampling frequency and so on ...) of the miniseed files you are going to manage. The reason of this design is that, it is easier to programming something that works independently from the miniseed file to metadata. For example when sorting the minified files from respect to an event. The software internally reads the name of all of your files (in the header) and then match this info with the metadata file. Notes : It is very easy using python to convert your dataless to xml. From: https://docs.obspy.org/_modules/obspy/core/inventory/inventory.html#Inventory.write from obspy import read_inventory inv = read_inventory(\"path_to_your_dataless\") inv.write(path_or_file_object, format=\"stationxml\", validate=True)","title":"Start with the basics"},{"location":"basics/#warming-tutorial","text":"This section will show you the overall structure of the project and a basic idea of how are the data managed by ISP.","title":"Warming tutorial"},{"location":"basics/#project-structure","text":"The current (ISP 1.0) structure of the project is showed in the plot below. We also show a scheme-description of the project. We include some of the most relevant files, such as OBSs/out.txt (output observations) ISP/ \u251c\u2500\u2500 install \u251c\u2500\u2500 isp \u2502 \u251c\u2500\u2500 DataProcessing \u2502 \u2502 \u251c\u2500\u2500 NeuralNetwork \u2502 \u2502 \u2502 \u251c\u2500\u2500 model \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 red_modelo.json \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 red_pesos.hdf5 \u2502 \u2502 \u2502 \u251c\u2500\u2500 picking_cnn_s_p_waves.py \u2502 \u2502 \u251c\u2500\u2500 dataless_manager.py \u2502 \u2502 \u251c\u2500\u2500 metadata_manager.py \u2502 \u2502 \u251c\u2500\u2500 plot_tools_manager.py \u2502 \u2502 \u251c\u2500\u2500 seismogram_analysis.py \u2502 \u2502 \u2514\u2500\u2500 wavelet.py \u2502 \u251c\u2500\u2500 FOCMEC \u2502 \u2502 \u2514\u2500\u2500 bin \u2502 \u2502 \u2514\u2500\u2500 focmec \u2502 \u251c\u2500\u2500 Gui \u2502 \u2502 \u251c\u2500\u2500 Frames \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_parameters.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 array_analysis_frames.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 crustal_model_parameters_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 data_download_tool.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 earth_model_viewer.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 earthquake_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 earthquake_frame_tabs.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 event_location_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 help_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 isola_ISP_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 main.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 matplotlib_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 open_magnitudes_calc.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 parameters.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 plot_polarization.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 ppsds_db_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 ppsds_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 qt_components.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 receiver_functions_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 settings_dialog.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 stations_coordinates.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 stations_info.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 synthetics_analysis_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 synthetics_generator_dialog.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 time_frequency_advance_frame.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 time_frequency_frames.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 time_frequency_frames_old.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 uis_frames.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 vespagram.py \u2502 \u2502 \u251c\u2500\u2500 Models \u2502 \u2502 \u2502 \u2514\u2500\u2500 sql_alchemy_model.py \u2502 \u2502 \u251c\u2500\u2500 StyleLib \u2502 \u2502 \u2502 \u2514\u2500\u2500 isp.mplstyle \u2502 \u2502 \u251c\u2500\u2500 Utils \u2502 \u2502 \u2502 \u251c\u2500\u2500 matplotlib_util.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 pyqt_decorators.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 pyqt_utils.py \u2502 \u2502 \u251c\u2500\u2500 controllers \u2502 \u2502 \u2502 \u2514\u2500\u2500 window_controller.py \u2502 \u2502 \u251c\u2500\u2500 databases \u2502 \u2502 \u2502 \u2514\u2500\u2500 isp_test.db \u2502 \u251c\u2500\u2500 Metadata \u2502 \u2502 \u251c\u2500\u2500 dataless \u2502 \u2502 \u2502 \u2514\u2500\u2500 dataless.dlsv \u2502 \u2502 \u2514\u2500\u2500 xml \u2502 \u2502 \u2514\u2500\u2500 metadata.xml \u2502 \u251c\u2500\u2500 NLL7 \u2502 \u2502 \u251c\u2500\u2500 bin \u2502 \u2502 \u2514\u2500\u2500 src \u2502 \u251c\u2500\u2500 PPSDS_Utils \u2502 \u2502 \u2514\u2500\u2500 ppsds_utils.py \u2502 \u251c\u2500\u2500 Structures \u2502 \u2502 \u251c\u2500\u2500 obspy_stats_keys.py \u2502 \u2502 \u2514\u2500\u2500 structures.py \u2502 \u251c\u2500\u2500 Test \u2502 \u251c\u2500\u2500 Utils \u2502 \u2502 \u251c\u2500\u2500 class_decorators.py \u2502 \u2502 \u251c\u2500\u2500 nllOrgErrors.py \u2502 \u2502 \u251c\u2500\u2500 obspy_utils.py \u2502 \u2502 \u251c\u2500\u2500 subprocess_utils.py \u2502 \u2502 \u2514\u2500\u2500 time_utils.py \u2502 \u251c\u2500\u2500 arrayanalysis \u2502 \u2502 \u251c\u2500\u2500 array_analysis.py \u2502 \u2502 \u2514\u2500\u2500 stations \u2502 \u2502 \u251c\u2500\u2500 coords.txt \u2502 \u251c\u2500\u2500 db \u2502 \u2502 \u251c\u2500\u2500 data_base.py \u2502 \u2502 \u251c\u2500\u2500 map_class \u2502 \u2502 \u2502 \u251c\u2500\u2500 clases_mpl_pyqt.py \u2502 \u2502 \u2514\u2500\u2500 models \u2502 \u2502 \u251c\u2500\u2500 base_model.py \u2502 \u2502 \u2514\u2500\u2500 models.py \u2502 \u251c\u2500\u2500 earthquakeAnalisysis \u2502 \u2502 \u251c\u2500\u2500 NLLGrid.py \u2502 \u2502 \u251c\u2500\u2500 auto_detect \u2502 \u2502 \u2502 \u251c\u2500\u2500 events \u2502 \u2502 \u2502 \u2514\u2500\u2500 phases \u2502 \u2502 \u251c\u2500\u2500 ellipsoid.py \u2502 \u2502 \u251c\u2500\u2500 first_polarity.py \u2502 \u2502 \u251c\u2500\u2500 focmecobspy.py \u2502 \u2502 \u251c\u2500\u2500 location_output \u2502 \u2502 \u2502 \u251c\u2500\u2500 ak135 \u2502 \u2502 \u2502 \u251c\u2500\u2500 all_locations \u2502 \u2502 \u2502 \u251c\u2500\u2500 first_polarity \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 focmec.lst \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 focmec_run \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 log.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 mechanism.out \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 rfocmec_RW \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 rfocmec_UW \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 test.inp \u2502 \u2502 \u2502 \u251c\u2500\u2500 loc \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 last.hyp \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 last.hyp.scat.xyz \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 location_run_temp.txt \u2502 \u2502 \u2502 \u251c\u2500\u2500 local_models \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 modelP \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 modelS \u2502 \u2502 \u2502 \u251c\u2500\u2500 model \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 layer.P.mod.buf \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 layer.P.mod.hdr \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 layer.S.mod.buf \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 layer.S.mod.hdr \u2502 \u2502 \u2502 \u251c\u2500\u2500 model3D \u2502 \u2502 \u2502 \u251c\u2500\u2500 obs \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 output.txt \u2502 \u2502 \u2502 \u251c\u2500\u2500 run \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 g2t_template \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 global_template \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 run_template \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 v2g_template \u2502 \u2502 \u2502 \u251c\u2500\u2500 stations \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 stations.txt \u2502 \u2502 \u2502 \u251c\u2500\u2500 temp \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 G2T_temp.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 info.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 input.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 run_temp.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 stations.txt \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 test_grd2time.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_fp \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 focmec.lst \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 mechanism.out \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 test.inp \u2502 \u2502 \u2502 \u2514\u2500\u2500 time \u2502 \u2502 \u251c\u2500\u2500 magnitude_atenuation \u2502 \u2502 \u2502 \u2514\u2500\u2500 atenuation.txt \u2502 \u2502 \u251c\u2500\u2500 pdf_plot.py \u2502 \u2502 \u251c\u2500\u2500 picker_manager.py \u2502 \u2502 \u251c\u2500\u2500 rotate.py \u2502 \u2502 \u251c\u2500\u2500 run_nll.py \u2502 \u2502 \u2514\u2500\u2500 stations_map.py \u2502 \u251c\u2500\u2500 examples \u2502 \u2502 \u251c\u2500\u2500 3Components \u2502 \u2502 \u251c\u2500\u2500 CFs \u2502 \u2502 \u251c\u2500\u2500 Coherence \u2502 \u2502 \u251c\u2500\u2500 Downloads \u2502 \u2502 \u251c\u2500\u2500 EGFs \u2502 \u2502 \u251c\u2500\u2500 Earthquake_location_test \u2502 \u2502 \u251c\u2500\u2500 Moment_Tensor_example \u2502 \u2502 \u251c\u2500\u2500 NuclearExplotionILAR_2017 \u2502 \u2502 \u251c\u2500\u2500 PPSDS_example \u2502 \u2502 \u251c\u2500\u2500 Synthetics \u2502 \u2502 \u251c\u2500\u2500 receiver_functions_example \u2502 \u2502 \u2514\u2500\u2500 teleseism \u2502 \u251c\u2500\u2500 mac_bin \u2502 \u251c\u2500\u2500 maps \u2502 \u251c\u2500\u2500 mti \u2502 \u2502 \u251c\u2500\u2500 class_isola_new.py \u2502 \u2502 \u251c\u2500\u2500 green \u2502 \u2502 \u251c\u2500\u2500 green_source \u2502 \u2502 \u251c\u2500\u2500 html \u2502 \u2502 \u251c\u2500\u2500 input \u2502 \u2502 \u251c\u2500\u2500 mti_utilities.py \u2502 \u2502 \u251c\u2500\u2500 output \u2502 \u2502 \u2514\u2500\u2500 read_log.py \u2502 \u251c\u2500\u2500 receiverfunctions \u2502 \u2502 \u251c\u2500\u2500 earth_models \u2502 \u2502 \u2502 \u2514\u2500\u2500 iasp91.csv \u2502 \u2502 \u251c\u2500\u2500 rf_dialogs.py \u2502 \u2502 \u251c\u2500\u2500 rf_dialogs_utils.py \u2502 \u2502 \u251c\u2500\u2500 rf_main_window_utils.py \u2502 \u2502 \u2514\u2500\u2500 rf_matplotlibwidget.py \u2502 \u251c\u2500\u2500 resources \u2502 \u2502 \u251c\u2500\u2500 designer_uis \u2502 \u2502 \u2502 \u251c\u2500\u2500 ArrayAnalysisFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 CrustalModelParametersFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 DataDownload.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 EarthModelWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 Earthquake3CFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 EarthquakeAnalysisFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 EarthquakeAnalysisFrame_old.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 EarthquakeLocationFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 EventInfoDockWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 EventLocationFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 FilterDockWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 MagnitudeFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 MainFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 MomentTensor.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 MomentTensor_old.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 PPSD.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 PPSDDialogsSettings.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 PPSD_DBGeneratorDialog.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 PaginationWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 PlotPolarizationWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 ReceiverFunctionsFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 RfAboutDialog.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 RfDialogsCrossSection.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 RfDialogsCutEqs.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 RfDialogsSaveFigure.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 RfDialogsShowEarthquake.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 SettingsDialog.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 SpectrumDockWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 StationInfoDockWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 StationsCoordinates.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 StationsInfo.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 SyntheticsAnalisysFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 SyntheticsGeneratorDialog.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 TimeAnalysisWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 TimeFrequencyAddWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 TimeFrequencyFrame.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 TimeFrequencyFrame_old.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 TimeSelectorDockWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 VespagramWidget.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 additionalParameters.ui \u2502 \u2502 \u2502 \u251c\u2500\u2500 help.ui \u2502 \u2502 \u2502 \u2514\u2500\u2500 parameters.ui \u2502 \u2502 \u251c\u2500\u2500 images \u2502 \u2502 \u2502 \u251c\u2500\u2500 icons \u2502 \u2502 \u251c\u2500\u2500 resources.py \u2502 \u2502 \u251c\u2500\u2500 resources.qrc \u2502 \u2502 \u2514\u2500\u2500 resources_rc.py \u2502 \u251c\u2500\u2500 retrieve_events \u2502 \u2502 \u2514\u2500\u2500 retrive_data_tools.py \u2502 \u2514\u2500\u2500 seismogramInspector \u2502 \u251c\u2500\u2500 COMPLIANCE.py \u2502 \u251c\u2500\u2500 CWT_fast.py \u2502 \u251c\u2500\u2500 MTspectrogram.py \u2502 \u251c\u2500\u2500 ba_fast.py \u2502 \u251c\u2500\u2500 entropy.py \u2502 \u251c\u2500\u2500 plotpm.py \u2502 \u251c\u2500\u2500 polarity2.py \u2502 \u251c\u2500\u2500 signal_processing_advanced.py \u2502 \u251c\u2500\u2500 status.py \u2502 \u2514\u2500\u2500 utilsEntropy.py \u251c\u2500\u2500 isp.sh \u251c\u2500\u2500 mti.tar.gz \u251c\u2500\u2500 requirements.txt \u251c\u2500\u2500 setup.py \u251c\u2500\u2500 start_isp.py","title":"Project Structure"},{"location":"basics/#seismograms-and-metadata","text":"","title":"Seismograms and metadata"},{"location":"basics/#description","text":"In ISP we have decided go for minified format, with is one of the most broadly used data storage formats for seismograms. The best description is given at http://ds.iris.edu/ds/nodes/dmc/data/formats/miniseed/ which is simply: MiniSEED is the subset of the SEED standard that is used for time series data. Very limited metadata for the time series is included in miniSEED beyond time series identification and simple state-of-health flags. In particular, geographic coordinates, response/scaling information and other information needed to interpret the data values are not included. Time series are stored as generally independent, fixed length data records which each contain a small segment of contiguous series values. A reader of miniSEED is required to reconstruct longer, contiguous time series from the data record segments. Common record lengths are 512-byte (for real time streams) and 4096-byte (for archiving), other record lengths are used for special scenarios. A \u201cfile\u201d or \u201cstream\u201d of miniSEED is simply a concatenation of data records. Depending on the capabilities of the intended reader the data records for multiple channels of data may be multiplexed together.","title":"Description"},{"location":"basics/#how-to-read-miniseed-files","text":"The user can find example of local miniseed files containing a broad variety of waveforms at .isp/examples (see Project Structure). Additionally, you can download data and metadata from the tool \"Retrieve Data\", either from a specific time window or an earthquake from a catalog. For example, if you are using Earthquake Analysis Module. Follow. The directions of the following screenshot: Robust will check that the files to be storage in the database are valid mseedfiles. Scan will allow create the database from a full folder tree. This option is very useful when the user has the mseed files distributed as SDS architecture (NET/STATIONS/CHANNELS/FILES).","title":"How to read miniseed files"},{"location":"basics/#metadata-dataless-and-xml","text":"ISP uses two kind of metadata files either Dataless or xml. ( https://docs.obspy.org/tutorial/code_snippets/stationxml_file_from_scratch.html ). You can find an example of this files at the folders isp/Metadata/dataless and isp/Metadata/xml. As you will see, in the this files there is information structured as a dictionary nets/stations/channels. Personally, the best way to make your own metadata file is using either the java software PDCC or going to the API Station Management Portal . Important : The idea in ISP is that your Metadata file (one single file) contains all of the information (such as coordinates of your stations, instrument response, sampling frequency and so on ...) of the miniseed files you are going to manage. The reason of this design is that, it is easier to programming something that works independently from the miniseed file to metadata. For example when sorting the minified files from respect to an event. The software internally reads the name of all of your files (in the header) and then match this info with the metadata file. Notes : It is very easy using python to convert your dataless to xml. From: https://docs.obspy.org/_modules/obspy/core/inventory/inventory.html#Inventory.write from obspy import read_inventory inv = read_inventory(\"path_to_your_dataless\") inv.write(path_or_file_object, format=\"stationxml\", validate=True)","title":"Metadata (Dataless and *.xml)"},{"location":"db/","text":"Database The Database sub-module is designed to incorporate all the results you can obtain from Earthquake location and Moment Tensor Inversion. It is possible to make queries to the data base, for example searching earthquake locations by a geographic frame or in a specific time spam. Moreover you can plot the results of your query in a map. With double click in a row of the table you can add a Focal mechanism detailed to the map and with right click just over one row of the table you can remove events. In the toolbar you will find two options, the first one \u201cRead hyp folder load\u201d will generate a database from all *.hyp that you had placed in the folder. The other option \u201cRead last location\u201d will load (last.hyp, from earthquake analysis), (log.txt, from Moment Tensor Inversion), (mechanism.out, from Earthquake analysis) and (magnitudes.out, from Earthquake analysis) and will fed the database with all of the information extracted. Fig. 1 shows a Data Base example. To plot fashion maps you can add a WMS and the layer you want to plot. I suggest go to this web site to find nice WMS/layers: MAP_SERVICE_URL = 'https://gis.ngdc.noaa.gov/arcgis/services/","title":"Database"},{"location":"db/#database","text":"The Database sub-module is designed to incorporate all the results you can obtain from Earthquake location and Moment Tensor Inversion. It is possible to make queries to the data base, for example searching earthquake locations by a geographic frame or in a specific time spam. Moreover you can plot the results of your query in a map. With double click in a row of the table you can add a Focal mechanism detailed to the map and with right click just over one row of the table you can remove events. In the toolbar you will find two options, the first one \u201cRead hyp folder load\u201d will generate a database from all *.hyp that you had placed in the folder. The other option \u201cRead last location\u201d will load (last.hyp, from earthquake analysis), (log.txt, from Moment Tensor Inversion), (mechanism.out, from Earthquake analysis) and (magnitudes.out, from Earthquake analysis) and will fed the database with all of the information extracted. Fig. 1 shows a Data Base example. To plot fashion maps you can add a WMS and the layer you want to plot. I suggest go to this web site to find nice WMS/layers: MAP_SERVICE_URL = 'https://gis.ngdc.noaa.gov/arcgis/services/","title":"Database"},{"location":"el/","text":"Earthquake Location The module Earthquake analysis allows you to analyse waveforms, polarization analysis of seismograms 3-components, calculate different magnitudes and finally locate an event and estimate the focal mechanism (First Polarity). We will walk through all of the functionality following this scheme: Pick Event From top to bottom in the left side of the window you will see: Event Info : This small box let enter information about an event, in this way you can plot the theoretical arrivals (ak-135F) with respect your seismograms. Plot arrivals requires that you have correctly loaded your metadata. Files Directory : By clicking in this button you will place the path of your files ( miniseed). Click on Read Files to load in an inner database the path to your files. With this action you will be ready to Process and Plot the seismograms. Remember click on Read Files every time you change the folder. Option scan means, scan the whole tree of folders from the root one, to include all possible mseed files paths in the database. Robust means that is going to check that every file in the selected folder is a valid mseed file. Metadata File : By clicking in this button you will place the path to you metadata file. The metadata file must contain the information of all of the stations seismograms you want to analyse (metadata must be a xml or dlsv). Start Time and End Time : The time boxes can be selected checking \u201cTrim Time\u201d. If you choose this option all the seismograms will be cut in accordance with the selected time window. Use the shortcuts \"Q\" and \"E\" to set over the plot automatically the trim stat time and endtime. Stations Info : will deploy a table with the fundamental information of the seismograms. Phase box : This combo box allow the selection of specific phases for picking it in the seismograms. Waves box : You can choose Body, surface, coda or noise. With this selected you can highlight a time window of the seismogram for further analysis. For example Mw Magnitude that requires a time window of body wave on many seismograms. Net, Station and Channel : You can fill this boxes (also using wildcards such as * or BH?) to select specific files from your files folder (check \u201cselect files\u201d). Stations Map : will show you the location of the stations that corresponds to the seismograms of your folder. The seismograms metadata must match with the metadata information. Rotate : This option will rotate all your station - 3 components (channels must be named N,E,Z) to the Great Arc Circle taking the reference the data of Event info tab. Check \"Use this Ang\" to rotate the components a specific angle. Cross : This button will compute the cross-correlation (cc) or the autocorrelation of all processed seismograms with respect the reference \u201cRef\u201d, the number of the seismogram from top to bottom. Process and Plot : This action will read the seismograms from the database of paths to your seismograms, created from your folder tree (database already built using Read Files) and will carry out the processing from the established \u201cMACRO\u201d. Further details in MACRO section \"Macros\". Additional options from the toolbar are: File File: New location will clean the picks that are saved automatically for be ready to compute new picking/location. File: Write Files will write in the folder you select the processed seismograms. File: Open Settings will open a window with the specific parameters of the subprocess that you can carry out in this module (sta/lta, wavelet detection, spectrogram, entropy\u2026). Actions Actions: Picks will open the file with the information of your picks. You can also open the file from here. Shortcut \"Ctr + u\" Actions: Macro will deploy a window with all of the processing options. All of the processing options will be applied once you press the button Processing and Plot. Shortcut \"Ctr + l\" Action: Detect event will associate the automatic picks carried out by the wavelet picker ant will declare an event. The events will be shown in the seismograms window. Actions: Run Picker will carry out the automatic detection/classification of P- and S- waves from the previously loaded \u201cNeural Network\u201d. You must have three components per stations (named N, E,*Z). BE CAREFUL this operation is computationally demanding. Actions: Run Autoloc will detect events using a associated picker based on the Continuous Wavelet Transform (go to File Open Settings to set Num Cycles, Fmin and Fmax) moreover you need to set Detection trigger options Threshold to trigger a pick, number of picks that coincide in different seismograms to declare an event and time window over the clustering of pick is going to be used (For example 40 s means that all seismograms around same time window of 40 s is going to be associated to the same event. Once an event is declared it is chopped the seismograms run the autopick (P and S wave) using the Neural Network and run and automatic location. If you want to use a local model to locate be sure that you have the travel times calculated. All locations will be storage in ./isp/earthquakeAnalysis/location_output/all_locations. Action: Clean Selection will remove an specific seismogram time window selection, such as Body wave, see the combo box selected and will delete from the selections. Action: Remove all selections Action: Clean Events Detected Actions: Magnitude Calculator will open a window in which you can compute different magnitudes. For open this you must have estimated an event and have selected the time-windows in the seismograms that you want the magnitudes be calculated. Action: Open Earth Model Viewer will open a tool to visualize 3D velocity models. For visualize an Earth Model you need the binary files ( buf and hdr) created in the tab Event location. Action: Data availability will plot the data availability (backlines) for each station/component of the database loaded from your folder tree. Compute Compute: STA/LTA from all processed seismograms and will plot the result together. STA/LTA takes the parameters from Parameters Settings. Compute: CWT (CF) from all processed seismograms and will plot the result together. CWT takes the parameters from Parameters Settings. Compute: Envelope from all processed seismograms and will plot the result together. Compute: Spectral Entropy from all processed seismograms and will plot the result together. Spectral entropy is estimated in small time windows see Parameters Settings. . All Seismograms: Plot together all seismograms. Stack: Compute (linear, nth-root or PWS) stack of all processed seismograms. Set your choice in File/Open Settings. Go Will ship you to the rest of ISP modules (RFs, Array analysis\u2026.). Multimedia Material (Pick Event) The following video shows a basic analysis of an earthquake Polarisation Analysis The Polarization Analysis is designed to analyze the three seismograms components from a station. You can freely rotate using the rotation RT or the LQT your NEZ components an angle (Rot Angle) with an Incidence angle (Inc Angle). The Particle motion of the processed seismogram is view clicking in \u201cPlot Polarization\u201d. This option will plot all the time window in a 3D view and in three 2D plot views. If you want to make a sliding window analysis of the polarization press \u201cPolarization Analysis\u201d. This will carry out a polarization analysis on windows length and frequency bandwidth specified by the user over the full analyzed seismogram. For a full particle motion analysis, press \u201cPlot Polarization\u201d. This will open another window with a 3D particle motion on the left and the three characteristic views on the right. Event Location and Focal Mechanism (FP) In the Event Location Frame the user can configure the velocity grid 1D/3D model, locate earthquakes and compute Focal Mechanisms. First it is needed to set a Velocity grid framework (Grid reference and transformation type are mandatory). For now is only available Transformation Simple and Global. Next, the Grid dimensions (Grid Size). Case 2D the dimension always must be 2 and the grid reference is referred to the corner SW. Case 3D the grid reference is the center of the Grid. Choose the grid type and the wave and then generate the velocity model binary files by clicking \u201cGenerate Velocity Grid\u201d. Please follow the scheme of the next figure to set correctly your grid frame. Once the binary files are generated you can check the results in the folder: ISP/earthquakeAnalysis/location_output/model Where and how place the velocity models? 2D models (see example) LAYER 0.0 6.1 0.0 3.49 0.0 2.7 0.0 LAYER 11.0 6.4 0.0 3.66 0.0 2.7 0.0 LAYER 24.0 6.9 0.0 3.94 0.0 2.7 0.0 LAYER 31.0 8.0 0.0 4.57 0.0 2.7 0.0 ISP/earthquakeAnalysis/location_output/local_models 3D models ISP/earthquakeAnalysis/location_output/model3D (see example) Every depth layer must be placed in files called, for example For the P wave --> layer.P.mod5.mod For the S wave --> layer.S.mod5.mod Which means that inside this file there is the grid for the layer at depth 5km. The layer must be a matrix with the values in the rows from top to bottom S to N and from left to right E to W. That's mean following the next example that the file corresponding to a depth layer 5km \"layer.P.mod5.mod\" could be like this: 4.5759 4.5735 4.5707 4.5677 4.5760 4.5755 4.5766 4.5670 ...... ...... ...... ...... 4.6800 4.650 4.67300 4.5678 This matrix means that, for example corresponds to geographic points (separated in cells of, dx dy of 0.5 x 0.5 degrees: Warning grid cells must be [dx = dy = dz] for a correct interpretation. (-10.0,34) (-9.5,34) (-9.0,34) (-8.5,34) (-10.0,34.5) (-9.5,34.5) (-9.0,34.5) (-8.5,34.5) ........ ......... ......... ......... (-10.0,40.0) (-9.5,40.0) (-9.0,40.0) (-8.5,40.0) The most important step is to generate the travel-times for all the stations inside the maximum distance the user determine. Please be sure that you have load previously the metadata (this Is necessary to associate your picks with your station coordinates. The generated travel-times will save in ISP/earthquakeAnalysis/location_output/time, for example with the following name l\"ayer.P.EBAD.time.buf\" Once you have complete the above steps you can locate the earthquake and the focal mechanism. The above operation are just necessary to be implemented the first time you use a specific Earth model. **For global is not necessary generate the velocity grid and travel times. To visualize the detailed Probability Density Function, press \u201cPlot PDF\u201d once you have already carried out the location. Moreover, if you have picked the seismic phases and have been designated the polarity in \u201cEvent frame\u201d , you will be able to obtain the Focal Mechanism (it uses the subprogram FocMec) Earth model Viewer The Earth Model Viewer is intended to help to visualize 3D Earth velocity models as Fig 2.8. Just select the binary file *.buf (can be generated from the model as described in previous section). Next, select the depth of the layer, the cross sections in longitude and latitude and the press plot. Magnitudes Estimation With the Magnitude Estimation you can calculate: Local Magnitude (ML) or Body-wave (mb), Surface-wave (Ms), Moment Magnitude (Mw) and Coda Magnitude. To estimate the magnitudes you have to select a time window of body, surface or coda on the seismograms. Units must be on velocity, so you must remove the response of the instrument to velocity, previously to open the Magnitudes window. For Local magnitude you have to remove the response of Wood-Anderson instrument. The hypocenter must be already calculated. The program will read the *.hyp file before open Magnitudes window. If you place 0.00 on all parameters of local or coda magnitudes, the program will calculate these magnitude with default parameters as follows: Coda Magnitude: Values for California a = 2.0; b = 0.0035; c= -0.87 Mc_value = a np.log10(t_coda)+b dist+c Local Magnitude: a = 1.11; b =0.00189; c= -2.09 ML_value = np.log10(max_amplitude)+a np.log10(dist)+b dist+c Briefly, Once you have open the Magnitude Window, select the magnitudes you want to compute and run the computation. In the upper panel it is shown the spectrum of the body waves and the fit to calculate the moment magnitude. In the bottom panel is shown the histograms of all magnitudes (the result of the magnitudes for all seismograms for all kind of magnitudes) and on the left an additional plot used to visualize the dispersion of the results. Shortcuts Shortcut Action 'Ctrl+L' Open Macro 'Ctrl+U' View Picks 'Ctrl+I' Deselect all 'Ctrl+J' Deselect a wave (Noise, Body, Surface) 'Ctrl+C' Clean events detected 'Ctrl+M' Open magnitudes calculator 'Ctrl+P' Open phases comboBox 'Ctrl+K' Save CFs (STA/LTA, Wavelet CF, Envelope, Entropy\u2026) 'Ctrl+N' Plot_all_seismograms 'Ctrl+B' Stack_all_seismograms 'a' Compute individual spectrum 'f' Compute all spectrums 'z' Compute Spectrogram 'q' Set start time 'w' Process and Plot 'e' Set end time","title":"Earthquake Location"},{"location":"el/#earthquake-location","text":"The module Earthquake analysis allows you to analyse waveforms, polarization analysis of seismograms 3-components, calculate different magnitudes and finally locate an event and estimate the focal mechanism (First Polarity). We will walk through all of the functionality following this scheme:","title":"Earthquake Location"},{"location":"el/#pick-event","text":"From top to bottom in the left side of the window you will see: Event Info : This small box let enter information about an event, in this way you can plot the theoretical arrivals (ak-135F) with respect your seismograms. Plot arrivals requires that you have correctly loaded your metadata. Files Directory : By clicking in this button you will place the path of your files ( miniseed). Click on Read Files to load in an inner database the path to your files. With this action you will be ready to Process and Plot the seismograms. Remember click on Read Files every time you change the folder. Option scan means, scan the whole tree of folders from the root one, to include all possible mseed files paths in the database. Robust means that is going to check that every file in the selected folder is a valid mseed file. Metadata File : By clicking in this button you will place the path to you metadata file. The metadata file must contain the information of all of the stations seismograms you want to analyse (metadata must be a xml or dlsv). Start Time and End Time : The time boxes can be selected checking \u201cTrim Time\u201d. If you choose this option all the seismograms will be cut in accordance with the selected time window. Use the shortcuts \"Q\" and \"E\" to set over the plot automatically the trim stat time and endtime. Stations Info : will deploy a table with the fundamental information of the seismograms. Phase box : This combo box allow the selection of specific phases for picking it in the seismograms. Waves box : You can choose Body, surface, coda or noise. With this selected you can highlight a time window of the seismogram for further analysis. For example Mw Magnitude that requires a time window of body wave on many seismograms. Net, Station and Channel : You can fill this boxes (also using wildcards such as * or BH?) to select specific files from your files folder (check \u201cselect files\u201d). Stations Map : will show you the location of the stations that corresponds to the seismograms of your folder. The seismograms metadata must match with the metadata information. Rotate : This option will rotate all your station - 3 components (channels must be named N,E,Z) to the Great Arc Circle taking the reference the data of Event info tab. Check \"Use this Ang\" to rotate the components a specific angle. Cross : This button will compute the cross-correlation (cc) or the autocorrelation of all processed seismograms with respect the reference \u201cRef\u201d, the number of the seismogram from top to bottom. Process and Plot : This action will read the seismograms from the database of paths to your seismograms, created from your folder tree (database already built using Read Files) and will carry out the processing from the established \u201cMACRO\u201d. Further details in MACRO section \"Macros\". Additional options from the toolbar are: File File: New location will clean the picks that are saved automatically for be ready to compute new picking/location. File: Write Files will write in the folder you select the processed seismograms. File: Open Settings will open a window with the specific parameters of the subprocess that you can carry out in this module (sta/lta, wavelet detection, spectrogram, entropy\u2026). Actions Actions: Picks will open the file with the information of your picks. You can also open the file from here. Shortcut \"Ctr + u\" Actions: Macro will deploy a window with all of the processing options. All of the processing options will be applied once you press the button Processing and Plot. Shortcut \"Ctr + l\" Action: Detect event will associate the automatic picks carried out by the wavelet picker ant will declare an event. The events will be shown in the seismograms window. Actions: Run Picker will carry out the automatic detection/classification of P- and S- waves from the previously loaded \u201cNeural Network\u201d. You must have three components per stations (named N, E,*Z). BE CAREFUL this operation is computationally demanding. Actions: Run Autoloc will detect events using a associated picker based on the Continuous Wavelet Transform (go to File Open Settings to set Num Cycles, Fmin and Fmax) moreover you need to set Detection trigger options Threshold to trigger a pick, number of picks that coincide in different seismograms to declare an event and time window over the clustering of pick is going to be used (For example 40 s means that all seismograms around same time window of 40 s is going to be associated to the same event. Once an event is declared it is chopped the seismograms run the autopick (P and S wave) using the Neural Network and run and automatic location. If you want to use a local model to locate be sure that you have the travel times calculated. All locations will be storage in ./isp/earthquakeAnalysis/location_output/all_locations. Action: Clean Selection will remove an specific seismogram time window selection, such as Body wave, see the combo box selected and will delete from the selections. Action: Remove all selections Action: Clean Events Detected Actions: Magnitude Calculator will open a window in which you can compute different magnitudes. For open this you must have estimated an event and have selected the time-windows in the seismograms that you want the magnitudes be calculated. Action: Open Earth Model Viewer will open a tool to visualize 3D velocity models. For visualize an Earth Model you need the binary files ( buf and hdr) created in the tab Event location. Action: Data availability will plot the data availability (backlines) for each station/component of the database loaded from your folder tree. Compute Compute: STA/LTA from all processed seismograms and will plot the result together. STA/LTA takes the parameters from Parameters Settings. Compute: CWT (CF) from all processed seismograms and will plot the result together. CWT takes the parameters from Parameters Settings. Compute: Envelope from all processed seismograms and will plot the result together. Compute: Spectral Entropy from all processed seismograms and will plot the result together. Spectral entropy is estimated in small time windows see Parameters Settings. . All Seismograms: Plot together all seismograms. Stack: Compute (linear, nth-root or PWS) stack of all processed seismograms. Set your choice in File/Open Settings. Go Will ship you to the rest of ISP modules (RFs, Array analysis\u2026.).","title":"Pick Event"},{"location":"el/#multimedia-material-pick-event","text":"The following video shows a basic analysis of an earthquake","title":"Multimedia Material (Pick Event)"},{"location":"el/#polarisation-analysis","text":"The Polarization Analysis is designed to analyze the three seismograms components from a station. You can freely rotate using the rotation RT or the LQT your NEZ components an angle (Rot Angle) with an Incidence angle (Inc Angle). The Particle motion of the processed seismogram is view clicking in \u201cPlot Polarization\u201d. This option will plot all the time window in a 3D view and in three 2D plot views. If you want to make a sliding window analysis of the polarization press \u201cPolarization Analysis\u201d. This will carry out a polarization analysis on windows length and frequency bandwidth specified by the user over the full analyzed seismogram. For a full particle motion analysis, press \u201cPlot Polarization\u201d. This will open another window with a 3D particle motion on the left and the three characteristic views on the right.","title":"Polarisation Analysis"},{"location":"el/#event-location-and-focal-mechanism-fp","text":"In the Event Location Frame the user can configure the velocity grid 1D/3D model, locate earthquakes and compute Focal Mechanisms. First it is needed to set a Velocity grid framework (Grid reference and transformation type are mandatory). For now is only available Transformation Simple and Global. Next, the Grid dimensions (Grid Size). Case 2D the dimension always must be 2 and the grid reference is referred to the corner SW. Case 3D the grid reference is the center of the Grid. Choose the grid type and the wave and then generate the velocity model binary files by clicking \u201cGenerate Velocity Grid\u201d. Please follow the scheme of the next figure to set correctly your grid frame. Once the binary files are generated you can check the results in the folder: ISP/earthquakeAnalysis/location_output/model Where and how place the velocity models? 2D models (see example) LAYER 0.0 6.1 0.0 3.49 0.0 2.7 0.0 LAYER 11.0 6.4 0.0 3.66 0.0 2.7 0.0 LAYER 24.0 6.9 0.0 3.94 0.0 2.7 0.0 LAYER 31.0 8.0 0.0 4.57 0.0 2.7 0.0 ISP/earthquakeAnalysis/location_output/local_models 3D models ISP/earthquakeAnalysis/location_output/model3D (see example) Every depth layer must be placed in files called, for example For the P wave --> layer.P.mod5.mod For the S wave --> layer.S.mod5.mod Which means that inside this file there is the grid for the layer at depth 5km. The layer must be a matrix with the values in the rows from top to bottom S to N and from left to right E to W. That's mean following the next example that the file corresponding to a depth layer 5km \"layer.P.mod5.mod\" could be like this: 4.5759 4.5735 4.5707 4.5677 4.5760 4.5755 4.5766 4.5670 ...... ...... ...... ...... 4.6800 4.650 4.67300 4.5678 This matrix means that, for example corresponds to geographic points (separated in cells of, dx dy of 0.5 x 0.5 degrees: Warning grid cells must be [dx = dy = dz] for a correct interpretation. (-10.0,34) (-9.5,34) (-9.0,34) (-8.5,34) (-10.0,34.5) (-9.5,34.5) (-9.0,34.5) (-8.5,34.5) ........ ......... ......... ......... (-10.0,40.0) (-9.5,40.0) (-9.0,40.0) (-8.5,40.0) The most important step is to generate the travel-times for all the stations inside the maximum distance the user determine. Please be sure that you have load previously the metadata (this Is necessary to associate your picks with your station coordinates. The generated travel-times will save in ISP/earthquakeAnalysis/location_output/time, for example with the following name l\"ayer.P.EBAD.time.buf\" Once you have complete the above steps you can locate the earthquake and the focal mechanism. The above operation are just necessary to be implemented the first time you use a specific Earth model. **For global is not necessary generate the velocity grid and travel times. To visualize the detailed Probability Density Function, press \u201cPlot PDF\u201d once you have already carried out the location. Moreover, if you have picked the seismic phases and have been designated the polarity in \u201cEvent frame\u201d , you will be able to obtain the Focal Mechanism (it uses the subprogram FocMec)","title":"Event Location and Focal Mechanism (FP)"},{"location":"el/#earth-model-viewer","text":"The Earth Model Viewer is intended to help to visualize 3D Earth velocity models as Fig 2.8. Just select the binary file *.buf (can be generated from the model as described in previous section). Next, select the depth of the layer, the cross sections in longitude and latitude and the press plot.","title":"Earth model Viewer"},{"location":"el/#magnitudes-estimation","text":"With the Magnitude Estimation you can calculate: Local Magnitude (ML) or Body-wave (mb), Surface-wave (Ms), Moment Magnitude (Mw) and Coda Magnitude. To estimate the magnitudes you have to select a time window of body, surface or coda on the seismograms. Units must be on velocity, so you must remove the response of the instrument to velocity, previously to open the Magnitudes window. For Local magnitude you have to remove the response of Wood-Anderson instrument. The hypocenter must be already calculated. The program will read the *.hyp file before open Magnitudes window. If you place 0.00 on all parameters of local or coda magnitudes, the program will calculate these magnitude with default parameters as follows: Coda Magnitude: Values for California a = 2.0; b = 0.0035; c= -0.87 Mc_value = a np.log10(t_coda)+b dist+c Local Magnitude: a = 1.11; b =0.00189; c= -2.09 ML_value = np.log10(max_amplitude)+a np.log10(dist)+b dist+c Briefly, Once you have open the Magnitude Window, select the magnitudes you want to compute and run the computation. In the upper panel it is shown the spectrum of the body waves and the fit to calculate the moment magnitude. In the bottom panel is shown the histograms of all magnitudes (the result of the magnitudes for all seismograms for all kind of magnitudes) and on the left an additional plot used to visualize the dispersion of the results.","title":"Magnitudes Estimation"},{"location":"el/#shortcuts","text":"Shortcut Action 'Ctrl+L' Open Macro 'Ctrl+U' View Picks 'Ctrl+I' Deselect all 'Ctrl+J' Deselect a wave (Noise, Body, Surface) 'Ctrl+C' Clean events detected 'Ctrl+M' Open magnitudes calculator 'Ctrl+P' Open phases comboBox 'Ctrl+K' Save CFs (STA/LTA, Wavelet CF, Envelope, Entropy\u2026) 'Ctrl+N' Plot_all_seismograms 'Ctrl+B' Stack_all_seismograms 'a' Compute individual spectrum 'f' Compute all spectrums 'z' Compute Spectrogram 'q' Set start time 'w' Process and Plot 'e' Set end time","title":"Shortcuts"},{"location":"install/","text":"Installation First of all, clone the repository from ISP master branch . Just open your terminal and navigate whenever you want to place ISP and type in the terminal git clone https://github.com/ProjectISP/ISP.git Then, go to the folder ./ISP and to change to the ongoing version ISP 2.0 type in your terminal git checkout ISP_2.0_development To be updated, from ./ISP type in your terminal, git pull The installation file will install the requirements and will compile the source packages. At the end of the installation the user will be asked for an alias \"isp\". Following the directions Installation for end users , it is needed to have previously installed anaconda . Installation for end users (Mac and Linux) To run the installation go to ./ISP/install and type: chmod u+x ISP_installer.sh ./ISP_installer.sh Just in case the alias isp do not open the software, go to ./ISP and type: conda activate isp or source activate isp python start_isp.py Warning: We have found that in some Mac computers is difficult to compile the third package NLL , so for this reason inside the folder ./ISP/isp/mac_bin/bin, you will find NLL fully compiled. Then, you can move this files from ./ISP/isp/mac_bin/bin to ./ISP/isp/NLL7/bin that is the folder where ISP will look for running this program. Installation for developers (Mac and Linux) We suggest installing the requirements first: python3 -m venv isp source isp/bin/activate python3 -m pip install -r requirements.txt Next, from the folder ./ISP, compile the source packages: python3 setup.py build_ext --inplace Installation for Windows users In the following text, we briefly explain how to install ISP in windows via WSL . 1. Install WSL Windows Subsystem for Linux version 2 and Ubuntu 20.04 2. Install Windows X Server 3. Initialize Windows X Server Create a direct access that execute the following instructions \"C:\\Program Files\\VcXsrv.exe\" :0 -multiwindow -clipboard -wgl -ac However, it could be more easy to you just run: Windows Key + R and then in the widget type \"C:\\Program Files\\VcXsrv.exe\" :0 -multiwindow -clipboard -wgl -ac 4. Directions to follow inside WSL export DISPLAY_NUMBER=\"0.0\" export DISPLAY=$(grep -m 1 nameserver /etc/resolv.conf | awk '{print $2}'):$DISPLAY_NUMBER 5. Install Anaconda Add to path Anconda to the file .bashrc \"export PATH=~/anaconda3/bin:$PATH\" Then everything is ready to install ISP as in Linux System 6. Install normally ISP: To run the installation go to ./isp/installation and type ./ISP_installer.sh Just in case the alias isp do not open the software, go to ./ISP and type: conda activate isp or source activate isp python start_isp.py Uninstall ISP First remove the folder ISP, then type in your terminal: conda remove --name isp --all List of Requirements sqlalchemy owslib Cython deprecated matplotlib numpy scipy >= 1.4.1 obspy pandas PyQt5 PyQtWebEngine mtspec nitime Cartopy pillow PyWavelets dill nvector numba Tensorflow>=2.3.0 Good luck with the process","title":"Installation"},{"location":"install/#installation","text":"First of all, clone the repository from ISP master branch . Just open your terminal and navigate whenever you want to place ISP and type in the terminal git clone https://github.com/ProjectISP/ISP.git Then, go to the folder ./ISP and to change to the ongoing version ISP 2.0 type in your terminal git checkout ISP_2.0_development To be updated, from ./ISP type in your terminal, git pull The installation file will install the requirements and will compile the source packages. At the end of the installation the user will be asked for an alias \"isp\". Following the directions Installation for end users , it is needed to have previously installed anaconda .","title":"Installation"},{"location":"install/#installation-for-end-users-mac-and-linux","text":"To run the installation go to ./ISP/install and type: chmod u+x ISP_installer.sh ./ISP_installer.sh Just in case the alias isp do not open the software, go to ./ISP and type: conda activate isp or source activate isp python start_isp.py Warning: We have found that in some Mac computers is difficult to compile the third package NLL , so for this reason inside the folder ./ISP/isp/mac_bin/bin, you will find NLL fully compiled. Then, you can move this files from ./ISP/isp/mac_bin/bin to ./ISP/isp/NLL7/bin that is the folder where ISP will look for running this program.","title":"Installation for end users (Mac and Linux)"},{"location":"install/#installation-for-developers-mac-and-linux","text":"We suggest installing the requirements first: python3 -m venv isp source isp/bin/activate python3 -m pip install -r requirements.txt Next, from the folder ./ISP, compile the source packages: python3 setup.py build_ext --inplace","title":"Installation for developers (Mac and Linux)"},{"location":"install/#installation-for-windows-users","text":"In the following text, we briefly explain how to install ISP in windows via WSL . 1. Install WSL Windows Subsystem for Linux version 2 and Ubuntu 20.04 2. Install Windows X Server 3. Initialize Windows X Server Create a direct access that execute the following instructions \"C:\\Program Files\\VcXsrv.exe\" :0 -multiwindow -clipboard -wgl -ac However, it could be more easy to you just run: Windows Key + R and then in the widget type \"C:\\Program Files\\VcXsrv.exe\" :0 -multiwindow -clipboard -wgl -ac 4. Directions to follow inside WSL export DISPLAY_NUMBER=\"0.0\" export DISPLAY=$(grep -m 1 nameserver /etc/resolv.conf | awk '{print $2}'):$DISPLAY_NUMBER 5. Install Anaconda Add to path Anconda to the file .bashrc \"export PATH=~/anaconda3/bin:$PATH\" Then everything is ready to install ISP as in Linux System 6. Install normally ISP: To run the installation go to ./isp/installation and type ./ISP_installer.sh Just in case the alias isp do not open the software, go to ./ISP and type: conda activate isp or source activate isp python start_isp.py","title":"Installation for Windows users"},{"location":"install/#uninstall-isp","text":"First remove the folder ISP, then type in your terminal: conda remove --name isp --all","title":"Uninstall ISP"},{"location":"install/#list-of-requirements","text":"sqlalchemy owslib Cython deprecated matplotlib numpy scipy >= 1.4.1 obspy pandas PyQt5 PyQtWebEngine mtspec nitime Cartopy pillow PyWavelets dill nvector numba Tensorflow>=2.3.0 Good luck with the process","title":"List of Requirements"},{"location":"license/","text":"ISP is licensed under the GNU Lesser General Public License (LGPL) v3.0.","title":"License"},{"location":"mti/","text":"Moment Tensor Inversion Create Earth velocity model To start you need to load a Earth model. Go to Build \u00e0 Earth Model and open the Earth Model Form, the fill it and save it. Bayesian Inversion The user needs to fill the following fields to go on with the inversion: Metadata >> Path to the file where you have the metadata. This is necessary to extract the stations coordinates and the instrument information to do the deconvolution (this is not totally necessary, the user can manage the seismograms already in velocity units). Files >> path to the seismogram files Earth Model >>> Path to the Earth model file (see previous section for see how to make this file with ISP, the user can also do it manually). Time Window >>> Set the window in which the seismograms will be used (StartTime, EndTime and CHECK trim). Macro >> You can set a Macro to make basic processing over the seismograms Now Follow this steps, Process and plot Seismograms Open Stations info. This action will allow you select which station/component will be used in the inversion Plot stations Map (First, fill Latitude Longitude and depth) This is optional - Fill the info: - Hipocenter location and Uncertainity (m) - Origin Time and Uncertainity - Magnitude - Frequency range for the inversion (see Fig 2 for example) - Distance filter. Avoid statations out of the distance filter (Distance from epicenter to station) - Option Deviatoric, Circle, Shape, Covariance (please because it uses previous noise window for inversion, select long enough prevent window (i.e., 10 min)) and use precalculated Green functions Pre-calculated Green Functions is useful because, once you have run an inversion then you may filter the inversion selecting different components or distances Multimedia Material (MTI)","title":"Seismic Moment Tensor Inversion"},{"location":"mti/#moment-tensor-inversion","text":"","title":"Moment Tensor Inversion"},{"location":"mti/#create-earth-velocity-model","text":"To start you need to load a Earth model. Go to Build \u00e0 Earth Model and open the Earth Model Form, the fill it and save it.","title":"Create Earth velocity model"},{"location":"mti/#bayesian-inversion","text":"The user needs to fill the following fields to go on with the inversion: Metadata >> Path to the file where you have the metadata. This is necessary to extract the stations coordinates and the instrument information to do the deconvolution (this is not totally necessary, the user can manage the seismograms already in velocity units). Files >> path to the seismogram files Earth Model >>> Path to the Earth model file (see previous section for see how to make this file with ISP, the user can also do it manually). Time Window >>> Set the window in which the seismograms will be used (StartTime, EndTime and CHECK trim). Macro >> You can set a Macro to make basic processing over the seismograms Now Follow this steps, Process and plot Seismograms Open Stations info. This action will allow you select which station/component will be used in the inversion Plot stations Map (First, fill Latitude Longitude and depth) This is optional - Fill the info: - Hipocenter location and Uncertainity (m) - Origin Time and Uncertainity - Magnitude - Frequency range for the inversion (see Fig 2 for example) - Distance filter. Avoid statations out of the distance filter (Distance from epicenter to station) - Option Deviatoric, Circle, Shape, Covariance (please because it uses previous noise window for inversion, select long enough prevent window (i.e., 10 min)) and use precalculated Green functions Pre-calculated Green Functions is useful because, once you have run an inversion then you may filter the inversion selecting different components or distances","title":"Bayesian Inversion"},{"location":"mti/#multimedia-material-mti","text":"","title":"Multimedia Material (MTI)"},{"location":"nrt/","text":"Near Real Time Adquisition The tool Near Real Time Adquisition is intended to retrieve data from a server. Structure Metadata Set the metadata file **Net/Station/Channel Place separated by \",\" the name of nets stations and channels you want to retrieve. It is convinient to use wildcards such as \"BH?\" or \"*\" Server Address Set the name of the server address you want to point to. Max Num Traces Number of traces you want to plot Time Window Duration of the time window in minutes you want to plot the traces Save Data This action will allow saving the mseed files that are collected in the destionation folder. The mseed will have a maximum of 24 h being the cut at \"00:00:00.0000\". Plot Map This action will plot the map of the metadata stations in red plus the statios you are collecting data in green.","title":"Near Real Time Adquisition"},{"location":"nrt/#near-real-time-adquisition","text":"The tool Near Real Time Adquisition is intended to retrieve data from a server.","title":"Near Real Time Adquisition"},{"location":"nrt/#structure","text":"Metadata Set the metadata file **Net/Station/Channel Place separated by \",\" the name of nets stations and channels you want to retrieve. It is convinient to use wildcards such as \"BH?\" or \"*\" Server Address Set the name of the server address you want to point to. Max Num Traces Number of traces you want to plot Time Window Duration of the time window in minutes you want to plot the traces Save Data This action will allow saving the mseed files that are collected in the destionation folder. The mseed will have a maximum of 24 h being the cut at \"00:00:00.0000\". Plot Map This action will plot the map of the metadata stations in red plus the statios you are collecting data in green.","title":"Structure"},{"location":"ppsds/","text":"Probability Power Spectral Dentitiy (PPSD) One the most common tools to evaluate the station performance of seismic data acquisition (Mcnamara and Buland, 2004) is to estimate the Probability Density Functions (PDFs). Once the PDFs are calculated, the seismic noise levels can be compared with the standard low and high noise levels, NLNM and NHNM (Peterson, 1993), or can be calculated cumulative spectrograms to observe seasonal variations. The ISP submodule \u201cPPSD\u201d allows to build a database to storage the PDFs of the stations/components desired from PPSDs, with an specific frame work for this task. Moreover the original databased can be upgraded with more data. Once the PDFs are computed, they can be visualized into another framework that offers multiple visualization options. The Fig. 1 shows the visualization framework with the PDFs of three components from three different station and the Fig 2 & 3 the diurnal and seasonal variation, respectively. The PDFs are also compared with earthquake power desnsity spectrums (Clinton and Heaton, 2002).","title":"PPSDs"},{"location":"ppsds/#probability-power-spectral-dentitiy-ppsd","text":"One the most common tools to evaluate the station performance of seismic data acquisition (Mcnamara and Buland, 2004) is to estimate the Probability Density Functions (PDFs). Once the PDFs are calculated, the seismic noise levels can be compared with the standard low and high noise levels, NLNM and NHNM (Peterson, 1993), or can be calculated cumulative spectrograms to observe seasonal variations. The ISP submodule \u201cPPSD\u201d allows to build a database to storage the PDFs of the stations/components desired from PPSDs, with an specific frame work for this task. Moreover the original databased can be upgraded with more data. Once the PDFs are computed, they can be visualized into another framework that offers multiple visualization options. The Fig. 1 shows the visualization framework with the PDFs of three components from three different station and the Fig 2 & 3 the diurnal and seasonal variation, respectively. The PDFs are also compared with earthquake power desnsity spectrums (Clinton and Heaton, 2002).","title":"Probability Power Spectral Dentitiy (PPSD)"},{"location":"rd/","text":"Retrieve Data Retrieve Data framework is an interface to facilitate download specific events to time-series or select a period and download data from different stations. Step1: Select a FDSN web service and click load. This action will load the inventory. Step2: You can plot the inventory stations and can be add to the posterior request with double-click on the map or manually added. Also you can remove it with right button double-click. From this point you can follow different actions, Download Time Series: Just set Starttime and Endtime and click on the button. This will download the mini seeds of the stations/channels requested for that period. Download Metadata: This action will download the stations.xml of the stations/channels requested. Step3: If we want to download earthquake seismograms from a period of time for specific stations/channels. Step1: Download catalog (see figure) and select the rows of the earthquake you are interested. Next, fill the gaps for net, stations and channels. You can plot the stations and use double-click action to select the stations. Step 2: Fill the cut time-window (s) before and after the first arrival and click on Download event data. The available FDSN web services are: BGR http://eida.bgr.de EMSC http://www.seismicportal.eu ETH http://eida.ethz.ch GEONET http://service.geonet.org.nz GFZ http://geofon.gfz-potsdam.de ICGC http://ws.icgc.cat INGV http://webservices.ingv.it IPGP http://ws.ipgp.fr IRIS http://service.iris.edu ISC http://isc-mirror.iris.washington.edu KNMI http://rdsa.knmi.nl KOERI http://eida.koeri.boun.edu.tr LMU http://erde.geophysik.uni-muenchen.de NCEDC http://service.ncedc.org NIEP http://eida-sc3.infp.ro NOA http://eida.gein.noa.gr ODC http://www.orfeus-eu.org ORFEUS http://www.orfeus-eu.org RASPISHAKE http://fdsnws.raspberryshakedata.com RESIF http://ws.resif.fr SCEDC http://service.scedc.caltech.edu TEXNET http://rtserve.beg.utexas.edu USGS http://earthquake.usgs.gov USP http://sismo.iag.usp.br There is also the possibility to connect to your own server to download the inventory and the data.","title":"Retrieve Data"},{"location":"rd/#retrieve-data","text":"Retrieve Data framework is an interface to facilitate download specific events to time-series or select a period and download data from different stations. Step1: Select a FDSN web service and click load. This action will load the inventory. Step2: You can plot the inventory stations and can be add to the posterior request with double-click on the map or manually added. Also you can remove it with right button double-click. From this point you can follow different actions, Download Time Series: Just set Starttime and Endtime and click on the button. This will download the mini seeds of the stations/channels requested for that period. Download Metadata: This action will download the stations.xml of the stations/channels requested. Step3: If we want to download earthquake seismograms from a period of time for specific stations/channels. Step1: Download catalog (see figure) and select the rows of the earthquake you are interested. Next, fill the gaps for net, stations and channels. You can plot the stations and use double-click action to select the stations. Step 2: Fill the cut time-window (s) before and after the first arrival and click on Download event data. The available FDSN web services are: BGR http://eida.bgr.de EMSC http://www.seismicportal.eu ETH http://eida.ethz.ch GEONET http://service.geonet.org.nz GFZ http://geofon.gfz-potsdam.de ICGC http://ws.icgc.cat INGV http://webservices.ingv.it IPGP http://ws.ipgp.fr IRIS http://service.iris.edu ISC http://isc-mirror.iris.washington.edu KNMI http://rdsa.knmi.nl KOERI http://eida.koeri.boun.edu.tr LMU http://erde.geophysik.uni-muenchen.de NCEDC http://service.ncedc.org NIEP http://eida-sc3.infp.ro NOA http://eida.gein.noa.gr ODC http://www.orfeus-eu.org ORFEUS http://www.orfeus-eu.org RASPISHAKE http://fdsnws.raspberryshakedata.com RESIF http://ws.resif.fr SCEDC http://service.scedc.caltech.edu TEXNET http://rtserve.beg.utexas.edu USGS http://earthquake.usgs.gov USP http://sismo.iag.usp.br There is also the possibility to connect to your own server to download the inventory and the data.","title":"Retrieve Data"},{"location":"refs/","text":"Allen, R. (1982). Automatic phase pickers: Their present use and future prospects. Bulletin of the Seismological Society of America, 72(6B), S225\u2013S242. Boashash, B., and Black, P. (1987). An efficient real-time implementation of the Wigner-Ville distribution. IEEE Transactions on Acoustics, Speech, and Signal Processing, 35(11), 1611\u20131618. Bormann, P., and Dewey, J. W. (2012). The new IASPEI standards for determining magnitudes from digital data and their relation to classical magnitudes. In New Manual of Seismological Observatory Practice 2 (NMSOP-2) (pp. 1\u201344). Deutsches GeoForschungsZentrum GFZ. Cabieces, R., Buforn, E., Cesca, S., and Pazos, A. (2020). Focal Parameters of Earthquakes Offshore Cape St. Vincent Using an Amphibious Network. Pure and Applied Geophysics. https://doi.org/10.1007/s00024-020-02475-3 Cabieces, R., Kr\u00fcger, F., Garcia-Yeguas, A., Villase\u00f1or, A., Buforn, E., Pazos, A., et al. (2020). Slowness vector estimation over large-aperture sparse arrays with the Continuous Wavelet Transform (CWT): application to Ocean Bottom Seismometers. Geophysical Journal International. https://doi.org/10.1093/gji/ggaa427 Capon, J. (1969). High-resolution frequency-wavenumber spectrum analysis. Proceedings of the IEEE, 57(8), 1408\u20131418. Clinton, J. F., and Heaton, T. H. (2002). Potential advantages of a strong-motion velocity meter over a strong-motion accelerometer. Seismological Research Letters, 73(3), 332\u2013342. Daubechies, I., and Bates, B. J. (1992). Ten lectures on wavelets. ASA. Flinn, E. A. (1965). Signal analysis using rectilinearity and direction of particle motion. Proceedings of the IEEE, 53(12), 1874\u20131876. Font, Y., Kao, H., Lallemand, S., Liu, C.-S., and Chiao, L.-Y. (2004). Hypocentre determination offshore of eastern Taiwan using the Maximum Intersection method. Geophysical Journal International, 158(2), 655\u2013675. Gal, M., Reading, A. M., Ellingsen, S. P., Koper, K. D., Gibbons, S. J., and Nasholm, S. P. (2014). Improved implementation of the fk and Capon methods for array analysis of seismic noise. Geophysical Journal International, 198(2), 1045\u20131054. https://doi.org/10.1093/gji/ggu183 Goldstein, P., Dodge, D., Firpo, M., Minner, L., Lee, W. H. K., Kanamori, H., et al. (2003). SAC2000: Signal processing and analysis tools for seismologists and engineers. The IASPEI International Handbook of Earthquake and Engineering Seismology, 81, 1613\u20131620. Herrmann, R. B. (2013). Computer Programs in Seismology: An Evolving Tool for Instruction and Research. Seismological Research Letters, 84(6), 1081\u20131088. https://doi.org/10.1785/0220110096 Hunter, J. D. (2007). Matplotlib: A 2D Graphics Environment. Computing in Science and Engineering, 9(3), 90\u201395. https://doi.org/10.1109/MCSE.2007.55 Kennett, B. L. N., Engdahl, E. R., and Buland, R. (1995). Constraints on seismic velocities in the Earth from traveltimes. Geophysical Journal International. https://doi.org/10.1111/j.1365-246X.1995.tb03540.x Krischer, L. (2016). mtspec Python wrappers 0.3.2. Zenodo. Krischer, L., Megies, T., Barsch, R., Beyreuther, M., Lecocq, T., Caudron, C., and Wassermann, J. (2015). ObsPy: A bridge for seismology into the scientific Python ecosystem. Computational Science and Discovery. https://doi.org/10.1088/1749-4699/8/1/014003 LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard, W., and Jackel, L. D. (1989). Backpropagation applied to digit recognition. Neural Computation. Lomax, A., and Curtis, A. (2001). Fast, probabilistic earthquake location in 3D models using oct-tree importance sampling. In Geophys. Res. Abstr (Vol. 3, p. 955). Mallat, S. (2009). A wavelet tour of signal processing (Third). Elsevier. Nawab, S., Dowla, F., and Lacoss, R. (1985). Direction determination of wideband signals. IEEE Transactions on Acoustics, Speech, and Signal Processing, 33(5), 1114\u20131122. Perol, T., Gharbi, M., and Denolle, M. (2018). Convolutional neural network for earthquake detection and location. Science Advances, 4(2), e1700578-9. https://doi.org/10.1126/sciadv.1700578 Peterson, J. R. (1993). Observations and modeling of seismic background noise. US Geological Survey. Podvin, P., and Lecomte, I. (1991). Finite difference computation of traveltimes in very contrasted velocity models: a massively parallel approach and its associated tools. Geophysical Journal International, 105(1), 271\u2013284. Poupinet, G., Ellsworth, W. L., and Frechet, J. (1984). Monitoring velocity variations in the crust using earthquake doublets: an application to the Calaveras fault, California ( USA). Journal of Geophysical Research. https://doi.org/10.1029/JB089iB07p05719 Prieto, G. A., Parker, R. L., and Vernon, F. L. (2009). A Fortran 90 library for multitaper spectrum analysis. Computers and Geosciences. https://doi.org/10.1016/j.cageo.2008.06.007 Ross, Z. E., Meier, M.-A., and Hauksson, E. (2018). P Wave Arrival Picking and First-Motion Polarity Determination With Deep Learning. Journal of Geophysical Research: Solid Earth, 123(6), 5120\u20135129. https://doi.org/10.1029/2017JB015251 Rost, S., and Thomas, C. (2002). Array seismology: Methods and applications. Reviews of Geophysics, 40(3), 2\u201327. Rost, S., and Thomas, C. (2009). Improving seismic resolution through array processing techniques. Surveys in Geophysics, 30(4\u20135), 271\u2013299. Ruigrok, E., Gibbons, S., and Wapenaar, K. (2017). Cross-correlation beamforming. Journal of Seismology, 21(3), 495\u2013508. Sambridge, M. (2013). A Parallel Tempering algorithm for probabilistic sampling and multimodal optimization. Geophysical Journal International, 196(1), 357\u2013374. https://doi.org/10.1093/gji/ggt342 Sambridge, Malcolm, and Mosegaard, K. (2002). Monte Carlo methods in geophysical inverse problems. Reviews of Geophysics, 40(3), 3\u201329. Saragiotis, C. D., Hadjileontiadis, L. J., and Panas, S. M. (2002). PAI-S/K: A robust automatic seismic P phase arrival identification scheme. IEEE Transactions on Geoscience and Remote Sensing. https://doi.org/10.1109/TGRS.2002.800438 Schimmel, M., and Paulssen, H. (1997). Noise reduction and detection of weak, coherent signals through phase-weighted stacks. Geophysical Journal International. https://doi.org/10.1111/j.1365-246X.1997.tb05664.x Stammler, K. (1993). SeismicHandler\u2014programmable multichannel data handler for interactive and automatic processing of seismological analyses. Computers \\& Geosciences, 19(2), 135\u2013140. Stehly, L., Campillo, M., Shapiro, N. M., Rost, S., Thomas, C., Reading, A. M., et al. (2013). ObsPy: A Python toolbox for seismology. Geophysical Journal International, 40(3), 157\u2013172. https://doi.org/10.1785/gssrl.81.5.750 Thomson, D. J. (1982). Spectrum estimation and harmonic analysis. Proceedings of the IEEE, 70(9), 1055\u20131096. Torrence, C., and Compo, G. P. (1998). A Practical Guide to Wavelet Analysis. Bulletin of the American Meteorological Society. https://doi.org/10.1175/1520-0477(1998)079<0061:APGTWA>2.0.CO;2 Vack\u00e1\u0159, J., Burj\u00e1nek, J., Gallovic, F., Zahradn\u00edk, J., and Clinton, J. (2017). Bayesian ISOLA: new tool for automated centroid moment tensor inversion. Geophysical Journal International, 210(2), 693\u2013705. https://doi.org/10.1093/gji/ggx158 Ventosa, S., Schimmel, M., and Stutzmann, E. (2017). Extracting surface waves, hum and normal modes: Time-scale phase-weighted stack and beyond. Geophysical Journal International. https://doi.org/10.1093/gji/ggx284 Zhou, H. (1994). Rapid three\u2010dimensional hypocentral determination using a master station method. Journal of Geophysical Research: Solid Earth, 99(B8), 15439\u201315455.","title":"References"},{"location":"release_notes/","text":"ISP is licensed under the GNU Lesser General Public License (LGPL) v3.0","title":"Release Notes"},{"location":"rf/","text":"Receiver Functions Get & Cut Eartquakes The receiver functions module uses a water-level deconvolution method to compute P to S receiver functions from earthquake recordings in mseed format. The program can be used to perform the H-k stacking (Zhu & Kanamori, 2000) of the receiver functions for the determination of the crustal thickness and VP/VS ratio, as well as the back-tracing and CCP (\u2018common-conversion point\u2019) stacking. The first step in the receiver function analysis consists in cutting a time window containing the P-wave arrivals for each earthquake and station. The \u2018Cut earthquakes\u2019 tool requires that the data we want to work with is available locally and can be accessed from the Menu Bar under \u2018Tools > Cut earthquakes \u2026\u2019 (Fig. 1). Fig. 1. Screenshot of the 'Cut earthquakes' tool. The numbers in the image are referred to in the text below. The \u2018Raw data\u2019 and \u2018XML/dataless\u2019 fields [1] must point to the directory containing our mseed data and the StationXML/dataless file for the instruments used to record the data (which must contain the location of the stations at least, and the instrumental responses if we wish to remove them). The \u2018Quick file search\u2019 checkbox can be used to quickly index the input files if they follow the naming convention \u201cYEAR.JULDAY.LOC.STATION.CHANNEL.mseed\u201d. If they do not, simply uncheck this option and the code will read the .mseed file headers instead. The buttons labeled with \u2018\u2026\u2019 [2] can be used to select the correct paths through the file explorer. The output of the \u2018Cut earthquakes\u2019 tool consists in a directory containing the windowed earthquakes for each station [3], and a metadata file [4] containing information about each event such as the origin time, location, azimuth, ray parameter, etc. The output paths for these files must also be set by the user. Under the \u2018Settings\u2019 section we can tune a few parameters regarding event selection, quality control and time windowing of the records. The determination of the P-wave arrival time to each station is performed automatically using the TauPy package and the information contained in a event catalog downloaded from a Web Service [5]. The \u2018Earth model\u2019 used in the TauPy computations can be selected using a drop-down menu [6]. The starting and ending dates for the event catalog can be set using [7]. The minimum magnitude of the selected events, the minimum and maximum epicentral distances (in degrees), the minimum acceptable signal-to-noise ratio for each event, and the start and end of the time window to cut from the local record relative to the P-wave arrival time can be set using [8], [9], [10], [11], [12], [13]. The coordinate system in which we want to work, \u2018LQT\u2019 for Q-receiver functions or \u2018ZRT\u2019 for R-receiver functions, can be set using a drop-down menu [14]. Fig. 2. Selection of the metadata file provided in the ISP example files. Estimate RFs Once the P-wave records are cut, the metadata file and a directory with the structure output/station/mseed files should have been created (the output path was set in the \u2018Cut earthquakes\u2019 tool, fields [3] and [4]). To compute and start working with the receiver functions, load the metadata file using the Main menu bar option \u2018Input > Read event data file \u2026\u2019 (Fig. 2). Triggering this option will open the file explorer. Once the metadata file has been successfully loaded, read the P-wave records under \u2018Input > RF Analysis > Read waveforms \u2026\u2019. A new instance of the file explorer will be opened (Fig. 3). It is important that the root directory containing the different station folders (field [3] chosen in the \u2018Cut earthquakes\u2019 tool) is selected, as the directory structure will allow the code to sort the data correctly. In this example, we will use the P-wave recordings and metadata file provided with ISP. These were created from 4 years of continuous recordings of the IU.PAB station (2002 to 2006) downloaded from the IRIS DMC. After correctly selecting the example files, the station \u2018PAB\u2019 will appear in the Water-level deconvolution panel [15] (Fig. 4). The Water-level deconvolution settings include a bandpass filter that is applied to the waveforms prior to deconvolution, with corner frequencies f1 and f2 [16], the width of the low-pass Gaussian filter used in the deconvolution [17], and the water-level itself [18]. These parameters should be tuned to obtain the best results for each individual station, but the default values are usually a good starting point. Once the settings are set, press the \u2018Compute RFs\u2019 button [19] and the receiver functions will appear on the panel [20]. A maximum of 7 receiver functions are displayed at once. Scroll through the different pages using the \u2018<\u2019 and \u2018>\u2019 buttons on the bottom right side of the panel [21]. Poor-quality receiver functions can be discarded by left-clicking on them, and reaccepted by left-clicking again (Fig. 5). Right clicking on the frame of a receiver function will display the waveform from which it was calculated. The \u2018Analysis tools\u2019 panel [22] can be used to change the time range displayed [23], sort the display order of the receiver functions [24] by back-azimuth or distance, discard all events lower than a certain magnitude [25] or remove all rejections, manual or automatic, and accept all receiver functions [26]. The \u2018Receiver function stack\u2019 panel [27] is intended to give the user an overview of all the available receiver functions in use, in order to facilitate their inspection and the detection of poor quality receiver functions that may be harming the results. The stack of all receiver functions is shown in the top part of this panel [28] and stacks at regular intervals of backazimuth or epicentral distance are shown on the bottom panel [29]. The size of these intervals and any desired overlap between them can be adjusted using the fields [30] and [31]. A \u2018Ps\u2019 phase moveout correction can be applied by selecting it in the [32] drop-down menu. To display the stack, simply press the \u2018Update plot\u2019 button [33]. The \u2018H-k stack\u2019 panel [34] displays the results of the H-k stacking, based on Zhu & Kanamori (2000). The code uses the semblance-weighted stacking method proposed by Eaton et al. (2006). The density of crustal thickness \u2013 Vp/Vs ratio (k) points for the H-k matrix can be adjusted using the fields [35], although the default value should be more than enough. The crustal thickness \u2013 Vp/Vs value ranges can be set using the fields [36], and the weights for the Ps, PpPs and PpSs+PsPs phases can be set using the fields [37]. Two widely used sets of weights are 0.70, 0.20, 0.10 and 0.34, 0.33, 0.44 for Ps, PpPs and PpSs+PsPs, respectively. Once satisfied with the parameters, press the \u2018Compute H-k stack\u2019 button. The H-k matrix will be shown, and the location of the maximum will be marked with two white lines. The uncertainty is displayed as a green ellipse and is computed following Eaton et al. (2006). The values and uncertainties for both parameters are shown in two labels below the H-k plot [38], [39]. The results for the PAB station example are H = 31.42, k = 1.73. The EARS result for this station are H = 32 km, k = 1.76 (http://ears.iris.washington.edu/Data/Summary/gauss_2.5/WM/UCM/station.html, last seen 26/01/2021). The event panel is located in the bottom right side of the main window [40] and displays the location of all the events used in the H-k computations. To generate this figure, simply press the \u2018Plot events\u2019 button [41]. For reference, two circles indicating 30 and 90 degrees of epicentral distance from the station are also displayed. After the H-k maximum is determined, the theoretical arrival times of the Ps, PpPs and PpSs+PsPs phases can be displayed on the \u2018Receiver function stack\u2019 panel for reference. For this, check the box labeled as \u2018Show theoretical arrival times\u2019 [42] and press the button \u2018Update plot\u2019 [33]. Two types of results can be saved: the receiver functions (which will be used in the second chapter of this tutorial) and the H-k maximum coordinates, pressing buttons \u2018Save RFs\u2019 [43] and \u2018Save results\u2019 [44], respectively. Both options open a file dialog. The \u2018Save RFs\u2019 [43] function requires the user to select an output folder where the receiver functions for the current station will be dumped as a Python pickle file. The \u2018Save results\u2019 [44] will output the H-k results in .csv format, creating a new file if it doesn\u2019t exist, or appending to an existing file if selected. Figures of the Receiver function stack, the H-k stack, and the event location plot can be saved using the corresponding \u2018Save figure\u2019 button, which will display the Save figure dialog. The \u2018Save figure\u2019 dialog creates a .png or .pdf image of the data being displayed in the main user interface. Height, width, and quality of the figure (DPI) can be chosen, as well as the size of the margins and the figure labels. Fig. 4. Screenshot of the main window. The numbers in the image are referred to in the text above* Back-tracing and CCP stacking of RFs After the receiver functions have been computed and undergone a visual quality control, they can be saved using the \u2018Save RFs\u2019 feature ([43], Fig. 4). The resulting files can be loaded back into the program for the back-tracing and CCP stacking of the receiver functions. The first step is to load the event metadata file produced in the previous chapter. If it is already loaded for the H-k analysis, it will not be necessary to load it again. The second step is to read the saved receiver functions. This can be done under \u2018Input > CCP Stacking > Read RFs \u2026\u2019. Triggering this option will display an open file dialog, in which the directory containing the receiver function files must be selected. Once loaded, switch to the \u201cCCP Stacking\u201d tab in the main window. A map of the stations with available receiver functions will be in display. The stacking is performed over a user-defined grid. This can be done either manually (pressing the \u2018Manual selection\u2019 button in the \u2018Grid Fig. 5. Cross section map and CCP stacking","title":"Receiver Functions"},{"location":"rf/#receiver-functions","text":"","title":"Receiver Functions"},{"location":"rf/#get-cut-eartquakes","text":"The receiver functions module uses a water-level deconvolution method to compute P to S receiver functions from earthquake recordings in mseed format. The program can be used to perform the H-k stacking (Zhu & Kanamori, 2000) of the receiver functions for the determination of the crustal thickness and VP/VS ratio, as well as the back-tracing and CCP (\u2018common-conversion point\u2019) stacking. The first step in the receiver function analysis consists in cutting a time window containing the P-wave arrivals for each earthquake and station. The \u2018Cut earthquakes\u2019 tool requires that the data we want to work with is available locally and can be accessed from the Menu Bar under \u2018Tools > Cut earthquakes \u2026\u2019 (Fig. 1). Fig. 1. Screenshot of the 'Cut earthquakes' tool. The numbers in the image are referred to in the text below. The \u2018Raw data\u2019 and \u2018XML/dataless\u2019 fields [1] must point to the directory containing our mseed data and the StationXML/dataless file for the instruments used to record the data (which must contain the location of the stations at least, and the instrumental responses if we wish to remove them). The \u2018Quick file search\u2019 checkbox can be used to quickly index the input files if they follow the naming convention \u201cYEAR.JULDAY.LOC.STATION.CHANNEL.mseed\u201d. If they do not, simply uncheck this option and the code will read the .mseed file headers instead. The buttons labeled with \u2018\u2026\u2019 [2] can be used to select the correct paths through the file explorer. The output of the \u2018Cut earthquakes\u2019 tool consists in a directory containing the windowed earthquakes for each station [3], and a metadata file [4] containing information about each event such as the origin time, location, azimuth, ray parameter, etc. The output paths for these files must also be set by the user. Under the \u2018Settings\u2019 section we can tune a few parameters regarding event selection, quality control and time windowing of the records. The determination of the P-wave arrival time to each station is performed automatically using the TauPy package and the information contained in a event catalog downloaded from a Web Service [5]. The \u2018Earth model\u2019 used in the TauPy computations can be selected using a drop-down menu [6]. The starting and ending dates for the event catalog can be set using [7]. The minimum magnitude of the selected events, the minimum and maximum epicentral distances (in degrees), the minimum acceptable signal-to-noise ratio for each event, and the start and end of the time window to cut from the local record relative to the P-wave arrival time can be set using [8], [9], [10], [11], [12], [13]. The coordinate system in which we want to work, \u2018LQT\u2019 for Q-receiver functions or \u2018ZRT\u2019 for R-receiver functions, can be set using a drop-down menu [14]. Fig. 2. Selection of the metadata file provided in the ISP example files.","title":"Get &amp; Cut Eartquakes"},{"location":"rf/#estimate-rfs","text":"Once the P-wave records are cut, the metadata file and a directory with the structure output/station/mseed files should have been created (the output path was set in the \u2018Cut earthquakes\u2019 tool, fields [3] and [4]). To compute and start working with the receiver functions, load the metadata file using the Main menu bar option \u2018Input > Read event data file \u2026\u2019 (Fig. 2). Triggering this option will open the file explorer. Once the metadata file has been successfully loaded, read the P-wave records under \u2018Input > RF Analysis > Read waveforms \u2026\u2019. A new instance of the file explorer will be opened (Fig. 3). It is important that the root directory containing the different station folders (field [3] chosen in the \u2018Cut earthquakes\u2019 tool) is selected, as the directory structure will allow the code to sort the data correctly. In this example, we will use the P-wave recordings and metadata file provided with ISP. These were created from 4 years of continuous recordings of the IU.PAB station (2002 to 2006) downloaded from the IRIS DMC. After correctly selecting the example files, the station \u2018PAB\u2019 will appear in the Water-level deconvolution panel [15] (Fig. 4). The Water-level deconvolution settings include a bandpass filter that is applied to the waveforms prior to deconvolution, with corner frequencies f1 and f2 [16], the width of the low-pass Gaussian filter used in the deconvolution [17], and the water-level itself [18]. These parameters should be tuned to obtain the best results for each individual station, but the default values are usually a good starting point. Once the settings are set, press the \u2018Compute RFs\u2019 button [19] and the receiver functions will appear on the panel [20]. A maximum of 7 receiver functions are displayed at once. Scroll through the different pages using the \u2018<\u2019 and \u2018>\u2019 buttons on the bottom right side of the panel [21]. Poor-quality receiver functions can be discarded by left-clicking on them, and reaccepted by left-clicking again (Fig. 5). Right clicking on the frame of a receiver function will display the waveform from which it was calculated. The \u2018Analysis tools\u2019 panel [22] can be used to change the time range displayed [23], sort the display order of the receiver functions [24] by back-azimuth or distance, discard all events lower than a certain magnitude [25] or remove all rejections, manual or automatic, and accept all receiver functions [26]. The \u2018Receiver function stack\u2019 panel [27] is intended to give the user an overview of all the available receiver functions in use, in order to facilitate their inspection and the detection of poor quality receiver functions that may be harming the results. The stack of all receiver functions is shown in the top part of this panel [28] and stacks at regular intervals of backazimuth or epicentral distance are shown on the bottom panel [29]. The size of these intervals and any desired overlap between them can be adjusted using the fields [30] and [31]. A \u2018Ps\u2019 phase moveout correction can be applied by selecting it in the [32] drop-down menu. To display the stack, simply press the \u2018Update plot\u2019 button [33]. The \u2018H-k stack\u2019 panel [34] displays the results of the H-k stacking, based on Zhu & Kanamori (2000). The code uses the semblance-weighted stacking method proposed by Eaton et al. (2006). The density of crustal thickness \u2013 Vp/Vs ratio (k) points for the H-k matrix can be adjusted using the fields [35], although the default value should be more than enough. The crustal thickness \u2013 Vp/Vs value ranges can be set using the fields [36], and the weights for the Ps, PpPs and PpSs+PsPs phases can be set using the fields [37]. Two widely used sets of weights are 0.70, 0.20, 0.10 and 0.34, 0.33, 0.44 for Ps, PpPs and PpSs+PsPs, respectively. Once satisfied with the parameters, press the \u2018Compute H-k stack\u2019 button. The H-k matrix will be shown, and the location of the maximum will be marked with two white lines. The uncertainty is displayed as a green ellipse and is computed following Eaton et al. (2006). The values and uncertainties for both parameters are shown in two labels below the H-k plot [38], [39]. The results for the PAB station example are H = 31.42, k = 1.73. The EARS result for this station are H = 32 km, k = 1.76 (http://ears.iris.washington.edu/Data/Summary/gauss_2.5/WM/UCM/station.html, last seen 26/01/2021). The event panel is located in the bottom right side of the main window [40] and displays the location of all the events used in the H-k computations. To generate this figure, simply press the \u2018Plot events\u2019 button [41]. For reference, two circles indicating 30 and 90 degrees of epicentral distance from the station are also displayed. After the H-k maximum is determined, the theoretical arrival times of the Ps, PpPs and PpSs+PsPs phases can be displayed on the \u2018Receiver function stack\u2019 panel for reference. For this, check the box labeled as \u2018Show theoretical arrival times\u2019 [42] and press the button \u2018Update plot\u2019 [33]. Two types of results can be saved: the receiver functions (which will be used in the second chapter of this tutorial) and the H-k maximum coordinates, pressing buttons \u2018Save RFs\u2019 [43] and \u2018Save results\u2019 [44], respectively. Both options open a file dialog. The \u2018Save RFs\u2019 [43] function requires the user to select an output folder where the receiver functions for the current station will be dumped as a Python pickle file. The \u2018Save results\u2019 [44] will output the H-k results in .csv format, creating a new file if it doesn\u2019t exist, or appending to an existing file if selected. Figures of the Receiver function stack, the H-k stack, and the event location plot can be saved using the corresponding \u2018Save figure\u2019 button, which will display the Save figure dialog. The \u2018Save figure\u2019 dialog creates a .png or .pdf image of the data being displayed in the main user interface. Height, width, and quality of the figure (DPI) can be chosen, as well as the size of the margins and the figure labels. Fig. 4. Screenshot of the main window. The numbers in the image are referred to in the text above*","title":"Estimate RFs"},{"location":"rf/#back-tracing-and-ccp-stacking-of-rfs","text":"After the receiver functions have been computed and undergone a visual quality control, they can be saved using the \u2018Save RFs\u2019 feature ([43], Fig. 4). The resulting files can be loaded back into the program for the back-tracing and CCP stacking of the receiver functions. The first step is to load the event metadata file produced in the previous chapter. If it is already loaded for the H-k analysis, it will not be necessary to load it again. The second step is to read the saved receiver functions. This can be done under \u2018Input > CCP Stacking > Read RFs \u2026\u2019. Triggering this option will display an open file dialog, in which the directory containing the receiver function files must be selected. Once loaded, switch to the \u201cCCP Stacking\u201d tab in the main window. A map of the stations with available receiver functions will be in display. The stacking is performed over a user-defined grid. This can be done either manually (pressing the \u2018Manual selection\u2019 button in the \u2018Grid Fig. 5. Cross section map and CCP stacking","title":"Back-tracing and CCP stacking of RFs"},{"location":"synth/","text":"Synthetic Generator The Synthetic Tool (Fig. 1), you can make queries to download synthetic seismograms using the synthetic generator (go to the toolbar to deploy it). Fig. 2 shows the tool to make the queries. To implement a query just add the location of the stations for the synthetics be generated. Choose a model, units (velocity, displacement or acceleration) the source coordinates and time spam and, very important, the type of source and the focal parameters. Once the query is done and the synthetic seismograms are saved in the location path you had selected, you can plot the synthetic seismograms and the map/focal mechanism for give a first eye to the results.","title":"Synthetic Generator"},{"location":"synth/#synthetic-generator","text":"The Synthetic Tool (Fig. 1), you can make queries to download synthetic seismograms using the synthetic generator (go to the toolbar to deploy it). Fig. 2 shows the tool to make the queries. To implement a query just add the location of the stations for the synthetics be generated. Choose a model, units (velocity, displacement or acceleration) the source coordinates and time spam and, very important, the type of source and the focal parameters. Once the query is done and the synthetic seismograms are saved in the location path you had selected, you can plot the synthetic seismograms and the map/focal mechanism for give a first eye to the results.","title":"Synthetic Generator"},{"location":"tf/","text":"Time-Frequency Analysis Multitaper, CWT and Wigner Distribution The Time-Frequency Analysis window is designed to facilitate the computation of advanced seismic signal processes on individual seismograms. The seismograms are selected in the files explorer. You can also set a macro with basic process before running any time-Frequency analysis The most important is the selection of the Seismogram (the analysis will be show in the upper panel . \u201cseismogram 1\u201d and lower panel seismogram 2). Then you can select which one of Time-Frequency analysis you want to compute. Before Compute the Time-Frequency analysis be sure that you have filled the parameters of that kind of analysis (MT for multitaper spectrogram and CWT for Continuous Wavelet Transform). With respect to the Wavelet: The wavelet needs, select the wavelet (Morlet, Paul or Mexican Hat are available) and fill the parameters in accordance to the selected wavelet (Mallat, 2009). With respect to the Multitaper (Thomson, 1982): His analysis needs to specify the Window Length, Time-Bandwidth, the Number of Tapers and the range of the frequencies Advanced TF analysis (two seismograms at once) In the Figures are shown an example of computation of CWT and the uncertainty cone using the Morlet wavelet (upper panel) and multitaper spectrogram (lower panel). In the multimedia material can be found an example of how to mange the TF framework. Once two seismograms are selected we can follow with more advanced signal processing (Open advanced analysis): Spectrum Comparison >>> plot the amplitude and phase spectrum individual and together (Fig. 2). Coherence >>> Plot the magnitude square coherence and its phase (Fig. 3). Cross Correlation >>> Plot the Autocorrelations and the cross correlation of both signals (Fig. 4). Cross Wavelet >>> Plot the Cross-CWT of both signals (Fig. 5). Multimedia Material (Time-Frequency Analysis) The following video shows a basic analysis of an earthquake Shortcuts Shortcut Action 'q' Set start time 'w' Process and Plot 'e' Set end time","title":"Time-Frequency Analysis"},{"location":"tf/#time-frequency-analysis","text":"","title":"Time-Frequency Analysis"},{"location":"tf/#multitaper-cwt-and-wigner-distribution","text":"The Time-Frequency Analysis window is designed to facilitate the computation of advanced seismic signal processes on individual seismograms. The seismograms are selected in the files explorer. You can also set a macro with basic process before running any time-Frequency analysis The most important is the selection of the Seismogram (the analysis will be show in the upper panel . \u201cseismogram 1\u201d and lower panel seismogram 2). Then you can select which one of Time-Frequency analysis you want to compute. Before Compute the Time-Frequency analysis be sure that you have filled the parameters of that kind of analysis (MT for multitaper spectrogram and CWT for Continuous Wavelet Transform). With respect to the Wavelet: The wavelet needs, select the wavelet (Morlet, Paul or Mexican Hat are available) and fill the parameters in accordance to the selected wavelet (Mallat, 2009). With respect to the Multitaper (Thomson, 1982): His analysis needs to specify the Window Length, Time-Bandwidth, the Number of Tapers and the range of the frequencies","title":"Multitaper, CWT and Wigner Distribution"},{"location":"tf/#advanced-tf-analysis-two-seismograms-at-once","text":"In the Figures are shown an example of computation of CWT and the uncertainty cone using the Morlet wavelet (upper panel) and multitaper spectrogram (lower panel). In the multimedia material can be found an example of how to mange the TF framework. Once two seismograms are selected we can follow with more advanced signal processing (Open advanced analysis): Spectrum Comparison >>> plot the amplitude and phase spectrum individual and together (Fig. 2). Coherence >>> Plot the magnitude square coherence and its phase (Fig. 3). Cross Correlation >>> Plot the Autocorrelations and the cross correlation of both signals (Fig. 4). Cross Wavelet >>> Plot the Cross-CWT of both signals (Fig. 5).","title":"Advanced TF analysis (two seismograms at once)"},{"location":"tf/#multimedia-material-time-frequency-analysis","text":"The following video shows a basic analysis of an earthquake","title":"Multimedia Material (Time-Frequency Analysis)"},{"location":"tf/#shortcuts","text":"Shortcut Action 'q' Set start time 'w' Process and Plot 'e' Set end time","title":"Shortcuts"}]}