{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Integrated Seismic Program (ISP) Documentation Integrated Seismic Program is an amenable toolbox that joins functionality and standard algorithms commonly used in seismology. The complete software is separated in several modules and each module is designed to overcome a specific task. In this tutorial will show how you can master ISP GitHub ISP github . Follow us in: twitter . Reference Paper : Roberto Cabieces, Andr\u00e9s Olivar\u2010Casta\u00f1o, Thiago C. Junqueira, Jes\u00fas Relinque, Luis Fernandez\u2010Prieto, Ji\u0159\u00ed Vack\u00e1r, Boris R\u00f6sler, Jaime Barco, Antonio Pazos, Luz Garc\u00eda\u2010Mart\u00ednez; Integrated Seismic Program (ISP): A New Python GUI\u2010Based Software for Earthquake Seismology and Seismic Signal Processing. Seismological Research Letters 2022;; 93 (3): 1895\u20131908. doi: https://doi.org/10.1785/0220210205 News 2022-10-25 We have created a repository with an example of 3D model The ISP team has recently developed: Earthquake Analysis module Upgraded In thin upgrade you can create your project from your individual files or from your sds structure. We have also included a fast way to search your waveforms from a catalog (./isp/examples/catalog/). Seismic Ambient Noise Tomography For now, It is available the Empirical Green Functions retrieval of vertical and Horizontal components, synchronize clocks using EGFs ,a tool to measure Group and Phase velocity from dispersion curves and create dispersion maps. An example with the results of Cabieces et al., 2022 \"Upper lithospheric structure of northeastern Venezuela from joint inversion of surface wave dispersion and receiver functions\" can be found in ./isp/ant Back Projection We have recently developed the BackProjection tool which is included in the Array Anaysis module. Please,see also the tutorial for further details. Testing Real Time Acquisition You can play with this new tool, soon we incorporate the corresponding tutorial.","title":"Home"},{"location":"#welcome-to-integrated-seismic-program-isp-documentation","text":"Integrated Seismic Program is an amenable toolbox that joins functionality and standard algorithms commonly used in seismology. The complete software is separated in several modules and each module is designed to overcome a specific task. In this tutorial will show how you can master ISP GitHub ISP github . Follow us in: twitter . Reference Paper : Roberto Cabieces, Andr\u00e9s Olivar\u2010Casta\u00f1o, Thiago C. Junqueira, Jes\u00fas Relinque, Luis Fernandez\u2010Prieto, Ji\u0159\u00ed Vack\u00e1r, Boris R\u00f6sler, Jaime Barco, Antonio Pazos, Luz Garc\u00eda\u2010Mart\u00ednez; Integrated Seismic Program (ISP): A New Python GUI\u2010Based Software for Earthquake Seismology and Seismic Signal Processing. Seismological Research Letters 2022;; 93 (3): 1895\u20131908. doi: https://doi.org/10.1785/0220210205","title":"Welcome to Integrated Seismic Program (ISP) Documentation"},{"location":"#news-2022-10-25","text":"We have created a repository with an example of 3D model The ISP team has recently developed: Earthquake Analysis module Upgraded In thin upgrade you can create your project from your individual files or from your sds structure. We have also included a fast way to search your waveforms from a catalog (./isp/examples/catalog/). Seismic Ambient Noise Tomography For now, It is available the Empirical Green Functions retrieval of vertical and Horizontal components, synchronize clocks using EGFs ,a tool to measure Group and Phase velocity from dispersion curves and create dispersion maps. An example with the results of Cabieces et al., 2022 \"Upper lithospheric structure of northeastern Venezuela from joint inversion of surface wave dispersion and receiver functions\" can be found in ./isp/ant Back Projection We have recently developed the BackProjection tool which is included in the Array Anaysis module. Please,see also the tutorial for further details. Testing Real Time Acquisition You can play with this new tool, soon we incorporate the corresponding tutorial.","title":"News 2022-10-25"},{"location":"Special_Thanks/","text":"The Developer Team of ISP thanks to: Anthony Lomax and Claudio Satriano for helping in NLL configuration and the help in the framework 3D-model Visualisation. ObsPy developers and users community for giving a hand to this project during the last few years. Real Instituto y Observatorio de la Armada (Spain), University of Potsdam (Germany), Institute of Rock Structure and Mechanic (Chzechia), University of Oviedo (Spain), Universidad de Granada (Spain), Instituto de Ciencias del Mar (Spain) and Instituto Geogr\u00e1fico Nacional (Spain).","title":"The Developer Team of ISP thanks to:"},{"location":"Special_Thanks/#the-developer-team-of-isp-thanks-to","text":"Anthony Lomax and Claudio Satriano for helping in NLL configuration and the help in the framework 3D-model Visualisation. ObsPy developers and users community for giving a hand to this project during the last few years. Real Instituto y Observatorio de la Armada (Spain), University of Potsdam (Germany), Institute of Rock Structure and Mechanic (Chzechia), University of Oviedo (Spain), Universidad de Granada (Spain), Instituto de Ciencias del Mar (Spain) and Instituto Geogr\u00e1fico Nacional (Spain).","title":"The Developer Team of ISP thanks to:"},{"location":"aa/","text":"Array Analysis Array Response Function (ARF) The Array Response Function (ARF) (Ruigrok et al., 2017) helps to evaluate the resolution of the array in a specific bandwidth. First you need to create a coordinates files and then load it. To create the coordinate file go to \u201cFiles >>> Stations Coordinates\u201d and fill the table with lat (o), lon (o) and depth (km). Then you can compute the ARF and plot the map with the array stations. Frequency-Wavenumber Analysis The Frequency-Wavenumber (FK) is basically a method to compute the beamforming in the frequency domain (Capon, 1969). To compute the FK you need follow this steps; Files: Path where you have the seismograms Dataless: path where you have the metadata ( .dlsv or .xml) Set temporal window of the analysis and check the box Trim Plot the seismograms Fill the parameters (Slowness Max, Time Window, overlap\u2026\u2026) Choose methods Press Run F-K Now, you will watch in the upper panels the Rel Power, Absolute Power, Back-Azimuth and Slowness results of your analysis. Two more actions: Double pick in the upper panels will run the FK in that specific time window (starting in the point). Then, the slowness map and the stack corresponding to the delays of the maximum power in the slowness vector will show up. The pick with the slowness vector corresponding to the phase you selected are automatically saved in the file \u201cisp/arrayanalysis/dataframe.csv\u201d and you can open the file just pressing \u201cctrl+o\u201d Vespagram The vespagram is a visualization of the FK results for an specific backazimuth or slowness. So, once you have done the FK analysis, you can compute the vespagram (Rost and Thomas, 2002). But before, you must select the time window. Go with the mouse to the any upper panel. Pick, hold and drag to the right direction to do the selection. Now you can open the vespagram window. In the vespagram window you can select the parameters (Win length, overlap, and frequency bandwidth of the analysis) and the backazimuth and slowness where you want to compute the vespagram. Back Projection The Back Projection is a relatively new technique (Kruger and Ohrnberger 2005) designed to quickly and effectively imaging rupture process of large earthquakes. Back-projecting seismic data can be done by big seismic arrays. In ISP the user can process the seismograms and set the BackProjection parameters. it is shown a screenshot of the tool. First the user set the path to the seismograms, metadata and the output folder. Second, the seismograms can be chopped and a macro with some signal processing can be established. Then, the user must set the Back Projection parameters: Warning . BackProjection is highly computing demanding, so we do not recomend using too high resolutions (dx = dy > 0.5), too long time window (time window < 800s) and too big grids (maxlat-minlat and maxlon - minlon < 15 degrees) Grid: set the minimum longitude and latitude and the maximum latitude and longitude as well as dx and dy (resolution in longitude and latitude in degrees) where the Back projection is going to be calculated. Set the depth. Time window is the whole period in which the BackProjection is going to be calculated. A small sliding window will be shifted forward in time in step by step . Click on generate the Travel Time Grid. This action will create a travel time grid in wich your grid cells have the travel time from every station to every lat and lon cell. Click on Run BackProjection. In every step will be calculated the Backprojcetion aligning the traces using the Multi Channel Cross Correlation technique (VanDecar and Crosson 1990) according to the Travel Time grid and estimating the power by a simple linear stack or using the Zero Lag Cross Correlation Technique (Almendros et al., 1999). Finally, Load the result video and play it. Multimedia Material (Array Analysis) The following video shows a basic analysis of a nueclear explotion (Test from Nort Korea test 2017, Alaska Array ILAR)","title":"Array Analysis"},{"location":"aa/#array-analysis","text":"","title":"Array Analysis"},{"location":"aa/#array-response-function-arf","text":"The Array Response Function (ARF) (Ruigrok et al., 2017) helps to evaluate the resolution of the array in a specific bandwidth. First you need to create a coordinates files and then load it. To create the coordinate file go to \u201cFiles >>> Stations Coordinates\u201d and fill the table with lat (o), lon (o) and depth (km). Then you can compute the ARF and plot the map with the array stations.","title":"Array Response Function (ARF)"},{"location":"aa/#frequency-wavenumber-analysis","text":"The Frequency-Wavenumber (FK) is basically a method to compute the beamforming in the frequency domain (Capon, 1969). To compute the FK you need follow this steps; Files: Path where you have the seismograms Dataless: path where you have the metadata ( .dlsv or .xml) Set temporal window of the analysis and check the box Trim Plot the seismograms Fill the parameters (Slowness Max, Time Window, overlap\u2026\u2026) Choose methods Press Run F-K Now, you will watch in the upper panels the Rel Power, Absolute Power, Back-Azimuth and Slowness results of your analysis. Two more actions: Double pick in the upper panels will run the FK in that specific time window (starting in the point). Then, the slowness map and the stack corresponding to the delays of the maximum power in the slowness vector will show up. The pick with the slowness vector corresponding to the phase you selected are automatically saved in the file \u201cisp/arrayanalysis/dataframe.csv\u201d and you can open the file just pressing \u201cctrl+o\u201d","title":"Frequency-Wavenumber Analysis"},{"location":"aa/#vespagram","text":"The vespagram is a visualization of the FK results for an specific backazimuth or slowness. So, once you have done the FK analysis, you can compute the vespagram (Rost and Thomas, 2002). But before, you must select the time window. Go with the mouse to the any upper panel. Pick, hold and drag to the right direction to do the selection. Now you can open the vespagram window. In the vespagram window you can select the parameters (Win length, overlap, and frequency bandwidth of the analysis) and the backazimuth and slowness where you want to compute the vespagram.","title":"Vespagram"},{"location":"aa/#back-projection","text":"The Back Projection is a relatively new technique (Kruger and Ohrnberger 2005) designed to quickly and effectively imaging rupture process of large earthquakes. Back-projecting seismic data can be done by big seismic arrays. In ISP the user can process the seismograms and set the BackProjection parameters. it is shown a screenshot of the tool. First the user set the path to the seismograms, metadata and the output folder. Second, the seismograms can be chopped and a macro with some signal processing can be established. Then, the user must set the Back Projection parameters: Warning . BackProjection is highly computing demanding, so we do not recomend using too high resolutions (dx = dy > 0.5), too long time window (time window < 800s) and too big grids (maxlat-minlat and maxlon - minlon < 15 degrees) Grid: set the minimum longitude and latitude and the maximum latitude and longitude as well as dx and dy (resolution in longitude and latitude in degrees) where the Back projection is going to be calculated. Set the depth. Time window is the whole period in which the BackProjection is going to be calculated. A small sliding window will be shifted forward in time in step by step . Click on generate the Travel Time Grid. This action will create a travel time grid in wich your grid cells have the travel time from every station to every lat and lon cell. Click on Run BackProjection. In every step will be calculated the Backprojcetion aligning the traces using the Multi Channel Cross Correlation technique (VanDecar and Crosson 1990) according to the Travel Time grid and estimating the power by a simple linear stack or using the Zero Lag Cross Correlation Technique (Almendros et al., 1999). Finally, Load the result video and play it.","title":"Back Projection"},{"location":"aa/#multimedia-material-array-analysis","text":"The following video shows a basic analysis of a nueclear explotion (Test from Nort Korea test 2017, Alaska Array ILAR)","title":"Multimedia Material (Array Analysis)"},{"location":"ant/","text":"Ambient Noise Tomography The module ANT is divided in three main parts. First the toolbox designed to retrive Empirical Green Function, second the toolbos designed to measure phase and group velocity from the dispersion curves of EGs and third the toolbox to generate dispersion maps from the previous measurements. In this tutorial is explained how to manage the module. EGF 1 Setting Files Path & Metadata To set the path to the metadata of your network and the path where you have hosted your seismogram files. First, let's create a project. Set the path where you have the data files. They can be located in any kind of structure, for example in SDS arquitecture ( NETWORK/STATION/CHANNEL/FILES ) or simply everything in one single folder. WARNING!, create the project can take some time, do not desperate!. Second, set the path where you have the metadata of all nets/stations/channels yo want to process. 2 Setting Parameters for the pre-processing steps of the EGFs 2.1. Processing Box Processing Time Window : This is the time window in seconds that the daily seismograms files will be splitted to save the matrix of noise (see below for more details). Filter Files : Might be you only want to generate a project for a set of stations \"sta1,sta2,sta3...\" or a set of channels \"BHZ,HHZ\". If you want everything just let the space empty. Remove Instrumet : Set the four corner frequencies (very carefull with nyquist frequency of your data), the water level value and the output units. Even though this operation is computationally demanding, it is fully recommended to deconvolve your instrument to prevent from mixture cross-correlation of data from different instruments. Decimate : Set the decimation factor. For example if you have HHZ (100hz), a good decimation factor would be 10 to set the new sampling rate to 10 Hz, which is enough to later measure dispersion. Time Normalization : If is selected a running avarage, a moving median avarage filter of time window selected will be applied. If 1 bit is selected (not recommended) amplitudes will be mapped to (+1, -1). Spectral Whithening : A moving avarage filter in the amplitude spectrum is applied with a bandwidth selected by the user. Then set the folder where you want the output of the pre-processing and the EGFs. 2.2. Stack Box Components : Select the components that you want to cross correlate and stack. This operation allows ISP just select specific noise matrix to boost the speed of the stack. Stacking Method :Select amoung Phase Wave stack, Linear and nth-root stack. Personally we recommend go for linear if you have several months of data and go for PWS if you have just few . Nth-rooth for testing and comparison with linear. The parameter is the power of the method in PWS or Nrooth (Do not change from 2 :-)) Maximum Intedistance : Because sometimes we do not want to mix EGFs with very long interdistance with short distance, ISP allows the user to filter the cross correlation and stack computation by maximum interdistance value. Check Noise Matrix Output : If the user check Compute daily Stacks , ISP will compute the evolution of the EGFs in partial stacks of 20 days. If Include Autocorrelations and Shifted Cross Correlations , ISP will estimate all pssoble cross-correlations including autocorrelations e.g., ZZ and both cross-correlations (e.g., ZE and EZ). This option is mandatory to be checked if you want go for Transversal components to estimate dispersion curves of Love Waves. 3 Run pre-processing Now, click on Run pre-processing. This action will load your settings and will make a database of the available files. Then the process will start to process the data. Finally per every station/channel a file will be saved containing a matrix with the noise data in frequency domain, ready to cross-correlate. 4 Run Stack This action will load files from the pre-processing step and then for every channel-channel combination will do a cross correlation and stack all the stacks will be saved in the .outpur_directory/stack. 5 Explore your EGFs In this point the user can set the path to the output files (hdf5 or sac files), read the files and then process and plot . The user can also establish a Macro to process the EGFs, plot a map and sort the EGFs by inter station distance. Notice that autocorrelations will be 0 distance. Set Path Set the path to your stack output directory. Read Files create a list ready to process and plot of the available stack EGF in the folder. If Sort is checked, the files will be sorted by inter-station distance or backazimth. Process and Plot Process the EGFs of the list according to the macro previously established and then plot. 6 Explaining the output When the user compute the preprocess, all information is saved in Noise Matrix per station/channel. The noise matrid is a 3D matrix in whic the first dimension or the rows are consecutive time windows of an split day, the seconddimension or the colums are the day and the third dimension or depth is the complex numers corresponding to the processed spectrum of the noise window. The matrix is saved as pickle with name \"NWTSTACHANNEL\". The matrix includes a column header with Clock Synchronization Dispersion Curves Dispersion Maps","title":"Ambient Noise Tomography"},{"location":"ant/#ambient-noise-tomography","text":"The module ANT is divided in three main parts. First the toolbox designed to retrive Empirical Green Function, second the toolbos designed to measure phase and group velocity from the dispersion curves of EGs and third the toolbox to generate dispersion maps from the previous measurements. In this tutorial is explained how to manage the module.","title":"Ambient Noise Tomography"},{"location":"ant/#egf","text":"1 Setting Files Path & Metadata To set the path to the metadata of your network and the path where you have hosted your seismogram files. First, let's create a project. Set the path where you have the data files. They can be located in any kind of structure, for example in SDS arquitecture ( NETWORK/STATION/CHANNEL/FILES ) or simply everything in one single folder. WARNING!, create the project can take some time, do not desperate!. Second, set the path where you have the metadata of all nets/stations/channels yo want to process. 2 Setting Parameters for the pre-processing steps of the EGFs 2.1. Processing Box Processing Time Window : This is the time window in seconds that the daily seismograms files will be splitted to save the matrix of noise (see below for more details). Filter Files : Might be you only want to generate a project for a set of stations \"sta1,sta2,sta3...\" or a set of channels \"BHZ,HHZ\". If you want everything just let the space empty. Remove Instrumet : Set the four corner frequencies (very carefull with nyquist frequency of your data), the water level value and the output units. Even though this operation is computationally demanding, it is fully recommended to deconvolve your instrument to prevent from mixture cross-correlation of data from different instruments. Decimate : Set the decimation factor. For example if you have HHZ (100hz), a good decimation factor would be 10 to set the new sampling rate to 10 Hz, which is enough to later measure dispersion. Time Normalization : If is selected a running avarage, a moving median avarage filter of time window selected will be applied. If 1 bit is selected (not recommended) amplitudes will be mapped to (+1, -1). Spectral Whithening : A moving avarage filter in the amplitude spectrum is applied with a bandwidth selected by the user. Then set the folder where you want the output of the pre-processing and the EGFs. 2.2. Stack Box Components : Select the components that you want to cross correlate and stack. This operation allows ISP just select specific noise matrix to boost the speed of the stack. Stacking Method :Select amoung Phase Wave stack, Linear and nth-root stack. Personally we recommend go for linear if you have several months of data and go for PWS if you have just few . Nth-rooth for testing and comparison with linear. The parameter is the power of the method in PWS or Nrooth (Do not change from 2 :-)) Maximum Intedistance : Because sometimes we do not want to mix EGFs with very long interdistance with short distance, ISP allows the user to filter the cross correlation and stack computation by maximum interdistance value. Check Noise Matrix Output : If the user check Compute daily Stacks , ISP will compute the evolution of the EGFs in partial stacks of 20 days. If Include Autocorrelations and Shifted Cross Correlations , ISP will estimate all pssoble cross-correlations including autocorrelations e.g., ZZ and both cross-correlations (e.g., ZE and EZ). This option is mandatory to be checked if you want go for Transversal components to estimate dispersion curves of Love Waves. 3 Run pre-processing Now, click on Run pre-processing. This action will load your settings and will make a database of the available files. Then the process will start to process the data. Finally per every station/channel a file will be saved containing a matrix with the noise data in frequency domain, ready to cross-correlate. 4 Run Stack This action will load files from the pre-processing step and then for every channel-channel combination will do a cross correlation and stack all the stacks will be saved in the .outpur_directory/stack. 5 Explore your EGFs In this point the user can set the path to the output files (hdf5 or sac files), read the files and then process and plot . The user can also establish a Macro to process the EGFs, plot a map and sort the EGFs by inter station distance. Notice that autocorrelations will be 0 distance. Set Path Set the path to your stack output directory. Read Files create a list ready to process and plot of the available stack EGF in the folder. If Sort is checked, the files will be sorted by inter-station distance or backazimth. Process and Plot Process the EGFs of the list according to the macro previously established and then plot. 6 Explaining the output When the user compute the preprocess, all information is saved in Noise Matrix per station/channel. The noise matrid is a 3D matrix in whic the first dimension or the rows are consecutive time windows of an split day, the seconddimension or the colums are the day and the third dimension or depth is the complex numers corresponding to the processed spectrum of the noise window. The matrix is saved as pickle with name \"NWTSTACHANNEL\". The matrix includes a column header with","title":"EGF"},{"location":"ant/#clock-synchronization","text":"","title":"Clock Synchronization"},{"location":"ant/#dispersion-curves","text":"","title":"Dispersion Curves"},{"location":"ant/#dispersion-maps","text":"","title":"Dispersion Maps"},{"location":"basics/","text":"Warming tutorial This section will show you the overall structure of the project and a basic idea of how are the data managed by ISP. Seismograms and metadata We start explaining how to start a project inside Earthquake Analysis module (more details inside sections). First of all you need to create a project. A project is basically a \"dictionary file\" that tells your computer where are your valid data. This strategy makes easier to explore your big data. Now, let's create a new project pressing the button \"New Project\" You will find this dialog that will guide you to crete the project. Two option: Create Project from individual files, you will select individual files that going to be part of your project. Create Full Project, you give the path to the folder tree where you have your daily data files. ISP will scan all folders validating the files and will create the project. Afterwards, you can save your project (recommended) giving a name and press \"Saving Project\". Becareful, when you start to create a project ISP will capture the search filters, so for example if in the Project Box Channels is selected \"BHZ\" as in the picture below, the project will created based on this filters- If you do not want any filter set the filter bocxes empty Filters boxes uses Regex Python keywords : For example, if ypu want search any component in channels \"BH.\" or if you want any station but verical component station \".+\" channel BHZ. Very important, you can reload your project apllying seatching filters simply by pressing \"R\" outside the plot window. This action also takes into account if trim is checked to cut the time window. This is very useful to search for specific time windows where you already knows in advance that there is an event there. Description In ISP we have decided go for miniseed format, with is one of the most broadly used data storage formats for seismograms. The best description is given at http://ds.iris.edu/ds/nodes/dmc/data/formats/miniseed/ which is simply: MiniSEED is the subset of the SEED standard that is used for time series data. Very limited metadata for the time series is included in miniSEED beyond time series identification and simple state-of-health flags. In particular, geographic coordinates, response/scaling information and other information needed to interpret the data values are not included. Time series are stored as generally independent, fixed length data records which each contain a small segment of contiguous series values. A reader of miniSEED is required to reconstruct longer, contiguous time series from the data record segments. Common record lengths are 512-byte (for real time streams) and 4096-byte (for archiving), other record lengths are used for special scenarios. A \u201cfile\u201d or \u201cstream\u201d of miniSEED is simply a concatenation of data records. Depending on the capabilities of the intended reader the data records for multiple channels of data may be multiplexed together. Metadata (Dataless and *.xml) ISP uses two kind of metadata files either Dataless or xml. ( https://docs.obspy.org/tutorial/code_snippets/stationxml_file_from_scratch.html ). You can find an example of this files at the folders isp/Metadata/dataless and isp/Metadata/xml. As you will see, in the this files there is information structured as a dictionary nets/stations/channels. Personally, the best way to make your own metadata file is using either the java software PDCC or going to the API Station Management Portal . Important : The idea in ISP is that your Metadata file (one single file) contains all of the information (such as coordinates of your stations, instrument response, sampling frequency and so on ...) of the miniseed files you are going to manage. The reason of this design is that, it is easier to programming something that works independently from the miniseed file to metadata. For example when sorting the minified files from respect to an event. The software internally reads the name of all of your files (in the header) and then match this info with the metadata file. Notes : It is very easy using python to convert your dataless to xml. From: https://docs.obspy.org/_modules/obspy/core/inventory/inventory.html#Inventory.write from obspy import read_inventory inv = read_inventory(\"path_to_your_dataless\") inv.write(path_or_file_object, format=\"stationxml\", validate=True) Shortcuts We show an example of Eartuqake analysis module keyword and mouse shortcuts. Generally there are shortcuts to be used inside plots and ohter shortcuts to be used to run actions.","title":"Start with the basics"},{"location":"basics/#warming-tutorial","text":"This section will show you the overall structure of the project and a basic idea of how are the data managed by ISP.","title":"Warming tutorial"},{"location":"basics/#seismograms-and-metadata","text":"We start explaining how to start a project inside Earthquake Analysis module (more details inside sections). First of all you need to create a project. A project is basically a \"dictionary file\" that tells your computer where are your valid data. This strategy makes easier to explore your big data. Now, let's create a new project pressing the button \"New Project\" You will find this dialog that will guide you to crete the project. Two option: Create Project from individual files, you will select individual files that going to be part of your project. Create Full Project, you give the path to the folder tree where you have your daily data files. ISP will scan all folders validating the files and will create the project. Afterwards, you can save your project (recommended) giving a name and press \"Saving Project\". Becareful, when you start to create a project ISP will capture the search filters, so for example if in the Project Box Channels is selected \"BHZ\" as in the picture below, the project will created based on this filters- If you do not want any filter set the filter bocxes empty Filters boxes uses Regex Python keywords : For example, if ypu want search any component in channels \"BH.\" or if you want any station but verical component station \".+\" channel BHZ. Very important, you can reload your project apllying seatching filters simply by pressing \"R\" outside the plot window. This action also takes into account if trim is checked to cut the time window. This is very useful to search for specific time windows where you already knows in advance that there is an event there.","title":"Seismograms and metadata"},{"location":"basics/#description","text":"In ISP we have decided go for miniseed format, with is one of the most broadly used data storage formats for seismograms. The best description is given at http://ds.iris.edu/ds/nodes/dmc/data/formats/miniseed/ which is simply: MiniSEED is the subset of the SEED standard that is used for time series data. Very limited metadata for the time series is included in miniSEED beyond time series identification and simple state-of-health flags. In particular, geographic coordinates, response/scaling information and other information needed to interpret the data values are not included. Time series are stored as generally independent, fixed length data records which each contain a small segment of contiguous series values. A reader of miniSEED is required to reconstruct longer, contiguous time series from the data record segments. Common record lengths are 512-byte (for real time streams) and 4096-byte (for archiving), other record lengths are used for special scenarios. A \u201cfile\u201d or \u201cstream\u201d of miniSEED is simply a concatenation of data records. Depending on the capabilities of the intended reader the data records for multiple channels of data may be multiplexed together.","title":"Description"},{"location":"basics/#metadata-dataless-and-xml","text":"ISP uses two kind of metadata files either Dataless or xml. ( https://docs.obspy.org/tutorial/code_snippets/stationxml_file_from_scratch.html ). You can find an example of this files at the folders isp/Metadata/dataless and isp/Metadata/xml. As you will see, in the this files there is information structured as a dictionary nets/stations/channels. Personally, the best way to make your own metadata file is using either the java software PDCC or going to the API Station Management Portal . Important : The idea in ISP is that your Metadata file (one single file) contains all of the information (such as coordinates of your stations, instrument response, sampling frequency and so on ...) of the miniseed files you are going to manage. The reason of this design is that, it is easier to programming something that works independently from the miniseed file to metadata. For example when sorting the minified files from respect to an event. The software internally reads the name of all of your files (in the header) and then match this info with the metadata file. Notes : It is very easy using python to convert your dataless to xml. From: https://docs.obspy.org/_modules/obspy/core/inventory/inventory.html#Inventory.write from obspy import read_inventory inv = read_inventory(\"path_to_your_dataless\") inv.write(path_or_file_object, format=\"stationxml\", validate=True)","title":"Metadata (Dataless and *.xml)"},{"location":"basics/#shortcuts","text":"We show an example of Eartuqake analysis module keyword and mouse shortcuts. Generally there are shortcuts to be used inside plots and ohter shortcuts to be used to run actions.","title":"Shortcuts"},{"location":"db/","text":"Database The Database sub-module is designed to incorporate all the results you can obtain from Earthquake location and Moment Tensor Inversion. It is possible to make queries to the data base, for example searching earthquake locations by a geographic frame or in a specific time spam. Moreover you can plot the results of your query in a map. With double click in a row of the table you can add a Focal mechanism detailed to the map and with right click just over one row of the table you can remove events. In the toolbar you will find two options, the first one \u201cRead hyp folder load\u201d will generate a database from all *.hyp that you had placed in the folder. The other option \u201cRead last location\u201d will load (last.hyp, from earthquake analysis), (log.txt, from Moment Tensor Inversion), (mechanism.out, from Earthquake analysis) and (magnitudes.out, from Earthquake analysis) and will fed the database with all of the information extracted. Fig. 1 shows a Data Base example. To plot fashion maps you can add a WMS and the layer you want to plot. I suggest go to this web site to find nice WMS/layers: MAP_SERVICE_URL = 'https://gis.ngdc.noaa.gov/arcgis/services/","title":"Database"},{"location":"db/#database","text":"The Database sub-module is designed to incorporate all the results you can obtain from Earthquake location and Moment Tensor Inversion. It is possible to make queries to the data base, for example searching earthquake locations by a geographic frame or in a specific time spam. Moreover you can plot the results of your query in a map. With double click in a row of the table you can add a Focal mechanism detailed to the map and with right click just over one row of the table you can remove events. In the toolbar you will find two options, the first one \u201cRead hyp folder load\u201d will generate a database from all *.hyp that you had placed in the folder. The other option \u201cRead last location\u201d will load (last.hyp, from earthquake analysis), (log.txt, from Moment Tensor Inversion), (mechanism.out, from Earthquake analysis) and (magnitudes.out, from Earthquake analysis) and will fed the database with all of the information extracted. Fig. 1 shows a Data Base example. To plot fashion maps you can add a WMS and the layer you want to plot. I suggest go to this web site to find nice WMS/layers: MAP_SERVICE_URL = 'https://gis.ngdc.noaa.gov/arcgis/services/","title":"Database"},{"location":"el/","text":"Earthquake Location The module Earthquake analysis allows you to analyse waveforms, polarization analysis of seismograms 3-components, calculate different magnitudes and finally locate an event and estimate the focal mechanism (First Polarity). We will walk through all of the functionality following this scheme: Pick Event From top to bottom in the left side of the window you will see: Event Info : This small box let enter information about an event, in this way you can plot the theoretical arrivals (ak-135F) with respect your seismograms. Plot arrivals requires that you have correctly loaded your metadata. Metadata File : By clicking in this button you will place the path to you metadata file. The metadata file must contain the information of all of the stations seismograms you want to analyse (metadata must be a xml or dlsv). Start Time and End Time : The time boxes can be selected checking \u201cTrim Time\u201d. If you choose this option all the seismograms will be cut in accordance with the selected time window. Use the shortcuts \"Q\" and \"E\" to set over the plot automatically the trim stat time and endtime. Stations Info : will deploy a table with the fundamental information of the seismograms. Phase box : This combo box allow the selection of specific phases for picking it in the seismograms. Waves box : You can choose Body, surface, coda or noise. With this selected you can highlight a time window of the seismogram for further analysis. For example Mw Magnitude that requires a time window of body wave on many seismograms. Net, Station and Channel : You can fill this boxes (also using wildcards such as * or BH?) to select specific files from your files folder (check \u201cselect files\u201d). Stations Map : will show you the location of the stations that corresponds to the seismograms of your folder. The seismograms metadata must match with the metadata information. Rotate : This option will rotate all your station - 3 components (channels must be named N,E,Z) to the Great Arc Circle taking the reference the data of Event info tab. Check \"Use this Ang\" to rotate the components a specific angle. Cross : This button will compute the cross-correlation (cc) or the autocorrelation of all processed seismograms with respect the reference \u201cRef\u201d, the number of the seismogram from top to bottom. Process and Plot : This action will read the seismograms from the database of paths to your seismograms, created from your folder tree (database already built using Read Files) and will carry out the processing from the established \u201cMACRO\u201d. Further details in MACRO section \"Macros\". Additional options from the toolbar are: File File: New location will clean the picks that are saved automatically for be ready to compute new picking/location. File: Write Files will write in the folder you select the processed seismograms. File: Open Settings will open a window with the specific parameters of the subprocess that you can carry out in this module (sta/lta, wavelet detection, spectrogram, entropy\u2026). Actions Actions: Picks Open will open the file with the information of your picks. You can also open the file from here. Shortcut \"Ctr + u\". Picks are saved in isp/earthquakeAnalysis/location_output/obs/output.txt Actions: Picks Remove will clean the pick file. Station_name Instrument Component P_phase_onset P_phase_descriptor First_Motion Date Hour_min Seconds GAU Err Coda_duration Amplitude Period PMG ? BHZ ? P ? 20221018 1150 24.693 GAU 0.00E+00 0.0 -3024.00 0.0 Actions: Macro will deploy a window with all of the processing options. All of the processing options will be applied once you press the button Processing and Plot. Shortcut \"Ctr + l\" Action: Detect event will associate the automatic picks carried out by the wavelet picker ant will declare an event. The events will be shown in the seismograms window. Actions: Run Picker will carry out the automatic detection/classification of P- and S- waves from the previously loaded \u201cNeural Network\u201d. You must have three components per stations (named N, E,*Z). BE CAREFUL this operation is computationally demanding. Actions: Run Autoloc will detect events using a associated picker based on the Continuous Wavelet Transform (go to File Open Settings to set Num Cycles, Fmin and Fmax) moreover you need to set Detection trigger options Threshold to trigger a pick, number of picks that coincide in different seismograms to declare an event and time window over the clustering of pick is going to be used (For example 40 s means that all seismograms around same time window of 40 s is going to be associated to the same event. Once an event is declared it is chopped the seismograms run the autopick (P and S wave) using the Neural Network and run and automatic location. If you want to use a local model to locate be sure that you have the travel times calculated. All locations will be storage in ./isp/earthquakeAnalysis/location_output/all_locations. Action: Clean Selection will remove an specific seismogram time window selection, such as Body wave, see the combo box selected and will delete from the selections. Action: Remove all selections Action: Clean Events Detected Actions: Magnitude Calculator will open a window in which you can compute different magnitudes. For open this you must have estimated an event and have selected the time-windows in the seismograms that you want the magnitudes be calculated. Action: Open Earth Model Viewer will open a tool to visualize 3D velocity models. For visualize an Earth Model you need the binary files ( buf and hdr) created in the tab Event location. Action: Data availability will plot the data availability (backlines) for each station/component of the database loaded from your folder tree. Action: Search in Catalog (see first figure) is a widget designed to plot your catalog and select an event to search in your project. The catalog must be a csv file with this header: Date;Time;Latitude;Longitude;Depth;Magnitude;mag_type 01/01/2007;02:03:03;34.9608;-4.0459;12.0;2.6;Mw You can find an example in isp/examples/catalog/catalog_resume. To facilitate the selection of events, the user can press \"t\" over the epicenter in the map to hilight it in the table. Finally, Pressing button \"Select Event\" the information is sent to the trim starttime and endtime and to the Event Box. Ready to reload your project to make the search of the event! Compute Compute: STA/LTA from all processed seismograms and will plot the result together. STA/LTA takes the parameters from Parameters Settings. Compute: CWT (CF) from all processed seismograms and will plot the result together. CWT takes the parameters from Parameters Settings. Compute: Envelope from all processed seismograms and will plot the result together. Compute: Spectral Entropy from all processed seismograms and will plot the result together. Spectral entropy is estimated in small time windows see Parameters Settings. Compute: All Seismograms : Plot together all seismograms. Compute: Stack run (linear, nth-root or PWS) stack of all processed seismograms. Set your choice in File/Open Settings. Go Will ship you to the rest of ISP modules (RFs, Array analysis\u2026.). We are working in connecting the seismograms processed in Earquake analysis with the other modules. Align Traces Align Traces: From Phase Pick will align the trace with respect the picks of the selected phase in the phase box. For example, this can be very useful to align the first arriaval, let's say P-wave of an event for all traces. Align Traces: From Starttime will set the same starttime to all traces. This is useful if you want to compare seismograms from different days. Align Traces: Using MCCC Multi Channel Cross Correlation technicque to find the best way to align all traces. This technique is very efficient when the user expect high coherence between waveforms. For example teleseismic events, or events detected in a coherent array. Import Import: Picks from file It will plot the picks from selected file in the corresponding waveforms. The picks from the file that the user select must be in the ISP/NLL format as it is shown above Actions:Picks. Multimedia Material (Pick Event) The following video shows a basic analysis of an earthquake Polarisation Analysis The Polarization Analysis is designed to analyze the three seismograms components from a station. You can freely rotate using the rotation RT or the LQT your NEZ components an angle (Rot Angle) with an Incidence angle (Inc Angle). The Particle motion of the processed seismogram is view clicking in \u201cPlot Polarization\u201d. This option will plot all the time window in a 3D view and in three 2D plot views. If you want to make a sliding window analysis of the polarization press \u201cPolarization Analysis\u201d. This will carry out a polarization analysis on windows length and frequency bandwidth specified by the user over the full analyzed seismogram. For a full particle motion analysis, press \u201cPlot Polarization\u201d. This will open another window with a 3D particle motion on the left and the three characteristic views on the right. Event Location and Focal Mechanism (FP) In the Event Location Frame the user can configure the velocity grid 1D/3D model, locate earthquakes and compute Focal Mechanisms. Grid Reference : First it is needed to set a Velocity grid framework (Grid reference and transformation type are mandatory). For now is only available Transformation Simple and Global. Grid Size : Next, the Grid dimensions (Grid Size). Case 1D the dimension in the x coordinate always must be 2 and the grid reference is refered to the corner SW. Case 3D the grid reference is the center of the Grid. Choose the grid type and the wave and then generate the velocity model binary files by clicking \u201cGenerate Velocity Grid\u201d. Please follow the scheme of the next figure to set correctly your 3D grid frame. For example, First the user would place the center of the grid in case you want the center of a 1D grid: Grid reference 34.0 Latitude, -14.0 Longitude and -1 (1 km in topography). Grid Size x = 2 (always) dx = 1, y = 2000 dy =1 and z = 200 dz = 1. Tha means an aproximate square region of radio 2000x2000x150 km with the reference at (34,-14,-1). Second, for the 3D case, the user must set the Grid reference also 37.0 Latitude, -9.0 Longitude and -1 (1 km in topography), but the Grid Size is refered to the distance from the grid reference. So, for example, Grid Size x = 881 dx = 1, y = 661 dy =1 and z = 61 dz = 1. This means a grid centered at 37.0,-9.0,-1.0 with a extension of diameter (881,661,60), see image below. Once the binary files are generated you can check the results in the folder: ISP/earthquakeAnalysis/location_output/model Where and how place the velocity 1D model?: isp/earthquakeAnalysis/location_output/local_models 1D models (see example): For the P-wave the file must named modelP and for the S-wave \"modelS\" LAYER 0.0 6.1 0.0 3.49 0.0 2.7 0.0 LAYER 11.0 6.4 0.0 3.66 0.0 2.7 0.0 LAYER 24.0 6.9 0.0 3.94 0.0 2.7 0.0 LAYER 31.0 8.0 0.0 4.57 0.0 2.7 0.0 LAYER .... ... ... .... ... ... ... Where and how place the velocity 3D model?: isp/earthquakeAnalysis/location_output/model3D Every depth layer must be placed in files called, for example For the P wave --> layer.P.mod5.mod For the S wave --> layer.S.mod5.mod Which means that inside this file there is the grid for the layer at depth 5km. The layer must be a matrix with the values in the rows from top to bottom S to N and from left to right E to W. That's mean following the next example that the file corresponding to a depth layer 5km \"layer.P.mod5.mod\" could be like this: 4.5759 4.5735 4.5707 4.5677 4.5760 4.5755 4.5766 4.5670 ...... ...... ...... ...... 4.6800 4.650 4.67300 4.5678 This matrix means that, for example corresponds to geographic points (separated in cells of, dx dy of 0.5 x 0.5 degrees: Warning grid cells must be [dx = dy = dz] for a correct interpretation. (-10.0,34) (-9.5,34) (-9.0,34) (-8.5,34) (-10.0,34.5) (-9.5,34.5) (-9.0,34.5) (-8.5,34.5) ........ ......... ......... ......... (-10.0,40.0) (-9.5,40.0) (-9.0,40.0) (-8.5,40.0) The most important step is to generate the travel-times for all the stations inside the maximum distance the user determine. Please be sure that you have load previously the metadata (this is necessary to associate your picks with your station coordinates). The generated travel-times will save in ISP/earthquakeAnalysis/location_output/time, for example with the following name l\"ayer.P.EBAD.time.buf\" Once you have complete the above steps you can locate the earthquake and the focal mechanism. The above operation are just necessary to be implemented the first time you use a specific Earth model. **For global is not necessary generate the velocity grid and travel times. To visualize the detailed Probability Density Function, press \u201cPlot PDF\u201d, once you have already carried out the location. Moreover, if you have picked the seismic phases and have been designated the polarity in \u201cEvent frame\u201d , you will be able to obtain the Focal Mechanism (it uses the subprogram FocMec) Earth model Viewer The Earth Model Viewer is intended to help to visualize 3D Earth velocity models as in the figure below. Just select the binary file *.buf (can be generated from the model as described in previous section). Next, select the depth of the layer, the cross sections in longitude and latitude and the press plot. Magnitudes Estimation With the Magnitude Estimation you can calculate): Local Magnitude ( ML ) or Body-wave ( mb ), Surface-wave ( Ms ), Moment Magnitude ( Mw ) and Coda Magnitude ( Mc ). To estimate the magnitudes you have to select a time window of body, surface or coda on the seismograms. Units must be on velocity, so you must remove the response of the instrument to velocity, previously to open the Magnitudes window. For Local magnitude you have to remove the response of Wood-Anderson instrument. The hypocenter must be already calculated. The program will read the *.hyp file before open Magnitudes window. If you place 0.00 on all parameters of local or coda magnitudes, the program will calculate these magnitude with default parameters as follows: Coda Magnitude: Values for California a = 2.0; b = 0.0035; c= -0.87 Mc_value = a np.log10(t_coda)+b dist+c Local Magnitude: a = 1.11; b =0.00189; c= -2.09 ML_value = np.log10(max_amplitude)+a np.log10(dist)+b dist+c Briefly, Once you have open the Magnitude Window, select the magnitudes you want to compute and run the computation. In the upper panel it is shown the spectrum of the body waves and the fit to calculate the moment magnitude. In the bottom panel is shown the histograms of all magnitudes (the result of the magnitudes for all seismograms for all kind of magnitudes) and on the left an additional plot used to visualize the dispersion of the results.","title":"Earthquake Location"},{"location":"el/#earthquake-location","text":"The module Earthquake analysis allows you to analyse waveforms, polarization analysis of seismograms 3-components, calculate different magnitudes and finally locate an event and estimate the focal mechanism (First Polarity). We will walk through all of the functionality following this scheme:","title":"Earthquake Location"},{"location":"el/#pick-event","text":"From top to bottom in the left side of the window you will see: Event Info : This small box let enter information about an event, in this way you can plot the theoretical arrivals (ak-135F) with respect your seismograms. Plot arrivals requires that you have correctly loaded your metadata. Metadata File : By clicking in this button you will place the path to you metadata file. The metadata file must contain the information of all of the stations seismograms you want to analyse (metadata must be a xml or dlsv). Start Time and End Time : The time boxes can be selected checking \u201cTrim Time\u201d. If you choose this option all the seismograms will be cut in accordance with the selected time window. Use the shortcuts \"Q\" and \"E\" to set over the plot automatically the trim stat time and endtime. Stations Info : will deploy a table with the fundamental information of the seismograms. Phase box : This combo box allow the selection of specific phases for picking it in the seismograms. Waves box : You can choose Body, surface, coda or noise. With this selected you can highlight a time window of the seismogram for further analysis. For example Mw Magnitude that requires a time window of body wave on many seismograms. Net, Station and Channel : You can fill this boxes (also using wildcards such as * or BH?) to select specific files from your files folder (check \u201cselect files\u201d). Stations Map : will show you the location of the stations that corresponds to the seismograms of your folder. The seismograms metadata must match with the metadata information. Rotate : This option will rotate all your station - 3 components (channels must be named N,E,Z) to the Great Arc Circle taking the reference the data of Event info tab. Check \"Use this Ang\" to rotate the components a specific angle. Cross : This button will compute the cross-correlation (cc) or the autocorrelation of all processed seismograms with respect the reference \u201cRef\u201d, the number of the seismogram from top to bottom. Process and Plot : This action will read the seismograms from the database of paths to your seismograms, created from your folder tree (database already built using Read Files) and will carry out the processing from the established \u201cMACRO\u201d. Further details in MACRO section \"Macros\". Additional options from the toolbar are: File File: New location will clean the picks that are saved automatically for be ready to compute new picking/location. File: Write Files will write in the folder you select the processed seismograms. File: Open Settings will open a window with the specific parameters of the subprocess that you can carry out in this module (sta/lta, wavelet detection, spectrogram, entropy\u2026). Actions Actions: Picks Open will open the file with the information of your picks. You can also open the file from here. Shortcut \"Ctr + u\". Picks are saved in isp/earthquakeAnalysis/location_output/obs/output.txt Actions: Picks Remove will clean the pick file. Station_name Instrument Component P_phase_onset P_phase_descriptor First_Motion Date Hour_min Seconds GAU Err Coda_duration Amplitude Period PMG ? BHZ ? P ? 20221018 1150 24.693 GAU 0.00E+00 0.0 -3024.00 0.0 Actions: Macro will deploy a window with all of the processing options. All of the processing options will be applied once you press the button Processing and Plot. Shortcut \"Ctr + l\" Action: Detect event will associate the automatic picks carried out by the wavelet picker ant will declare an event. The events will be shown in the seismograms window. Actions: Run Picker will carry out the automatic detection/classification of P- and S- waves from the previously loaded \u201cNeural Network\u201d. You must have three components per stations (named N, E,*Z). BE CAREFUL this operation is computationally demanding. Actions: Run Autoloc will detect events using a associated picker based on the Continuous Wavelet Transform (go to File Open Settings to set Num Cycles, Fmin and Fmax) moreover you need to set Detection trigger options Threshold to trigger a pick, number of picks that coincide in different seismograms to declare an event and time window over the clustering of pick is going to be used (For example 40 s means that all seismograms around same time window of 40 s is going to be associated to the same event. Once an event is declared it is chopped the seismograms run the autopick (P and S wave) using the Neural Network and run and automatic location. If you want to use a local model to locate be sure that you have the travel times calculated. All locations will be storage in ./isp/earthquakeAnalysis/location_output/all_locations. Action: Clean Selection will remove an specific seismogram time window selection, such as Body wave, see the combo box selected and will delete from the selections. Action: Remove all selections Action: Clean Events Detected Actions: Magnitude Calculator will open a window in which you can compute different magnitudes. For open this you must have estimated an event and have selected the time-windows in the seismograms that you want the magnitudes be calculated. Action: Open Earth Model Viewer will open a tool to visualize 3D velocity models. For visualize an Earth Model you need the binary files ( buf and hdr) created in the tab Event location. Action: Data availability will plot the data availability (backlines) for each station/component of the database loaded from your folder tree. Action: Search in Catalog (see first figure) is a widget designed to plot your catalog and select an event to search in your project. The catalog must be a csv file with this header: Date;Time;Latitude;Longitude;Depth;Magnitude;mag_type 01/01/2007;02:03:03;34.9608;-4.0459;12.0;2.6;Mw You can find an example in isp/examples/catalog/catalog_resume. To facilitate the selection of events, the user can press \"t\" over the epicenter in the map to hilight it in the table. Finally, Pressing button \"Select Event\" the information is sent to the trim starttime and endtime and to the Event Box. Ready to reload your project to make the search of the event! Compute Compute: STA/LTA from all processed seismograms and will plot the result together. STA/LTA takes the parameters from Parameters Settings. Compute: CWT (CF) from all processed seismograms and will plot the result together. CWT takes the parameters from Parameters Settings. Compute: Envelope from all processed seismograms and will plot the result together. Compute: Spectral Entropy from all processed seismograms and will plot the result together. Spectral entropy is estimated in small time windows see Parameters Settings. Compute: All Seismograms : Plot together all seismograms. Compute: Stack run (linear, nth-root or PWS) stack of all processed seismograms. Set your choice in File/Open Settings. Go Will ship you to the rest of ISP modules (RFs, Array analysis\u2026.). We are working in connecting the seismograms processed in Earquake analysis with the other modules. Align Traces Align Traces: From Phase Pick will align the trace with respect the picks of the selected phase in the phase box. For example, this can be very useful to align the first arriaval, let's say P-wave of an event for all traces. Align Traces: From Starttime will set the same starttime to all traces. This is useful if you want to compare seismograms from different days. Align Traces: Using MCCC Multi Channel Cross Correlation technicque to find the best way to align all traces. This technique is very efficient when the user expect high coherence between waveforms. For example teleseismic events, or events detected in a coherent array. Import Import: Picks from file It will plot the picks from selected file in the corresponding waveforms. The picks from the file that the user select must be in the ISP/NLL format as it is shown above Actions:Picks.","title":"Pick Event"},{"location":"el/#multimedia-material-pick-event","text":"The following video shows a basic analysis of an earthquake","title":"Multimedia Material (Pick Event)"},{"location":"el/#polarisation-analysis","text":"The Polarization Analysis is designed to analyze the three seismograms components from a station. You can freely rotate using the rotation RT or the LQT your NEZ components an angle (Rot Angle) with an Incidence angle (Inc Angle). The Particle motion of the processed seismogram is view clicking in \u201cPlot Polarization\u201d. This option will plot all the time window in a 3D view and in three 2D plot views. If you want to make a sliding window analysis of the polarization press \u201cPolarization Analysis\u201d. This will carry out a polarization analysis on windows length and frequency bandwidth specified by the user over the full analyzed seismogram. For a full particle motion analysis, press \u201cPlot Polarization\u201d. This will open another window with a 3D particle motion on the left and the three characteristic views on the right.","title":"Polarisation Analysis"},{"location":"el/#event-location-and-focal-mechanism-fp","text":"In the Event Location Frame the user can configure the velocity grid 1D/3D model, locate earthquakes and compute Focal Mechanisms. Grid Reference : First it is needed to set a Velocity grid framework (Grid reference and transformation type are mandatory). For now is only available Transformation Simple and Global. Grid Size : Next, the Grid dimensions (Grid Size). Case 1D the dimension in the x coordinate always must be 2 and the grid reference is refered to the corner SW. Case 3D the grid reference is the center of the Grid. Choose the grid type and the wave and then generate the velocity model binary files by clicking \u201cGenerate Velocity Grid\u201d. Please follow the scheme of the next figure to set correctly your 3D grid frame. For example, First the user would place the center of the grid in case you want the center of a 1D grid: Grid reference 34.0 Latitude, -14.0 Longitude and -1 (1 km in topography). Grid Size x = 2 (always) dx = 1, y = 2000 dy =1 and z = 200 dz = 1. Tha means an aproximate square region of radio 2000x2000x150 km with the reference at (34,-14,-1). Second, for the 3D case, the user must set the Grid reference also 37.0 Latitude, -9.0 Longitude and -1 (1 km in topography), but the Grid Size is refered to the distance from the grid reference. So, for example, Grid Size x = 881 dx = 1, y = 661 dy =1 and z = 61 dz = 1. This means a grid centered at 37.0,-9.0,-1.0 with a extension of diameter (881,661,60), see image below. Once the binary files are generated you can check the results in the folder: ISP/earthquakeAnalysis/location_output/model Where and how place the velocity 1D model?: isp/earthquakeAnalysis/location_output/local_models 1D models (see example): For the P-wave the file must named modelP and for the S-wave \"modelS\" LAYER 0.0 6.1 0.0 3.49 0.0 2.7 0.0 LAYER 11.0 6.4 0.0 3.66 0.0 2.7 0.0 LAYER 24.0 6.9 0.0 3.94 0.0 2.7 0.0 LAYER 31.0 8.0 0.0 4.57 0.0 2.7 0.0 LAYER .... ... ... .... ... ... ... Where and how place the velocity 3D model?: isp/earthquakeAnalysis/location_output/model3D Every depth layer must be placed in files called, for example For the P wave --> layer.P.mod5.mod For the S wave --> layer.S.mod5.mod Which means that inside this file there is the grid for the layer at depth 5km. The layer must be a matrix with the values in the rows from top to bottom S to N and from left to right E to W. That's mean following the next example that the file corresponding to a depth layer 5km \"layer.P.mod5.mod\" could be like this: 4.5759 4.5735 4.5707 4.5677 4.5760 4.5755 4.5766 4.5670 ...... ...... ...... ...... 4.6800 4.650 4.67300 4.5678 This matrix means that, for example corresponds to geographic points (separated in cells of, dx dy of 0.5 x 0.5 degrees: Warning grid cells must be [dx = dy = dz] for a correct interpretation. (-10.0,34) (-9.5,34) (-9.0,34) (-8.5,34) (-10.0,34.5) (-9.5,34.5) (-9.0,34.5) (-8.5,34.5) ........ ......... ......... ......... (-10.0,40.0) (-9.5,40.0) (-9.0,40.0) (-8.5,40.0) The most important step is to generate the travel-times for all the stations inside the maximum distance the user determine. Please be sure that you have load previously the metadata (this is necessary to associate your picks with your station coordinates). The generated travel-times will save in ISP/earthquakeAnalysis/location_output/time, for example with the following name l\"ayer.P.EBAD.time.buf\" Once you have complete the above steps you can locate the earthquake and the focal mechanism. The above operation are just necessary to be implemented the first time you use a specific Earth model. **For global is not necessary generate the velocity grid and travel times. To visualize the detailed Probability Density Function, press \u201cPlot PDF\u201d, once you have already carried out the location. Moreover, if you have picked the seismic phases and have been designated the polarity in \u201cEvent frame\u201d , you will be able to obtain the Focal Mechanism (it uses the subprogram FocMec)","title":"Event Location and Focal Mechanism (FP)"},{"location":"el/#earth-model-viewer","text":"The Earth Model Viewer is intended to help to visualize 3D Earth velocity models as in the figure below. Just select the binary file *.buf (can be generated from the model as described in previous section). Next, select the depth of the layer, the cross sections in longitude and latitude and the press plot.","title":"Earth model Viewer"},{"location":"el/#magnitudes-estimation","text":"With the Magnitude Estimation you can calculate): Local Magnitude ( ML ) or Body-wave ( mb ), Surface-wave ( Ms ), Moment Magnitude ( Mw ) and Coda Magnitude ( Mc ). To estimate the magnitudes you have to select a time window of body, surface or coda on the seismograms. Units must be on velocity, so you must remove the response of the instrument to velocity, previously to open the Magnitudes window. For Local magnitude you have to remove the response of Wood-Anderson instrument. The hypocenter must be already calculated. The program will read the *.hyp file before open Magnitudes window. If you place 0.00 on all parameters of local or coda magnitudes, the program will calculate these magnitude with default parameters as follows: Coda Magnitude: Values for California a = 2.0; b = 0.0035; c= -0.87 Mc_value = a np.log10(t_coda)+b dist+c Local Magnitude: a = 1.11; b =0.00189; c= -2.09 ML_value = np.log10(max_amplitude)+a np.log10(dist)+b dist+c Briefly, Once you have open the Magnitude Window, select the magnitudes you want to compute and run the computation. In the upper panel it is shown the spectrum of the body waves and the fit to calculate the moment magnitude. In the bottom panel is shown the histograms of all magnitudes (the result of the magnitudes for all seismograms for all kind of magnitudes) and on the left an additional plot used to visualize the dispersion of the results.","title":"Magnitudes Estimation"},{"location":"install/","text":"Installation First of all, clone the repository from ISP master branch . Just open your terminal and navigate whenever you want to place ISP and type in the terminal git clone https://github.com/ProjectISP/ISP.git Optionally, go to the folder ./ISP and if you want to change to the ongoing version ISP 2.0 type in your terminal git checkout ISP_2.0_development To be updated, from ./ISP type in your terminal, git pull The installation file will install the requirements and will compile the source packages. At the end of the installation the user will be asked for an alias \"isp\". Following the directions Installation for end users , it is needed to have previously installed anaconda . Installation for end users (Mac and Linux) To run the installation go to ./ISP/install and type: chmod u+x ISP_installer.sh ./ISP_installer.sh Just in case the alias isp do not open the software, go to ./ISP and type: conda activate isp or source activate isp python start_isp.py Warning: We have found that in some Mac computers is difficult to compile the third package NLL , so for this reason inside the folder ./ISP/isp/mac_bin/bin, you will find NLL fully compiled. Then, you can move this files from ./ISP/isp/mac_bin/bin to ./ISP/isp/NLL7/bin that is the folder where ISP will look for running this program. Installation for developers (Mac and Linux) First, Install python 3 and some Cartopy dependencies sudo apt install python3-pip python3.8-venv sudo apt install libproj-dev proj-data proj-bin libgeos-dev Then, we suggest installing the requirements: python3 -m venv isp source isp/bin/activate python3 -m pip install -r requirements.txt pip install --upgrade setuptools Next, from the folder ./ISP, compile the source packages: python3 setup.py build_ext --inplace Installation for Windows users In the following text, we briefly explain how to install ISP in windows via WSL . 1. Install WSL Windows Subsystem for Linux version 2 and Ubuntu 20.04 2. Install Windows X Server 3. Initialize Windows X Server Create a direct access that execute the following instructions \"C:\\Program Files\\VcXsrv.exe\" :0 -multiwindow -clipboard -wgl -ac However, it could be more easy to you just run: Windows Key + R and then in the widget type \"C:\\Program Files\\VcXsrv.exe\" :0 -multiwindow -clipboard -wgl -ac 4. Directions to follow inside WSL export DISPLAY_NUMBER=\"0.0\" export DISPLAY=$(grep -m 1 nameserver /etc/resolv.conf | awk '{print $2}'):$DISPLAY_NUMBER 5. Install Anaconda Add to path Anconda to the file .bashrc \"export PATH=~/anaconda3/bin:$PATH\" Then everything is ready to install ISP as in Linux System 6. Install normally ISP: To run the installation go to ./isp/installation and type ./ISP_installer.sh Just in case the alias isp do not open the software, go to ./ISP and type: conda activate isp or source activate isp python start_isp.py Uninstall ISP First remove the folder ISP, then type in your terminal: conda remove --name isp --all List of Requirements sqlalchemy owslib Cython deprecated matplotlib numpy scipy >= 1.4.1 obspy pandas PyQt5 PyQtWebEngine mtspec nitime Cartopy pillow PyWavelets dill nvector numba Tensorflow>=2.3.0 Good luck with the process","title":"Installation"},{"location":"install/#installation","text":"First of all, clone the repository from ISP master branch . Just open your terminal and navigate whenever you want to place ISP and type in the terminal git clone https://github.com/ProjectISP/ISP.git Optionally, go to the folder ./ISP and if you want to change to the ongoing version ISP 2.0 type in your terminal git checkout ISP_2.0_development To be updated, from ./ISP type in your terminal, git pull The installation file will install the requirements and will compile the source packages. At the end of the installation the user will be asked for an alias \"isp\". Following the directions Installation for end users , it is needed to have previously installed anaconda .","title":"Installation"},{"location":"install/#installation-for-end-users-mac-and-linux","text":"To run the installation go to ./ISP/install and type: chmod u+x ISP_installer.sh ./ISP_installer.sh Just in case the alias isp do not open the software, go to ./ISP and type: conda activate isp or source activate isp python start_isp.py Warning: We have found that in some Mac computers is difficult to compile the third package NLL , so for this reason inside the folder ./ISP/isp/mac_bin/bin, you will find NLL fully compiled. Then, you can move this files from ./ISP/isp/mac_bin/bin to ./ISP/isp/NLL7/bin that is the folder where ISP will look for running this program.","title":"Installation for end users (Mac and Linux)"},{"location":"install/#installation-for-developers-mac-and-linux","text":"First, Install python 3 and some Cartopy dependencies sudo apt install python3-pip python3.8-venv sudo apt install libproj-dev proj-data proj-bin libgeos-dev Then, we suggest installing the requirements: python3 -m venv isp source isp/bin/activate python3 -m pip install -r requirements.txt pip install --upgrade setuptools Next, from the folder ./ISP, compile the source packages: python3 setup.py build_ext --inplace","title":"Installation for developers (Mac and Linux)"},{"location":"install/#installation-for-windows-users","text":"In the following text, we briefly explain how to install ISP in windows via WSL . 1. Install WSL Windows Subsystem for Linux version 2 and Ubuntu 20.04 2. Install Windows X Server 3. Initialize Windows X Server Create a direct access that execute the following instructions \"C:\\Program Files\\VcXsrv.exe\" :0 -multiwindow -clipboard -wgl -ac However, it could be more easy to you just run: Windows Key + R and then in the widget type \"C:\\Program Files\\VcXsrv.exe\" :0 -multiwindow -clipboard -wgl -ac 4. Directions to follow inside WSL export DISPLAY_NUMBER=\"0.0\" export DISPLAY=$(grep -m 1 nameserver /etc/resolv.conf | awk '{print $2}'):$DISPLAY_NUMBER 5. Install Anaconda Add to path Anconda to the file .bashrc \"export PATH=~/anaconda3/bin:$PATH\" Then everything is ready to install ISP as in Linux System 6. Install normally ISP: To run the installation go to ./isp/installation and type ./ISP_installer.sh Just in case the alias isp do not open the software, go to ./ISP and type: conda activate isp or source activate isp python start_isp.py","title":"Installation for Windows users"},{"location":"install/#uninstall-isp","text":"First remove the folder ISP, then type in your terminal: conda remove --name isp --all","title":"Uninstall ISP"},{"location":"install/#list-of-requirements","text":"sqlalchemy owslib Cython deprecated matplotlib numpy scipy >= 1.4.1 obspy pandas PyQt5 PyQtWebEngine mtspec nitime Cartopy pillow PyWavelets dill nvector numba Tensorflow>=2.3.0 Good luck with the process","title":"List of Requirements"},{"location":"license/","text":"ISP is licensed under the GNU Lesser General Public License (LGPL) v3.0.","title":"License"},{"location":"mti/","text":"Moment Tensor Inversion Create Earth velocity model To start you need to load a Earth model. Go to Build \u00e0 Earth Model and open the Earth Model Form, the fill it and save it. Bayesian Inversion The user needs to fill the following fields to go on with the inversion: Metadata >> Path to the file where you have the metadata. This is necessary to extract the stations coordinates and the instrument information to do the deconvolution (this is not totally necessary, the user can manage the seismograms already in velocity units). Files >> path to the seismogram files Earth Model >>> Path to the Earth model file (see previous section for see how to make this file with ISP, the user can also do it manually). Time Window >>> Set the window in which the seismograms will be used (StartTime, EndTime and CHECK trim). Macro >> You can set a Macro to make basic processing over the seismograms Now Follow this steps, Process and plot Seismograms Open Stations info. This action will allow you select which station/component will be used in the inversion Plot stations Map (First, fill Latitude Longitude and depth) This is optional - Fill the info: - Hipocenter location and Uncertainity (m) - Origin Time and Uncertainity - Magnitude - Frequency range for the inversion (see Fig 2 for example) - Distance filter. Avoid statations out of the distance filter (Distance from epicenter to station) - Option Deviatoric, Circle, Shape, Covariance (please because it uses previous noise window for inversion, select long enough prevent window (i.e., 10 min)) and use precalculated Green functions Pre-calculated Green Functions is useful because, once you have run an inversion then you may filter the inversion selecting different components or distances Multimedia Material (MTI)","title":"Seismic Moment Tensor Inversion"},{"location":"mti/#moment-tensor-inversion","text":"","title":"Moment Tensor Inversion"},{"location":"mti/#create-earth-velocity-model","text":"To start you need to load a Earth model. Go to Build \u00e0 Earth Model and open the Earth Model Form, the fill it and save it.","title":"Create Earth velocity model"},{"location":"mti/#bayesian-inversion","text":"The user needs to fill the following fields to go on with the inversion: Metadata >> Path to the file where you have the metadata. This is necessary to extract the stations coordinates and the instrument information to do the deconvolution (this is not totally necessary, the user can manage the seismograms already in velocity units). Files >> path to the seismogram files Earth Model >>> Path to the Earth model file (see previous section for see how to make this file with ISP, the user can also do it manually). Time Window >>> Set the window in which the seismograms will be used (StartTime, EndTime and CHECK trim). Macro >> You can set a Macro to make basic processing over the seismograms Now Follow this steps, Process and plot Seismograms Open Stations info. This action will allow you select which station/component will be used in the inversion Plot stations Map (First, fill Latitude Longitude and depth) This is optional - Fill the info: - Hipocenter location and Uncertainity (m) - Origin Time and Uncertainity - Magnitude - Frequency range for the inversion (see Fig 2 for example) - Distance filter. Avoid statations out of the distance filter (Distance from epicenter to station) - Option Deviatoric, Circle, Shape, Covariance (please because it uses previous noise window for inversion, select long enough prevent window (i.e., 10 min)) and use precalculated Green functions Pre-calculated Green Functions is useful because, once you have run an inversion then you may filter the inversion selecting different components or distances","title":"Bayesian Inversion"},{"location":"mti/#multimedia-material-mti","text":"","title":"Multimedia Material (MTI)"},{"location":"nrt/","text":"Near Real Time Adquisition The tool Near Real Time Adquisition is intended to retrieve data from a server. Structure Metadata Set the metadata file **Net/Station/Channel Place separated by \",\" the name of nets stations and channels you want to retrieve. It is convinient to use wildcards such as \"BH?\" or \"*\" Server Address Set the name of the server address you want to point to. Max Num Traces Number of traces you want to plot Time Window Duration of the time window in minutes you want to plot the traces Save Data This action will allow saving the mseed files that are collected in the destionation folder. The mseed will have a maximum of 24 h being the cut at \"00:00:00.0000\". Plot Map This action will plot the map of the metadata stations in red plus the statios you are collecting data in green.","title":"Near Real Time Adquisition"},{"location":"nrt/#near-real-time-adquisition","text":"The tool Near Real Time Adquisition is intended to retrieve data from a server.","title":"Near Real Time Adquisition"},{"location":"nrt/#structure","text":"Metadata Set the metadata file **Net/Station/Channel Place separated by \",\" the name of nets stations and channels you want to retrieve. It is convinient to use wildcards such as \"BH?\" or \"*\" Server Address Set the name of the server address you want to point to. Max Num Traces Number of traces you want to plot Time Window Duration of the time window in minutes you want to plot the traces Save Data This action will allow saving the mseed files that are collected in the destionation folder. The mseed will have a maximum of 24 h being the cut at \"00:00:00.0000\". Plot Map This action will plot the map of the metadata stations in red plus the statios you are collecting data in green.","title":"Structure"},{"location":"ppsds/","text":"Probability Power Spectral Dentitiy (PPSD) One the most common tools to evaluate the station performance of seismic data acquisition (Mcnamara and Buland, 2004) is to estimate the Probability Density Functions (PDFs). Once the PDFs are calculated, the seismic noise levels can be compared with the standard low and high noise levels, NLNM and NHNM (Peterson, 1993), or can be calculated cumulative spectrograms to observe seasonal variations. The ISP submodule \u201cPPSD\u201d allows to build a database to storage the PDFs of the stations/components desired from PPSDs, with an specific frame work for this task. Moreover the original databased can be upgraded with more data. Once the PDFs are computed, they can be visualized into another framework that offers multiple visualization options. The Fig. 1 shows the visualization framework with the PDFs of three components from three different station and the Fig 2 & 3 the diurnal and seasonal variation, respectively. The PDFs are also compared with earthquake power desnsity spectrums (Clinton and Heaton, 2002).","title":"PPSDs"},{"location":"ppsds/#probability-power-spectral-dentitiy-ppsd","text":"One the most common tools to evaluate the station performance of seismic data acquisition (Mcnamara and Buland, 2004) is to estimate the Probability Density Functions (PDFs). Once the PDFs are calculated, the seismic noise levels can be compared with the standard low and high noise levels, NLNM and NHNM (Peterson, 1993), or can be calculated cumulative spectrograms to observe seasonal variations. The ISP submodule \u201cPPSD\u201d allows to build a database to storage the PDFs of the stations/components desired from PPSDs, with an specific frame work for this task. Moreover the original databased can be upgraded with more data. Once the PDFs are computed, they can be visualized into another framework that offers multiple visualization options. The Fig. 1 shows the visualization framework with the PDFs of three components from three different station and the Fig 2 & 3 the diurnal and seasonal variation, respectively. The PDFs are also compared with earthquake power desnsity spectrums (Clinton and Heaton, 2002).","title":"Probability Power Spectral Dentitiy (PPSD)"},{"location":"rd/","text":"Retrieve Data Retrieve Data framework is an interface to facilitate download specific events to time-series or select a period and download data from different stations. Step1: Select a FDSN web service and click load. This action will load the inventory. Step2: You can plot the inventory stations and can be add to the posterior request with double-click on the map or manually added. Also you can remove it with right button double-click. From this point you can follow different actions, Download Time Series: Just set Starttime and Endtime and click on the button. This will download the mini seeds of the stations/channels requested for that period. Download Metadata: This action will download the stations.xml of the stations/channels requested. Step3: If we want to download earthquake seismograms from a period of time for specific stations/channels. Step1: Download catalog (see figure) and select the rows of the earthquake you are interested. Next, fill the gaps for net, stations and channels. You can plot the stations and use double-click action to select the stations. Step 2: Fill the cut time-window (s) before and after the first arrival and click on Download event data. The available FDSN web services are: BGR http://eida.bgr.de EMSC http://www.seismicportal.eu ETH http://eida.ethz.ch GEONET http://service.geonet.org.nz GFZ http://geofon.gfz-potsdam.de ICGC http://ws.icgc.cat INGV http://webservices.ingv.it IPGP http://ws.ipgp.fr IRIS http://service.iris.edu ISC http://isc-mirror.iris.washington.edu KNMI http://rdsa.knmi.nl KOERI http://eida.koeri.boun.edu.tr LMU http://erde.geophysik.uni-muenchen.de NCEDC http://service.ncedc.org NIEP http://eida-sc3.infp.ro NOA http://eida.gein.noa.gr ODC http://www.orfeus-eu.org ORFEUS http://www.orfeus-eu.org RASPISHAKE http://fdsnws.raspberryshakedata.com RESIF http://ws.resif.fr SCEDC http://service.scedc.caltech.edu TEXNET http://rtserve.beg.utexas.edu USGS http://earthquake.usgs.gov USP http://sismo.iag.usp.br There is also the possibility to connect to your own server to download the inventory and the data.","title":"Retrieve Data"},{"location":"rd/#retrieve-data","text":"Retrieve Data framework is an interface to facilitate download specific events to time-series or select a period and download data from different stations. Step1: Select a FDSN web service and click load. This action will load the inventory. Step2: You can plot the inventory stations and can be add to the posterior request with double-click on the map or manually added. Also you can remove it with right button double-click. From this point you can follow different actions, Download Time Series: Just set Starttime and Endtime and click on the button. This will download the mini seeds of the stations/channels requested for that period. Download Metadata: This action will download the stations.xml of the stations/channels requested. Step3: If we want to download earthquake seismograms from a period of time for specific stations/channels. Step1: Download catalog (see figure) and select the rows of the earthquake you are interested. Next, fill the gaps for net, stations and channels. You can plot the stations and use double-click action to select the stations. Step 2: Fill the cut time-window (s) before and after the first arrival and click on Download event data. The available FDSN web services are: BGR http://eida.bgr.de EMSC http://www.seismicportal.eu ETH http://eida.ethz.ch GEONET http://service.geonet.org.nz GFZ http://geofon.gfz-potsdam.de ICGC http://ws.icgc.cat INGV http://webservices.ingv.it IPGP http://ws.ipgp.fr IRIS http://service.iris.edu ISC http://isc-mirror.iris.washington.edu KNMI http://rdsa.knmi.nl KOERI http://eida.koeri.boun.edu.tr LMU http://erde.geophysik.uni-muenchen.de NCEDC http://service.ncedc.org NIEP http://eida-sc3.infp.ro NOA http://eida.gein.noa.gr ODC http://www.orfeus-eu.org ORFEUS http://www.orfeus-eu.org RASPISHAKE http://fdsnws.raspberryshakedata.com RESIF http://ws.resif.fr SCEDC http://service.scedc.caltech.edu TEXNET http://rtserve.beg.utexas.edu USGS http://earthquake.usgs.gov USP http://sismo.iag.usp.br There is also the possibility to connect to your own server to download the inventory and the data.","title":"Retrieve Data"},{"location":"refs/","text":"References Almendros, J., Ib\u00e1nez, J. M., Alguacil, G., & Del Pezzo, E. (1999). Array analysis using circular-wave-front geometry: an application to locate the nearby seismo-volcanic source. Geophysical Journal International, 136(1), 159-170. Boashash, B., and Black, P. (1987). An efficient real-time implementation of the Wigner-Ville distribution. IEEE Transactions on Acoustics, Speech, and Signal Processing, 35(11), 1611\u20131618. Bormann, P., and Dewey, J. W. (2012). The new IASPEI standards for determining magnitudes from digital data and their relation to classical magnitudes. In New Manual of Seismological Observatory Practice 2 (NMSOP-2) (pp. 1\u201344). Deutsches GeoForschungsZentrum GFZ. Cabieces, R., Buforn, E., Cesca, S., and Pazos, A. (2020). Focal Parameters of Earthquakes Offshore Cape St. Vincent Using an Amphibious Network. Pure and Applied Geophysics. https://doi.org/10.1007/s00024-020-02475-3 Capon, J. (1969). High-resolution frequency-wavenumber spectrum analysis. Proceedings of the IEEE, 57(8), 1408\u20131418. Clinton, J. F., and Heaton, T. H. (2002). Potential advantages of a strong-motion velocity meter over a strong-motion accelerometer. Seismological Research Letters, 73(3), 332\u2013342. Daubechies, I., and Bates, B. J. (1992). Ten lectures on wavelets. ASA. van Driel, M., Krischer, L., St\u00e4hler, S. C., Hosseini, K., and Nissen-Meyer, T. (2015). Instaseis: instant global seismograms based on a broadband waveform database. Solid Earth, 6(2), 701\u2013717. https://doi.org/10.5194/se-6-701-2015 Flinn, E. A. (1965). Signal analysis using rectilinearity and direction of particle motion. Proceedings of the IEEE, 53(12), 1874\u20131876. Font, Y., Kao, H., Lallemand, S., Liu, C.-S., and Chiao, L.-Y. (2004). Hypocentre determination offshore of eastern Taiwan using the Maximum Intersection method. Geophysical Journal International, 158(2), 655\u2013675. Gal, M., Reading, A. M., Ellingsen, S. P., Koper, K. D., Gibbons, S. J., and Nasholm, S. P. (2014). Improved implementation of the fk and Capon methods for array analysis of seismic noise. Geophysical Journal International, 198(2), 1045\u20131054. https://doi.org/10.1093/gji/ggu183 Goldstein, P., Dodge, D., Firpo, M., Minner, L., Lee, W. H. K., Kanamori, H., et al. (2003). SAC2000: Signal processing and analysis tools for seismologists and engineers. The IASPEI International Handbook of Earthquake and Engineering Seismology, 81, 1613\u20131620. Goutorbe, B., D. L. de Oliveira Coelho, and S. Drouet (2015). Rayleigh wave group velocities at periods of 6-23 s across Brazil from ambient noise tomography, Geophys. J. Int. 203, no. 2, 869\u2013882. Havskov, J., Voss, P.H. and Ottemoller, L. (2020). Seismological Observatory Software: 30 Yr of SEISAN. Seismological Research Letters, 91 (3): 1846-1852. DOI: https://doi.org/10.1785/0220190313 Herrmann, R. B. (2013). Computer Programs in Seismology: An Evolving Tool for Instruction and Research. Seismological Research Letters, 84(6), 1081\u20131088. https://doi.org/10.1785/0220110096 Hunter, J. D. (2007). Matplotlib: A 2D Graphics Environment. Computing in Science and Engineering, 9(3), 90\u201395. https://doi.org/10.1109/MCSE.2007.55 Jiang, C., and M. A. Denolle (2020). NoisePy: A new high-perfor- mance Python tool for ambient-noise seismology, Seismol. Res. Lett. 91, no. 3, 1853\u20131866, doi: 10.1785/0220190364. Krischer, L., Megies, T., Barsch, R., Beyreuther, M., Lecocq, T., Caudron, C., and Wassermann, J. (2015). ObsPy: A bridge for seismology into the scientific Python ecosystem. Computational Science and Discovery. https://doi.org/10.1088/1749-4699/8/1/014003 Kruger, F., and M. Ohrnberger. 2005. Tracking the rupture of the Mw & equals; 9.3 Sumatra earthquake over 1,150 km at teleseismic distance. Nature 435 (7044): 937\u2013939. Langston, C. A. (1979). Structure under Mount Rainier, Washington, inferred from teleseismic body waves. Journal of Geophysical Research: Solid Earth, 84(B9), 4749\u20134762. Lecocq, T., C. Caudron, and F. Brenguier (2014). MSNoise, a Python package for monitoring seismic velocity changes using ambient seismic noise, Seismol. Res. Lett. 85, no. 3, 715\u2013726. Loeliger J., and McCullough, M. (2012) Version Control with Git: Powerful tools and techniques for collaborative software development. \" O'Reilly Media, Inc.\" Lomax, A., and Curtis, A. (2001). Fast, probabilistic earthquake location in 3D models using oct-tree importance sampling. In Geophys. Res. Abstr (Vol. 3, p. 955). Mallat, S. (2009). A wavelet tour of signal processing (Third). Elsevier. McNamara, D. E., and Buland, R. P. (2004). Ambiente noise levels in the continental United States. Bulletin of the Seismological Society of America. https://doi.org/10.1785/012003001 Nawab, S., Dowla, F., and Lacoss, R. (1985). Direction determination of wideband signals. IEEE Transactions on Acoustics, Speech, and Signal Processing, 33(5), 1114\u20131122. Nissen-Meyer, T., van Driel, M., St\u00e4hler, S. C., Hosseini, K., Hempel, S., Auer, L., Colombi, A., and Fournier, A. (2014). AxiSEM: broadband 3-D seismic wavefields in axisymmetric media, Solid Earth, 5, 425-445, https://doi.org/10.5194/se-5-425-2014. Peterson, J. R. (1993). Observations and modeling of seismic background noise. US Geological Survey. Podvin, P., and Lecomte, I. (1991). Finite difference computation of traveltimes in very contrasted velocity models: a massively parallel approach and its associated tools. Geophysical Journal International, 105(1), 271\u2013284. Prieto, G. A., Parker, R. L., and Vernon, F. L. (2009). A Fortran 90 library for multitaper spectrum analysis. Computers and Geosciences. https://doi.org/10.1016/j.cageo.2008.06.007 Ross, Z. E., Meier, M.-A., Hauksson, E., and Heaton, T. H. (2018). Generalized Seismic Phase Detection with Deep Learning. Bulletin of the Seismological Society of America, 108(5A), 2894\u20132901. https://doi.org/10.1785/0120180080 Rost, S., and Thomas, C. (2002). Array seismology: Methods and applications. Reviews of Geophysics, 40(3), 2\u201327. Ruigrok, E., Gibbons, S., and Wapenaar, K. (2017). Cross-correlation beamforming. Journal of Seismology, 21(3), 495\u2013508. Sambridge, M., and Mosegaard, K. (2002). Monte Carlo methods in geophysical inverse problems. Reviews of Geophysics, 40(3), 3\u201329. Sambridge, M. (2013). A Parallel Tempering algorithm for probabilistic sampling and multimodal optimization. Geophysical Journal International, 196(1), 357\u2013374. https://doi.org/10.1093/gji/ggt342 Schimmel, M., and Paulssen, H. (1997). Noise reduction and detection of weak, coherent signals through phase-weighted stacks. Geophysical Journal International. https://doi.org/10.1111/j.1365-246X.1997.tb05664.x Smith, W. S., Zeng, Z., & Carette, J. (2018). Seismology software: state of the practice. Journal of Seismology, 22(3), 755-788. Silva, S., Terrinha, P., Matias, L., Duarte, J. C., Roque, C., Ranero, C. R., et al. (2017). Micro-seismicity in the Gulf of Cadiz: Is there a link between micro-seismicity, high magnitude earthquakes and active faults? Tectonophysics. https://doi.org/10.1016/j.tecto.2017.07.026 Stammler, K. (1993). SeismicHandler\u2014programmable multichannel data handler for interactive and automatic processing of seismological analyses. Computers \\& Geosciences, 19(2), 135\u2013140. Stehly, L., Campillo, M., Shapiro, N. M., Rost, S., Thomas, C., Reading, A. M., et al. (2013). ObsPy: A Python toolbox for seismology. Geophysical Journal International, 40(3), 157\u2013172. https://doi.org/10.1785/gssrl.81.5.750 Thomson, D. J. (1982). Spectrum estimation and harmonic analysis. Proceedings of the IEEE, 70(9), 1055\u20131096. Torrence, C., and Compo, G. P. (1998). A Practical Guide to Wavelet Analysis. Bulletin of the American Meteorological Society. https://doi.org/10.1175/1520-0477(1998)079<0061:APGTWA>2.0.CO;2 Vack\u00e1\u0159, J., Burj\u00e1nek, J., Gallovic, F., Zahradn\u00edk, J., and Clinton, J. (2017). Bayesian ISOLA: new tool for automated centroid moment tensor inversion. Geophysical Journal International, 210(2), 693\u2013705. https://doi.org/10.1093/gji/ggx158 VanDecar, J.C., and R.S. Crosson. 1990. Determination of teleseismic relative phase arrival times using multi-channel cross-correlation and least squares. Bulletin of the Seismological Society of America 80 (1): 150\u2013169. Ventosa, S., Schimmel, M., and Stutzmann, E. (2017). Extracting surface waves, hum and normal modes: Time-scale phase-weighted stack and beyond. Geophysical Journal International. https://doi.org/10.1093/gji/ggx284 Wathelet, M., Chatelain, J. L., Cornou, C., Giulio, G. D., Guillier, B., Ohrnberger, M., & Savvaidis, A. (2020). Geopsy: A user\u2010friendly open\u2010source tool set for ambient vibration processing. Seismological Research Letters, 91(3), 1878-1889. Zhou, H. (1994). Rapid three\u2010dimensional hypocentral determination using a master station method. Journal of Geophysical Research: Solid Earth, 99(B8), 15439\u201315455. Zhu, L., and Kanamori, H. (2000). Moho depth variation in southern California from teleseismic receiver functions. Journal of Geophysical Research: Solid Earth, 105(B2), 2969\u20132980.","title":"References"},{"location":"refs/#references","text":"Almendros, J., Ib\u00e1nez, J. M., Alguacil, G., & Del Pezzo, E. (1999). Array analysis using circular-wave-front geometry: an application to locate the nearby seismo-volcanic source. Geophysical Journal International, 136(1), 159-170. Boashash, B., and Black, P. (1987). An efficient real-time implementation of the Wigner-Ville distribution. IEEE Transactions on Acoustics, Speech, and Signal Processing, 35(11), 1611\u20131618. Bormann, P., and Dewey, J. W. (2012). The new IASPEI standards for determining magnitudes from digital data and their relation to classical magnitudes. In New Manual of Seismological Observatory Practice 2 (NMSOP-2) (pp. 1\u201344). Deutsches GeoForschungsZentrum GFZ. Cabieces, R., Buforn, E., Cesca, S., and Pazos, A. (2020). Focal Parameters of Earthquakes Offshore Cape St. Vincent Using an Amphibious Network. Pure and Applied Geophysics. https://doi.org/10.1007/s00024-020-02475-3 Capon, J. (1969). High-resolution frequency-wavenumber spectrum analysis. Proceedings of the IEEE, 57(8), 1408\u20131418. Clinton, J. F., and Heaton, T. H. (2002). Potential advantages of a strong-motion velocity meter over a strong-motion accelerometer. Seismological Research Letters, 73(3), 332\u2013342. Daubechies, I., and Bates, B. J. (1992). Ten lectures on wavelets. ASA. van Driel, M., Krischer, L., St\u00e4hler, S. C., Hosseini, K., and Nissen-Meyer, T. (2015). Instaseis: instant global seismograms based on a broadband waveform database. Solid Earth, 6(2), 701\u2013717. https://doi.org/10.5194/se-6-701-2015 Flinn, E. A. (1965). Signal analysis using rectilinearity and direction of particle motion. Proceedings of the IEEE, 53(12), 1874\u20131876. Font, Y., Kao, H., Lallemand, S., Liu, C.-S., and Chiao, L.-Y. (2004). Hypocentre determination offshore of eastern Taiwan using the Maximum Intersection method. Geophysical Journal International, 158(2), 655\u2013675. Gal, M., Reading, A. M., Ellingsen, S. P., Koper, K. D., Gibbons, S. J., and Nasholm, S. P. (2014). Improved implementation of the fk and Capon methods for array analysis of seismic noise. Geophysical Journal International, 198(2), 1045\u20131054. https://doi.org/10.1093/gji/ggu183 Goldstein, P., Dodge, D., Firpo, M., Minner, L., Lee, W. H. K., Kanamori, H., et al. (2003). SAC2000: Signal processing and analysis tools for seismologists and engineers. The IASPEI International Handbook of Earthquake and Engineering Seismology, 81, 1613\u20131620. Goutorbe, B., D. L. de Oliveira Coelho, and S. Drouet (2015). Rayleigh wave group velocities at periods of 6-23 s across Brazil from ambient noise tomography, Geophys. J. Int. 203, no. 2, 869\u2013882. Havskov, J., Voss, P.H. and Ottemoller, L. (2020). Seismological Observatory Software: 30 Yr of SEISAN. Seismological Research Letters, 91 (3): 1846-1852. DOI: https://doi.org/10.1785/0220190313 Herrmann, R. B. (2013). Computer Programs in Seismology: An Evolving Tool for Instruction and Research. Seismological Research Letters, 84(6), 1081\u20131088. https://doi.org/10.1785/0220110096 Hunter, J. D. (2007). Matplotlib: A 2D Graphics Environment. Computing in Science and Engineering, 9(3), 90\u201395. https://doi.org/10.1109/MCSE.2007.55 Jiang, C., and M. A. Denolle (2020). NoisePy: A new high-perfor- mance Python tool for ambient-noise seismology, Seismol. Res. Lett. 91, no. 3, 1853\u20131866, doi: 10.1785/0220190364. Krischer, L., Megies, T., Barsch, R., Beyreuther, M., Lecocq, T., Caudron, C., and Wassermann, J. (2015). ObsPy: A bridge for seismology into the scientific Python ecosystem. Computational Science and Discovery. https://doi.org/10.1088/1749-4699/8/1/014003 Kruger, F., and M. Ohrnberger. 2005. Tracking the rupture of the Mw & equals; 9.3 Sumatra earthquake over 1,150 km at teleseismic distance. Nature 435 (7044): 937\u2013939. Langston, C. A. (1979). Structure under Mount Rainier, Washington, inferred from teleseismic body waves. Journal of Geophysical Research: Solid Earth, 84(B9), 4749\u20134762. Lecocq, T., C. Caudron, and F. Brenguier (2014). MSNoise, a Python package for monitoring seismic velocity changes using ambient seismic noise, Seismol. Res. Lett. 85, no. 3, 715\u2013726. Loeliger J., and McCullough, M. (2012) Version Control with Git: Powerful tools and techniques for collaborative software development. \" O'Reilly Media, Inc.\" Lomax, A., and Curtis, A. (2001). Fast, probabilistic earthquake location in 3D models using oct-tree importance sampling. In Geophys. Res. Abstr (Vol. 3, p. 955). Mallat, S. (2009). A wavelet tour of signal processing (Third). Elsevier. McNamara, D. E., and Buland, R. P. (2004). Ambiente noise levels in the continental United States. Bulletin of the Seismological Society of America. https://doi.org/10.1785/012003001 Nawab, S., Dowla, F., and Lacoss, R. (1985). Direction determination of wideband signals. IEEE Transactions on Acoustics, Speech, and Signal Processing, 33(5), 1114\u20131122. Nissen-Meyer, T., van Driel, M., St\u00e4hler, S. C., Hosseini, K., Hempel, S., Auer, L., Colombi, A., and Fournier, A. (2014). AxiSEM: broadband 3-D seismic wavefields in axisymmetric media, Solid Earth, 5, 425-445, https://doi.org/10.5194/se-5-425-2014. Peterson, J. R. (1993). Observations and modeling of seismic background noise. US Geological Survey. Podvin, P., and Lecomte, I. (1991). Finite difference computation of traveltimes in very contrasted velocity models: a massively parallel approach and its associated tools. Geophysical Journal International, 105(1), 271\u2013284. Prieto, G. A., Parker, R. L., and Vernon, F. L. (2009). A Fortran 90 library for multitaper spectrum analysis. Computers and Geosciences. https://doi.org/10.1016/j.cageo.2008.06.007 Ross, Z. E., Meier, M.-A., Hauksson, E., and Heaton, T. H. (2018). Generalized Seismic Phase Detection with Deep Learning. Bulletin of the Seismological Society of America, 108(5A), 2894\u20132901. https://doi.org/10.1785/0120180080 Rost, S., and Thomas, C. (2002). Array seismology: Methods and applications. Reviews of Geophysics, 40(3), 2\u201327. Ruigrok, E., Gibbons, S., and Wapenaar, K. (2017). Cross-correlation beamforming. Journal of Seismology, 21(3), 495\u2013508. Sambridge, M., and Mosegaard, K. (2002). Monte Carlo methods in geophysical inverse problems. Reviews of Geophysics, 40(3), 3\u201329. Sambridge, M. (2013). A Parallel Tempering algorithm for probabilistic sampling and multimodal optimization. Geophysical Journal International, 196(1), 357\u2013374. https://doi.org/10.1093/gji/ggt342 Schimmel, M., and Paulssen, H. (1997). Noise reduction and detection of weak, coherent signals through phase-weighted stacks. Geophysical Journal International. https://doi.org/10.1111/j.1365-246X.1997.tb05664.x Smith, W. S., Zeng, Z., & Carette, J. (2018). Seismology software: state of the practice. Journal of Seismology, 22(3), 755-788. Silva, S., Terrinha, P., Matias, L., Duarte, J. C., Roque, C., Ranero, C. R., et al. (2017). Micro-seismicity in the Gulf of Cadiz: Is there a link between micro-seismicity, high magnitude earthquakes and active faults? Tectonophysics. https://doi.org/10.1016/j.tecto.2017.07.026 Stammler, K. (1993). SeismicHandler\u2014programmable multichannel data handler for interactive and automatic processing of seismological analyses. Computers \\& Geosciences, 19(2), 135\u2013140. Stehly, L., Campillo, M., Shapiro, N. M., Rost, S., Thomas, C., Reading, A. M., et al. (2013). ObsPy: A Python toolbox for seismology. Geophysical Journal International, 40(3), 157\u2013172. https://doi.org/10.1785/gssrl.81.5.750 Thomson, D. J. (1982). Spectrum estimation and harmonic analysis. Proceedings of the IEEE, 70(9), 1055\u20131096. Torrence, C., and Compo, G. P. (1998). A Practical Guide to Wavelet Analysis. Bulletin of the American Meteorological Society. https://doi.org/10.1175/1520-0477(1998)079<0061:APGTWA>2.0.CO;2 Vack\u00e1\u0159, J., Burj\u00e1nek, J., Gallovic, F., Zahradn\u00edk, J., and Clinton, J. (2017). Bayesian ISOLA: new tool for automated centroid moment tensor inversion. Geophysical Journal International, 210(2), 693\u2013705. https://doi.org/10.1093/gji/ggx158 VanDecar, J.C., and R.S. Crosson. 1990. Determination of teleseismic relative phase arrival times using multi-channel cross-correlation and least squares. Bulletin of the Seismological Society of America 80 (1): 150\u2013169. Ventosa, S., Schimmel, M., and Stutzmann, E. (2017). Extracting surface waves, hum and normal modes: Time-scale phase-weighted stack and beyond. Geophysical Journal International. https://doi.org/10.1093/gji/ggx284 Wathelet, M., Chatelain, J. L., Cornou, C., Giulio, G. D., Guillier, B., Ohrnberger, M., & Savvaidis, A. (2020). Geopsy: A user\u2010friendly open\u2010source tool set for ambient vibration processing. Seismological Research Letters, 91(3), 1878-1889. Zhou, H. (1994). Rapid three\u2010dimensional hypocentral determination using a master station method. Journal of Geophysical Research: Solid Earth, 99(B8), 15439\u201315455. Zhu, L., and Kanamori, H. (2000). Moho depth variation in southern California from teleseismic receiver functions. Journal of Geophysical Research: Solid Earth, 105(B2), 2969\u20132980.","title":"References"},{"location":"release_notes/","text":"ISP is licensed under the GNU Lesser General Public License (LGPL) v3.0","title":"Release Notes"},{"location":"rf/","text":"Receiver Functions Get & Cut Eartquakes The receiver functions module uses a water-level deconvolution method to compute P to S receiver functions from earthquake recordings in mseed format. The program can be used to perform the H-k stacking (Zhu & Kanamori, 2000) of the receiver functions for the determination of the crustal thickness and VP/VS ratio, as well as the back-tracing and CCP (\u2018common-conversion point\u2019) stacking. The first step in the receiver function analysis consists in cutting a time window containing the P-wave arrivals for each earthquake and station. The \u2018Cut earthquakes\u2019 tool requires that the data we want to work with is available locally and can be accessed from the Menu Bar under \u2018Tools > Cut earthquakes \u2026\u2019 (Fig. 1). Fig. 1. Screenshot of the 'Cut earthquakes' tool. The numbers in the image are referred to in the text below. The \u2018Raw data\u2019 and \u2018XML/dataless\u2019 fields [1] must point to the directory containing our mseed data and the StationXML/dataless file for the instruments used to record the data (which must contain the location of the stations at least, and the instrumental responses if we wish to remove them). The \u2018Quick file search\u2019 checkbox can be used to quickly index the input files if they follow the naming convention \u201cYEAR.JULDAY.LOC.STATION.CHANNEL.mseed\u201d. If they do not, simply uncheck this option and the code will read the .mseed file headers instead. The buttons labeled with \u2018\u2026\u2019 [2] can be used to select the correct paths through the file explorer. The output of the \u2018Cut earthquakes\u2019 tool consists in a directory containing the windowed earthquakes for each station [3], and a metadata file [4] containing information about each event such as the origin time, location, azimuth, ray parameter, etc. The output paths for these files must also be set by the user. Under the \u2018Settings\u2019 section we can tune a few parameters regarding event selection, quality control and time windowing of the records. The determination of the P-wave arrival time to each station is performed automatically using the TauPy package and the information contained in a event catalog downloaded from a Web Service [5]. The \u2018Earth model\u2019 used in the TauPy computations can be selected using a drop-down menu [6]. The starting and ending dates for the event catalog can be set using [7]. The minimum magnitude of the selected events, the minimum and maximum epicentral distances (in degrees), the minimum acceptable signal-to-noise ratio for each event, and the start and end of the time window to cut from the local record relative to the P-wave arrival time can be set using [8], [9], [10], [11], [12], [13]. The coordinate system in which we want to work, \u2018LQT\u2019 for Q-receiver functions or \u2018ZRT\u2019 for R-receiver functions, can be set using a drop-down menu [14]. Fig. 2. Selection of the metadata file provided in the ISP example files. Estimate RFs Once the P-wave records are cut, the metadata file and a directory with the structure output/station/mseed files should have been created (the output path was set in the \u2018Cut earthquakes\u2019 tool, fields [3] and [4]). To compute and start working with the receiver functions, load the metadata file using the Main menu bar option \u2018Input > Read event data file \u2026\u2019 (Fig. 2). Triggering this option will open the file explorer. Once the metadata file has been successfully loaded, read the P-wave records under \u2018Input > RF Analysis > Read waveforms \u2026\u2019. A new instance of the file explorer will be opened (Fig. 3). It is important that the root directory containing the different station folders (field [3] chosen in the \u2018Cut earthquakes\u2019 tool) is selected, as the directory structure will allow the code to sort the data correctly. In this example, we will use the P-wave recordings and metadata file provided with ISP. These were created from 4 years of continuous recordings of the IU.PAB station (2002 to 2006) downloaded from the IRIS DMC. After correctly selecting the example files, the station \u2018PAB\u2019 will appear in the Water-level deconvolution panel [15] (Fig. 4). The Water-level deconvolution settings include a bandpass filter that is applied to the waveforms prior to deconvolution, with corner frequencies f1 and f2 [16], the width of the low-pass Gaussian filter used in the deconvolution [17], and the water-level itself [18]. These parameters should be tuned to obtain the best results for each individual station, but the default values are usually a good starting point. Once the settings are set, press the \u2018Compute RFs\u2019 button [19] and the receiver functions will appear on the panel [20]. A maximum of 7 receiver functions are displayed at once. Scroll through the different pages using the \u2018<\u2019 and \u2018>\u2019 buttons on the bottom right side of the panel [21]. Poor-quality receiver functions can be discarded by left-clicking on them, and reaccepted by left-clicking again (Fig. 5). Right clicking on the frame of a receiver function will display the waveform from which it was calculated. The \u2018Analysis tools\u2019 panel [22] can be used to change the time range displayed [23], sort the display order of the receiver functions [24] by back-azimuth or distance, discard all events lower than a certain magnitude [25] or remove all rejections, manual or automatic, and accept all receiver functions [26]. The \u2018Receiver function stack\u2019 panel [27] is intended to give the user an overview of all the available receiver functions in use, in order to facilitate their inspection and the detection of poor quality receiver functions that may be harming the results. The stack of all receiver functions is shown in the top part of this panel [28] and stacks at regular intervals of backazimuth or epicentral distance are shown on the bottom panel [29]. The size of these intervals and any desired overlap between them can be adjusted using the fields [30] and [31]. A \u2018Ps\u2019 phase moveout correction can be applied by selecting it in the [32] drop-down menu. To display the stack, simply press the \u2018Update plot\u2019 button [33]. The \u2018H-k stack\u2019 panel [34] displays the results of the H-k stacking, based on Zhu & Kanamori (2000). The code uses the semblance-weighted stacking method proposed by Eaton et al. (2006). The density of crustal thickness \u2013 Vp/Vs ratio (k) points for the H-k matrix can be adjusted using the fields [35], although the default value should be more than enough. The crustal thickness \u2013 Vp/Vs value ranges can be set using the fields [36], and the weights for the Ps, PpPs and PpSs+PsPs phases can be set using the fields [37]. Two widely used sets of weights are 0.70, 0.20, 0.10 and 0.34, 0.33, 0.44 for Ps, PpPs and PpSs+PsPs, respectively. Once satisfied with the parameters, press the \u2018Compute H-k stack\u2019 button. The H-k matrix will be shown, and the location of the maximum will be marked with two white lines. The uncertainty is displayed as a green ellipse and is computed following Eaton et al. (2006). The values and uncertainties for both parameters are shown in two labels below the H-k plot [38], [39]. The results for the PAB station example are H = 31.42, k = 1.73. The EARS result for this station are H = 32 km, k = 1.76 (http://ears.iris.washington.edu/Data/Summary/gauss_2.5/WM/UCM/station.html, last seen 26/01/2021). The event panel is located in the bottom right side of the main window [40] and displays the location of all the events used in the H-k computations. To generate this figure, simply press the \u2018Plot events\u2019 button [41]. For reference, two circles indicating 30 and 90 degrees of epicentral distance from the station are also displayed. After the H-k maximum is determined, the theoretical arrival times of the Ps, PpPs and PpSs+PsPs phases can be displayed on the \u2018Receiver function stack\u2019 panel for reference. For this, check the box labeled as \u2018Show theoretical arrival times\u2019 [42] and press the button \u2018Update plot\u2019 [33]. Two types of results can be saved: the receiver functions (which will be used in the second chapter of this tutorial) and the H-k maximum coordinates, pressing buttons \u2018Save RFs\u2019 [43] and \u2018Save results\u2019 [44], respectively. Both options open a file dialog. The \u2018Save RFs\u2019 [43] function requires the user to select an output folder where the receiver functions for the current station will be dumped as a Python pickle file. The \u2018Save results\u2019 [44] will output the H-k results in .csv format, creating a new file if it doesn\u2019t exist, or appending to an existing file if selected. Figures of the Receiver function stack, the H-k stack, and the event location plot can be saved using the corresponding \u2018Save figure\u2019 button, which will display the Save figure dialog. The \u2018Save figure\u2019 dialog creates a .png or .pdf image of the data being displayed in the main user interface. Height, width, and quality of the figure (DPI) can be chosen, as well as the size of the margins and the figure labels. Fig. 4. Screenshot of the main window. The numbers in the image are referred to in the text above* Back-tracing and CCP stacking of RFs After the receiver functions have been computed and undergone a visual quality control, they can be saved using the \u2018Save RFs\u2019 feature ([43], Fig. 4). The resulting files can be loaded back into the program for the back-tracing and CCP stacking of the receiver functions. The first step is to load the event metadata file produced in the previous chapter. If it is already loaded for the H-k analysis, it will not be necessary to load it again. The second step is to read the saved receiver functions. This can be done under \u2018Input > CCP Stacking > Read RFs \u2026\u2019. Triggering this option will display an open file dialog, in which the directory containing the receiver function files must be selected. Once loaded, switch to the \u201cCCP Stacking\u201d tab in the main window. A map of the stations with available receiver functions will be in display. The stacking is performed over a user-defined grid. This can be done either manually (pressing the \u2018Manual selection\u2019 button in the \u2018Grid Fig. 5. Cross section map and CCP stacking","title":"Receiver Functions"},{"location":"rf/#receiver-functions","text":"","title":"Receiver Functions"},{"location":"rf/#get-cut-eartquakes","text":"The receiver functions module uses a water-level deconvolution method to compute P to S receiver functions from earthquake recordings in mseed format. The program can be used to perform the H-k stacking (Zhu & Kanamori, 2000) of the receiver functions for the determination of the crustal thickness and VP/VS ratio, as well as the back-tracing and CCP (\u2018common-conversion point\u2019) stacking. The first step in the receiver function analysis consists in cutting a time window containing the P-wave arrivals for each earthquake and station. The \u2018Cut earthquakes\u2019 tool requires that the data we want to work with is available locally and can be accessed from the Menu Bar under \u2018Tools > Cut earthquakes \u2026\u2019 (Fig. 1). Fig. 1. Screenshot of the 'Cut earthquakes' tool. The numbers in the image are referred to in the text below. The \u2018Raw data\u2019 and \u2018XML/dataless\u2019 fields [1] must point to the directory containing our mseed data and the StationXML/dataless file for the instruments used to record the data (which must contain the location of the stations at least, and the instrumental responses if we wish to remove them). The \u2018Quick file search\u2019 checkbox can be used to quickly index the input files if they follow the naming convention \u201cYEAR.JULDAY.LOC.STATION.CHANNEL.mseed\u201d. If they do not, simply uncheck this option and the code will read the .mseed file headers instead. The buttons labeled with \u2018\u2026\u2019 [2] can be used to select the correct paths through the file explorer. The output of the \u2018Cut earthquakes\u2019 tool consists in a directory containing the windowed earthquakes for each station [3], and a metadata file [4] containing information about each event such as the origin time, location, azimuth, ray parameter, etc. The output paths for these files must also be set by the user. Under the \u2018Settings\u2019 section we can tune a few parameters regarding event selection, quality control and time windowing of the records. The determination of the P-wave arrival time to each station is performed automatically using the TauPy package and the information contained in a event catalog downloaded from a Web Service [5]. The \u2018Earth model\u2019 used in the TauPy computations can be selected using a drop-down menu [6]. The starting and ending dates for the event catalog can be set using [7]. The minimum magnitude of the selected events, the minimum and maximum epicentral distances (in degrees), the minimum acceptable signal-to-noise ratio for each event, and the start and end of the time window to cut from the local record relative to the P-wave arrival time can be set using [8], [9], [10], [11], [12], [13]. The coordinate system in which we want to work, \u2018LQT\u2019 for Q-receiver functions or \u2018ZRT\u2019 for R-receiver functions, can be set using a drop-down menu [14]. Fig. 2. Selection of the metadata file provided in the ISP example files.","title":"Get &amp; Cut Eartquakes"},{"location":"rf/#estimate-rfs","text":"Once the P-wave records are cut, the metadata file and a directory with the structure output/station/mseed files should have been created (the output path was set in the \u2018Cut earthquakes\u2019 tool, fields [3] and [4]). To compute and start working with the receiver functions, load the metadata file using the Main menu bar option \u2018Input > Read event data file \u2026\u2019 (Fig. 2). Triggering this option will open the file explorer. Once the metadata file has been successfully loaded, read the P-wave records under \u2018Input > RF Analysis > Read waveforms \u2026\u2019. A new instance of the file explorer will be opened (Fig. 3). It is important that the root directory containing the different station folders (field [3] chosen in the \u2018Cut earthquakes\u2019 tool) is selected, as the directory structure will allow the code to sort the data correctly. In this example, we will use the P-wave recordings and metadata file provided with ISP. These were created from 4 years of continuous recordings of the IU.PAB station (2002 to 2006) downloaded from the IRIS DMC. After correctly selecting the example files, the station \u2018PAB\u2019 will appear in the Water-level deconvolution panel [15] (Fig. 4). The Water-level deconvolution settings include a bandpass filter that is applied to the waveforms prior to deconvolution, with corner frequencies f1 and f2 [16], the width of the low-pass Gaussian filter used in the deconvolution [17], and the water-level itself [18]. These parameters should be tuned to obtain the best results for each individual station, but the default values are usually a good starting point. Once the settings are set, press the \u2018Compute RFs\u2019 button [19] and the receiver functions will appear on the panel [20]. A maximum of 7 receiver functions are displayed at once. Scroll through the different pages using the \u2018<\u2019 and \u2018>\u2019 buttons on the bottom right side of the panel [21]. Poor-quality receiver functions can be discarded by left-clicking on them, and reaccepted by left-clicking again (Fig. 5). Right clicking on the frame of a receiver function will display the waveform from which it was calculated. The \u2018Analysis tools\u2019 panel [22] can be used to change the time range displayed [23], sort the display order of the receiver functions [24] by back-azimuth or distance, discard all events lower than a certain magnitude [25] or remove all rejections, manual or automatic, and accept all receiver functions [26]. The \u2018Receiver function stack\u2019 panel [27] is intended to give the user an overview of all the available receiver functions in use, in order to facilitate their inspection and the detection of poor quality receiver functions that may be harming the results. The stack of all receiver functions is shown in the top part of this panel [28] and stacks at regular intervals of backazimuth or epicentral distance are shown on the bottom panel [29]. The size of these intervals and any desired overlap between them can be adjusted using the fields [30] and [31]. A \u2018Ps\u2019 phase moveout correction can be applied by selecting it in the [32] drop-down menu. To display the stack, simply press the \u2018Update plot\u2019 button [33]. The \u2018H-k stack\u2019 panel [34] displays the results of the H-k stacking, based on Zhu & Kanamori (2000). The code uses the semblance-weighted stacking method proposed by Eaton et al. (2006). The density of crustal thickness \u2013 Vp/Vs ratio (k) points for the H-k matrix can be adjusted using the fields [35], although the default value should be more than enough. The crustal thickness \u2013 Vp/Vs value ranges can be set using the fields [36], and the weights for the Ps, PpPs and PpSs+PsPs phases can be set using the fields [37]. Two widely used sets of weights are 0.70, 0.20, 0.10 and 0.34, 0.33, 0.44 for Ps, PpPs and PpSs+PsPs, respectively. Once satisfied with the parameters, press the \u2018Compute H-k stack\u2019 button. The H-k matrix will be shown, and the location of the maximum will be marked with two white lines. The uncertainty is displayed as a green ellipse and is computed following Eaton et al. (2006). The values and uncertainties for both parameters are shown in two labels below the H-k plot [38], [39]. The results for the PAB station example are H = 31.42, k = 1.73. The EARS result for this station are H = 32 km, k = 1.76 (http://ears.iris.washington.edu/Data/Summary/gauss_2.5/WM/UCM/station.html, last seen 26/01/2021). The event panel is located in the bottom right side of the main window [40] and displays the location of all the events used in the H-k computations. To generate this figure, simply press the \u2018Plot events\u2019 button [41]. For reference, two circles indicating 30 and 90 degrees of epicentral distance from the station are also displayed. After the H-k maximum is determined, the theoretical arrival times of the Ps, PpPs and PpSs+PsPs phases can be displayed on the \u2018Receiver function stack\u2019 panel for reference. For this, check the box labeled as \u2018Show theoretical arrival times\u2019 [42] and press the button \u2018Update plot\u2019 [33]. Two types of results can be saved: the receiver functions (which will be used in the second chapter of this tutorial) and the H-k maximum coordinates, pressing buttons \u2018Save RFs\u2019 [43] and \u2018Save results\u2019 [44], respectively. Both options open a file dialog. The \u2018Save RFs\u2019 [43] function requires the user to select an output folder where the receiver functions for the current station will be dumped as a Python pickle file. The \u2018Save results\u2019 [44] will output the H-k results in .csv format, creating a new file if it doesn\u2019t exist, or appending to an existing file if selected. Figures of the Receiver function stack, the H-k stack, and the event location plot can be saved using the corresponding \u2018Save figure\u2019 button, which will display the Save figure dialog. The \u2018Save figure\u2019 dialog creates a .png or .pdf image of the data being displayed in the main user interface. Height, width, and quality of the figure (DPI) can be chosen, as well as the size of the margins and the figure labels. Fig. 4. Screenshot of the main window. The numbers in the image are referred to in the text above*","title":"Estimate RFs"},{"location":"rf/#back-tracing-and-ccp-stacking-of-rfs","text":"After the receiver functions have been computed and undergone a visual quality control, they can be saved using the \u2018Save RFs\u2019 feature ([43], Fig. 4). The resulting files can be loaded back into the program for the back-tracing and CCP stacking of the receiver functions. The first step is to load the event metadata file produced in the previous chapter. If it is already loaded for the H-k analysis, it will not be necessary to load it again. The second step is to read the saved receiver functions. This can be done under \u2018Input > CCP Stacking > Read RFs \u2026\u2019. Triggering this option will display an open file dialog, in which the directory containing the receiver function files must be selected. Once loaded, switch to the \u201cCCP Stacking\u201d tab in the main window. A map of the stations with available receiver functions will be in display. The stacking is performed over a user-defined grid. This can be done either manually (pressing the \u2018Manual selection\u2019 button in the \u2018Grid Fig. 5. Cross section map and CCP stacking","title":"Back-tracing and CCP stacking of RFs"},{"location":"synth/","text":"Synthetic Generator The Synthetic Tool (Fig. 1), you can make queries to download synthetic seismograms using the synthetic generator (go to the toolbar to deploy it). Fig. 2 shows the tool to make the queries. To implement a query just add the location of the stations for the synthetics be generated. Choose a model, units (velocity, displacement or acceleration) the source coordinates and time spam and, very important, the type of source and the focal parameters. Once the query is done and the synthetic seismograms are saved in the location path you had selected, you can plot the synthetic seismograms and the map/focal mechanism for give a first eye to the results.","title":"Synthetic Generator"},{"location":"synth/#synthetic-generator","text":"The Synthetic Tool (Fig. 1), you can make queries to download synthetic seismograms using the synthetic generator (go to the toolbar to deploy it). Fig. 2 shows the tool to make the queries. To implement a query just add the location of the stations for the synthetics be generated. Choose a model, units (velocity, displacement or acceleration) the source coordinates and time spam and, very important, the type of source and the focal parameters. Once the query is done and the synthetic seismograms are saved in the location path you had selected, you can plot the synthetic seismograms and the map/focal mechanism for give a first eye to the results.","title":"Synthetic Generator"},{"location":"tf/","text":"Time-Frequency Analysis Multitaper, CWT and Wigner Distribution The Time-Frequency Analysis window is designed to facilitate the computation of advanced seismic signal processes on individual seismograms. The seismograms are selected in the files explorer. You can also set a macro with basic process before running any time-Frequency analysis The most important is the selection of the Seismogram (the analysis will be show in the upper panel . \u201cseismogram 1\u201d and lower panel seismogram 2). Then you can select which one of Time-Frequency analysis you want to compute. Before Compute the Time-Frequency analysis be sure that you have filled the parameters of that kind of analysis (MT for multitaper spectrogram and CWT for Continuous Wavelet Transform). With respect to the Wavelet: The wavelet needs, select the wavelet (Morlet, Paul or Mexican Hat are available) and fill the parameters in accordance to the selected wavelet (Mallat, 2009). With respect to the Multitaper (Thomson, 1982): His analysis needs to specify the Window Length, Time-Bandwidth, the Number of Tapers and the range of the frequencies Advanced TF analysis (two seismograms at once) In the Figures are shown an example of computation of CWT and the uncertainty cone using the Morlet wavelet (upper panel) and multitaper spectrogram (lower panel). In the multimedia material can be found an example of how to mange the TF framework. Once two seismograms are selected we can follow with more advanced signal processing (Open advanced analysis): Spectrum Comparison >>> plot the amplitude and phase spectrum individual and together (Fig. 2). Coherence >>> Plot the magnitude square coherence and its phase (Fig. 3). Cross Correlation >>> Plot the Autocorrelations and the cross correlation of both signals (Fig. 4). Cross Wavelet >>> Plot the Cross-CWT of both signals (Fig. 5). Multimedia Material (Time-Frequency Analysis) The following video shows a basic analysis of an earthquake Shortcuts Shortcut Action 'q' Set start time 'w' Process and Plot 'e' Set end time","title":"Time-Frequency Analysis"},{"location":"tf/#time-frequency-analysis","text":"","title":"Time-Frequency Analysis"},{"location":"tf/#multitaper-cwt-and-wigner-distribution","text":"The Time-Frequency Analysis window is designed to facilitate the computation of advanced seismic signal processes on individual seismograms. The seismograms are selected in the files explorer. You can also set a macro with basic process before running any time-Frequency analysis The most important is the selection of the Seismogram (the analysis will be show in the upper panel . \u201cseismogram 1\u201d and lower panel seismogram 2). Then you can select which one of Time-Frequency analysis you want to compute. Before Compute the Time-Frequency analysis be sure that you have filled the parameters of that kind of analysis (MT for multitaper spectrogram and CWT for Continuous Wavelet Transform). With respect to the Wavelet: The wavelet needs, select the wavelet (Morlet, Paul or Mexican Hat are available) and fill the parameters in accordance to the selected wavelet (Mallat, 2009). With respect to the Multitaper (Thomson, 1982): His analysis needs to specify the Window Length, Time-Bandwidth, the Number of Tapers and the range of the frequencies","title":"Multitaper, CWT and Wigner Distribution"},{"location":"tf/#advanced-tf-analysis-two-seismograms-at-once","text":"In the Figures are shown an example of computation of CWT and the uncertainty cone using the Morlet wavelet (upper panel) and multitaper spectrogram (lower panel). In the multimedia material can be found an example of how to mange the TF framework. Once two seismograms are selected we can follow with more advanced signal processing (Open advanced analysis): Spectrum Comparison >>> plot the amplitude and phase spectrum individual and together (Fig. 2). Coherence >>> Plot the magnitude square coherence and its phase (Fig. 3). Cross Correlation >>> Plot the Autocorrelations and the cross correlation of both signals (Fig. 4). Cross Wavelet >>> Plot the Cross-CWT of both signals (Fig. 5).","title":"Advanced TF analysis (two seismograms at once)"},{"location":"tf/#multimedia-material-time-frequency-analysis","text":"The following video shows a basic analysis of an earthquake","title":"Multimedia Material (Time-Frequency Analysis)"},{"location":"tf/#shortcuts","text":"Shortcut Action 'q' Set start time 'w' Process and Plot 'e' Set end time","title":"Shortcuts"}]}